[{"title":"grpc上手使用","url":"/2018/12/21/grpc上手使用/","content":"\n# grpc上手使用\n\n### 安装\n\n`golang`版本的`grpc`要求`go`版本要在`1.6`以上\n\n##### install gRPC\n\n使用`go get`命令安装`grpc`包\n\n```sh\n$ go get -u google.golang.org/grpc\n```\n\n> 由于某些不可逆原因，上面命令会报连接超时，可以到`github`上将项目`clone`到`$GOPATH/src/google.golang.org/`下\n>\n> ```sh\n> $ cd $GOPATH/src/google.golang.org\n> $ git clone git@github.com:grpc/grpc-go.git grpc\n> ```\n\n##### install Protocol Buffers  v3\n\n`grpc`默认使用`protobuf`作为序列化工具。\n\n1. 打开[Releases](https://github.com/protocolbuffers/protobuf/releases)页面，下载对应平台的`.zip`包`protoc-<version>-<platform>.zip`\n2. 解压\n3. 添加二进制文件路径导`PATH`环境变量\n\n##### install protoc plugin\n\n安装`golang`版本对应的`protobuf`生成工具\n\n```sh\n$ go get -u github.com/golang/protobuf/protoc-gen-go\n$ export PATH=$PATH:$GOPATH/bin\n```\n\n### 运行demo\n\n进入`example`目录\n\n```sh\n$ cd $GOPATH/src/google.golang.org/grpc/examples/helloworld\n```\n\n删除原来的`helloworld.pb.go`文件，并使用`protoc`生成自己生成一个\n\n```sh\n$ rm helloworld/helloworld.pb.go // 删除原来的helloworld.pb.go文件\n$ protoc -I helloworld/ helloworld/helloworld.proto --go_out=plugins=grpc:helloworld // 根据 .proto 文件生成对应的.go文件\n```\n\n编写`grpc`接口时，在`.proto`文件定义接口通信数据格式和接口信息，然后通过`protoc`自动生成对应的`go`代码，大大方便了开发\n\n- `-I PATH`：specify the directory in which to search for imports.  May be specified multiple times; directories will be searched in order.  If not given, the current working directory is used.\n- `--go_out`：指定输出`go`代码\n- `plugins=grpc`：`.proto`中的`service `是`grpc`扩展的功能，需要使用`grpc`插件进行解析才能生成对应的接口定义代码。\n\n运行 `grpc server `和 `grpc client`\n\n```sh\n$ go run greeter_server/main.go // 启动grpc server\n$ go run greeter_client/main.go // 启动grpc client\n```\n\n\n\n### 实践\n\n使用`grpc`开发一个简单的求和服务。\n\n##### 定义.proto文件\n\n在项目下创建`proto/sum.proto`文件：\n\n```protobuf\nsyntax = \"proto3\"; // 使用 proto3\n\n// java生成选项\noption java_multiple_files = true;\noption java_package = \"io.grpc.examples.helloworld\";\noption java_outer_classname = \"HelloWorldProto\";\n\npackage proto; // 生成的go所属的package\n\nmessage SumResp {\n    int64 sum = 1;\n}\n\nmessage SumReq {\n    int64 a = 1;\n    int64 b = 2;\n}\n\n\nservice CalcSvc {\n    // 每个rpc接口声明都必须有且一个参数和一个返回值\n    rpc Sum(SumReq) returns (SumResp) {}\n}\n```\n\n##### 根据接口描述文件生成源码\n\n进入`proto`目录，执行\n\n```sh\n$ protoc sum.proto --go_out=plugins=grpc:.\n```\n\n可以看到，在本目录下生成`sum.pb.go`文件，且`package`为`proto`\n\n##### 开发服务端接口\n\n首先查看生成的`sum.pb.go`文件，可以看到根据`sum.proto`文件中的`CalcSvc`接口定义生成了对应的接口：\n\n```go\n// CalcSvcServer is the server API for CalcSvc service.\ntype CalcSvcServer interface {\n\t// 每个rpc接口声明都必须有且一个参数和一个返回值\n\tSum(context.Context, *SumReq) (*SumResp, error)\n}\n```\n\n开发服务端接口只要就是根据这些接口定义实现具体的业务逻辑\n\n在项目下创建`service/main.go`：\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/reflection\"\n\t\"grpc-demo/proto\"\n\t\"log\"\n\t\"net\"\n)\n\n// 类型断言\nvar _ proto.CalcSvcServer = new(CalcSvc)\n\ntype CalcSvc struct{}\n\nfunc (CalcSvc) Sum(ctx context.Context, req *proto.SumReq) (resp *proto.SumResp, err error) {\n    // 建议使用GetA，不要直接使用req.A，可能存在req=nil的情况\n\ta := req.GetA() \n\tb := req.GetB()\n\tlog.Println(\"request coming ...\")\n\treturn &proto.SumResp{\n\t\tSum: a + b,\n\t}, err\n}\n\nfunc main() {\n\tlis, err := net.Listen(\"tcp\", \":8888\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n    // 注册服务到gRPC\n\ts := grpc.NewServer()\n\tproto.RegisterCalcSvcServer(s, &CalcSvc{})\n    // 启用Server Reflection，可以使用gRPC CLI去检查services\n    // https://github.com/grpc/grpc-go/blob/master/Documentation/server-reflection-tutorial.md\n\treflection.Register(s)\n    // 启动服务\n\tif err := s.Serve(lis); err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n```\n\n##### 客户端访问\n\n在项目下创建`client/main.go`：\n\n```go \npackage main\n\nimport (\n\t\"context\"\n\t\"google.golang.org/grpc\"\n\t\"grpc-demo/proto\"\n\t\"log\"\n)\n\nfunc main() {\n    // 创建gRPC连接\n    // WithInsecure option 指定不启用认证功能\n\tconn, err := grpc.Dial(\":8888\", grpc.WithInsecure())\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n    // 创建gRPC client\n\tclient := proto.NewCalcSvcClient(conn)\n    // 请求gRPC server\n\tresp, err := client.Sum(context.Background(), &proto.SumReq{\n\t\tA: 5,\n\t\tB: 10,\n\t})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tlog.Printf(\"5 + 10 = %d\", resp.GetSum())\n}\n```\n\n##### 运行\n\n```go \n$ go run service/main.go\n$ go run client/main.go\n```\n\n\n\n### grpc连接复用\n\n首先修改服务端代码，**添加 `1s` 的睡眠时间**，模拟复杂业务处理场景：\n\n```go\nfunc (CalcSvc) Sum(ctx context.Context, req *proto.SumReq) (resp *proto.SumResp, err error) {\n\ta := req.GetA()\n\tb := req.GetB()\n\tlog.Println(\"request coming ...\")\n    // 添加 1s 睡眠，模拟接口执行业务逻辑\n\ttime.Sleep(time.Second)\n\treturn &proto.SumResp{\n\t\tSum: a + b,\n\t}, err\n}\n```\n\n##### http2多路复用\n\n`grpc`底层使用`http2`协议进行通信，因此单条连接支持多路复用\n\n修改客户端代码：\n\n```go\n\nfunc main() {\n\tconn ,err:=grpc.Dial(\":8888\", grpc.WithInsecure())\n\tif err!=nil {\n\t\tlog.Fatal(err)\n\t}\n\tclient :=proto.NewCalcSvcClient(conn)\n\n\twg := sync.WaitGroup{}\n\tbegin := time.Now()\n\tconcurrentNum := 1000\n\twg.Add(concurrentNum)\n    \n\tfor i := 0; i < concurrentNum; i++ {\n\t\tgo func() {\n\t\t\tresp, err := client.Sum(context.Background(), &proto.SumReq{\n\t\t\t\tA: 5,\n\t\t\t\tB: 10,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal(err)\n\t\t\t}\n\t\t\tlog.Printf(\"5 + 10 = %d\", resp.GetSum())\n\t\t\twg.Done()\n\t\t}()\n\t}\n\twg.Wait()\n\tlog.Printf(\"用时：%v\", time.Now().Sub(begin))\n}\n```\n\n在上面代码中，服务端每次都睡眠`1s`，客户端使用单条连接进行通信，**1000个并发请求总共执行时间为`1.1s`左右**\n\n如果是`2000`个请求，平均在`1.2s`左右，`10000`个请求是`2`s左右。\n\n可见`grpc`本身单条连接可用提供的并发效果足以满足大部分业务场景。\n\n**注意：**上面的`1000`个并发请求并不是单条连接可以同时发起`1000`个请求，而是其内部支持类似`pipeline`的机制。\n\n##### 连接池\n\n接下来不使用`http2`的多路复用，采用连接池的方式来创建请求\n\n首先实现一个连接池：\n\n```go\npackage main\n\nimport (\n\t\"google.golang.org/grpc\"\n\t\"sync\"\n\t\"time\"\n)\n\n// 连接池选项\ntype Options struct {\n\tDial        Dialer\n\tMaxConn     int\n\tMaxIdle     int\n\tWaitTimeout time.Duration\n}\n\n// 创建连接\ntype Dialer func() (*grpc.ClientConn, error)\n\ntype Pool struct {\n\tdial    Dialer\n\tmaxConn int // 最大打开连接数\n\tmaxIdle int // 最大空闲连接数\n\n\twaitTimeout time.Duration // 等待连接超时时间\n    // 等待连接时通过connCh来传输可用连接\n\tconnCh      chan *grpc.ClientConn\n\n\tcurConnNum int // 记录当前打开的连接数\n    // 保存空闲连接\n\tfreeConn   []*grpc.ClientConn\n\tsync.Mutex\n}\n\n// 创建连接池\nfunc NewPool(opts Options) *Pool {\n\tif opts.MaxConn <= 0 {\n\t\topts.MaxConn = 10\n\t}\n\tif opts.MaxIdle <= 0 {\n\t\topts.MaxIdle = 5\n\t}\n\tif opts.MaxIdle > opts.MaxConn {\n\t\topts.MaxIdle = opts.MaxIdle\n\t}\n\n\treturn &Pool{\n\t\tdial:        opts.Dial,\n\t\tmaxConn:     opts.MaxConn,\n\t\tmaxIdle:     opts.MaxIdle,\n\t\twaitTimeout: opts.WaitTimeout,\n\t\tconnCh:      make(chan *grpc.ClientConn),\n\t\tfreeConn:    make([]*grpc.ClientConn, 0, opts.MaxIdle),\n\t}\n\n}\n\n// 获取连接\nfunc (p *Pool) Get() (conn *grpc.ClientConn) {\n\tp.Lock()\n\t// 已经到达最大连接数\n\tif p.curConnNum >= p.maxConn {\n        // 如果等待超时时间为0，直接返回\n\t\tif p.waitTimeout == 0 {\n\t\t\tp.Unlock()\n\t\t\treturn\n\t\t}\n\n\t\tvar tm <-chan time.Time\n        // 如果等待超时时间小于0，表示无限等待\n\t\tif p.waitTimeout > 0 {\n\t\t\ttm = time.After(p.waitTimeout)\n\t\t}\n\t\tp.Unlock()\n        // 等待可用连接或者超时\n\t\tselect {\n\t\tcase <-tm:\n\t\tcase conn = <-p.connCh:\n\t\t}\n\t\treturn\n\t}\n\t// 如果存在空闲连接\n\tif ln := len(p.freeConn); ln > 0 {\n\t\tconn = p.freeConn[0]\n\t\tp.freeConn[0] = p.freeConn[ln-1]\n\t\tp.freeConn = p.freeConn[:ln-1]\n\t} else { // 创建新的连接\n\t\tc, err := p.dial()\n\t\tif err != nil {\n\t\t\tconn = nil\n\t\t} else {\n\t\t\tp.curConnNum++\n\t\t\tconn = c\n\t\t}\n\t}\n\tp.Unlock()\n\treturn\n}\n\n// 释放连接\nfunc (p *Pool) Put(conn *grpc.ClientConn) error {\n\tif conn == nil {\n\t\treturn nil\n\t}\n    // 首先判断是否有其他协程在等待连接\n\tselect {\n\tcase p.connCh <- conn:\n\t\treturn nil\n\tdefault:\n\t}\n\tp.Lock()\n\tdefer p.Unlock()\n    // 放回空闲连接\n\tif len(p.freeConn) < p.maxIdle {\n\t\tp.freeConn = append(p.freeConn, conn)\n\t\treturn nil\n\t}\n    // 再次判断是否有等待可用连接\n\tselect {\n\tcase p.connCh <- conn:\n\t\treturn nil\n\tdefault:\n        // 关闭连接\n\t\tp.curConnNum--\n\t\treturn conn.Close()\n\t}\n}\n\n// 统计连接池状态\nfunc (p *Pool) Stat() PoolStat {\n\tp.Lock()\n\tp.Unlock()\n\treturn PoolStat{\n\t\tConnNum:     p.curConnNum,\n\t\tIdleConnNum: len(p.freeConn),\n\t}\n}\n\ntype PoolStat struct {\n\tConnNum     int\n\tIdleConnNum int\n}\n\n```\n\n接下来，使用该连接池进行测试：\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"google.golang.org/grpc\"\n\t\"grpc-demo/proto\"\n\t\"log\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc main() {\n\topts := Options{\n\t\tDial: func() (*grpc.ClientConn, error) {\n\t\t\treturn grpc.Dial(\":8888\", grpc.WithInsecure())\n\t\t},\n\t\tWaitTimeout: time.Second * 10,\n\t\tMaxConn:     100, // 设置最大连接数为100\n\t\tMaxIdle:     50,\n\t}\n\tpool := NewPool(opts)\n\tif pool == nil {\n\t\tpanic(\"nil pool\")\n\t}\n\n\twg := sync.WaitGroup{}\n\tbegin := time.Now()\n\tconcurrentNum := 1000\n\twg.Add(concurrentNum)\n\tfor i := 0; i < concurrentNum; i++ {\n\t\tgo func() {\n\n\t\t\tconn := pool.Get()\n\t\t\tif conn == nil {\n\t\t\t\tpanic(\"nil conn\")\n\t\t\t}\n\t\t\tdefer pool.Put(conn)\n\t\t\tclient := proto.NewCalcSvcClient(conn)\n\n\t\t\tresp, err := client.Sum(context.Background(), &proto.SumReq{\n\t\t\t\tA: 5,\n\t\t\t\tB: 10,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal(err)\n\t\t\t}\n\t\t\tlog.Printf(\"5 + 10 = %d\", resp.GetSum())\n\t\t\twg.Done()\n\t\t}()\n\t}\n\twg.Wait()\n\tlog.Printf(\"用时：%v\", time.Now().Sub(begin))\n\tlog.Println(pool.Stat())\n}\n```\n\n在上面的代码中，每次请求时都从连接池中获取一个连接，请求完成后将其释放。\n\n运行上面代码，**`1000`个并发请求总共需要花费`10.15s`左右**。\n\n\n\n### 负载均衡\n\n这里使用`dns`来进行负载均衡进行演示。\n\n我实验机器上面的本机`IP`是`127.0.0.1`，虚拟机`IP`是`192.168.50.12`\n\n首先，修改系统的`hosts`文件，添加：\n\n```\n192.168.50.12 www.grpc.com\n127.0.0.1 www.grpc.com\n```\n\n然后，同时在本地和虚拟机中启动`grpc server`\n\n最后，修改`grpc client`代码：\n\n```go\nconn, err := grpc.Dial(\"dns:///www.grpc.com:8888\", grpc.WithInsecure(), grpc.WithBalancerName(roundrobin.Name))\nif err != nil {\n\tlog.Fatal(err)\n}\nclient := proto.NewCalcSvcClient(conn)\n```\n\n在创建`grpc`连接的时候，使用`dns:///www.grpc.com:8888`，同时指定负载策略为`roundrobin`。\n\n执行`grpc client`，可用看到**两边的`grpc server`都有打印出请求日志**。\n\n`grpc`提供的负载均衡测试是在**请求级别上进行负载均衡**。\n\n`grpc`会同时为每个`grpc server`创建一条连接；每次要发起一个请求的时候，都会根据负载策略选择一条连接来发起请求。","tags":["go","grpc"]},{"title":"go编译共享库给c调用","url":"/2018/12/19/go编译共享库给c调用/","content":"\n### introduce\n\n使用` golang`开发`httpServer`非常方便，如果我们需要在`c`程序中内嵌`httpServer`，可以考虑使用`go`来开发服务模块，然后编译成共享库供`c`调用\n\n### code by go \n\n##### code\n\n```go\npackage main\n\nimport (\n\t\"net/http\"\n\t\"time\"\n\t\"log\"\n)\n\nimport \"C\" // 需要导入`C`才可以生成`.h`文件\n\n\n// 使用`export`导出函数\n//export ServerRun\nfunc ServerRun(addr string) int {\n\tmux := http.NewServeMux()\n\tmux.HandleFunc(\"/\", func(resp http.ResponseWriter, req *http.Request) {\n\t\tresp.Write([]byte{'H', 'i', '!'})\n\t})\n\tif err := http.ListenAndServe(addr, mux); err != nil {\n\t\tlog.Println(err.Error())\n\t\treturn -1\n\t}\n\treturn 0\n}\n\n// 内部函数也可以导出\n//export wait\nfunc wait() {\n\ttime.Sleep(time.Hour * 1)\n}\n\nfunc main() {}\n```\n\n注意点：\n\n- 需要引入`C`包\n- 需要导出的函数，需要使用`//export funcName`标识\n- 包内函数也可以导出\n\n##### compile\n\n- 动态共享库：运行时动态加载；如果运行时加载失败则报错\n\n  ```sh\n  $ go build -buildmode=c-shared -o libtest.so main.go\n  ```\n\n  编译完成之后将生成`libtest.so`和`libtest.h`文件\n\n- 静态共享库：编译时静态链接到程序中；生成二进制文件较大\n\n  ```sh\n  $ go build -buildmode=c-archive -o test.a main.go\n  ```\n\n  编译完成之后将生成`test.h`和`test.a`文件\n\n\n\n### use in c \n\n##### code \n\n在开始写代码之前，我们要先看一下生成的`test.h`里面的内容：\n\n```c\ntypedef struct { const char *p; ptrdiff_t n; } _GoString_;\ntypedef _GoString_ GoString;\n\ntypedef long long GoInt64;\ntypedef GoInt64 GoInt;\n\nextern GoInt ServerRun(GoString p0);\n\nextern void wait();\n```\n\n`go`中的`string`类型是一个结构体：\n\n```go\ntype string struct {\n    data []byte\n    len int\n}\n```\n\n而`c`中的`string`实际上是`byte[]`，两者的内存布局本身就不一样，因此在`c`中调用`go`的代码时，需要先按照`go`的类型结构构造参数。\n\n```c\n#include<stdio.h>\n#include \"test.h\"\n\nint main(void){\n    // 构造字符串类型\n    char str[5] = {':','8','0','8','0'};\n    GoString addr = {\n        p: str,\n        n: 5\n    };\n\t// 执行 ServerRun\n    if (ServerRun(addr) != 0){\n        printf(\"failed to start server!\");\n        return -1;\n    }\n    return 0;\n}\n```\n\n\n\n##### compile \n\n- 静态共享库\n\n  ```sh\n  $ gcc -pthread -o test main.c test.a \n  ```\n\n  使用静态链接时，需要指定`-pthread`选项 \n\n  > Link with the POSIX threads library.  This option is supported on GNU/Linux targets, most other Unix derivatives, and also on x86 Cygwin and MinGW targets.  On some targets this option also sets flags for the preprocessor, so it should be used consistently for both compilation and linking.\n\n  也可以动态加载`pthread`库\n\n  ```sh\n  $ gcc -lpthread -o test main.c test.a\n  ```\n\n- 动态共享库\n\n  ```sh\n  $ gcc main.c -ltest -L. -o test\n  ```\n\n  - `-l`：声明使用到的动态共享库，比如`libtest.so`，则这里传入`test`\n  - `-L`：在指定路径中查找共享库；也可以将`.so`文件拷贝到默认共享库目录下\n\n\n\n编译之后生成`test`文件，执行`./test`，然后在访问`http://localhost:8080`可以看到返回了`Hi!`内容。\n\n如果使用动态加载，运行前需要先将`libtest.so`文件拷贝到动态加载库默认的加载路径中，或者将当前路径加到`LD_LIBRARY_PATH `环境变量中。\n","tags":["go"]},{"title":"goland 中获取 goid","url":"/2018/08/18/goland-中获取-goid/","content":"\n### introduce\n\n目前网上有很多获取goroutine id的方法，主要分为两种：\n\n- 通过runtime.Stack方法获取栈的信息，而栈信息以`goroutine {goid}` 开头，再通过字符串处理就可以提取出goid\n- go中通过g来表示goroutine，而在tls中保存了当前执行的g的地址。可以通过汇编获取到g的地址，然后加上goid在g中的偏移量就可以获取到goid的值了\n\n第一种方法实现方便，只要通过简单的字符串处理就可以获取到goid，但是性能开销较大；\n\n第二种方法，需要结合汇编来获取当前执行的g的地址，而且需要获取到goid在g中的偏移量；而不同的版本中g的结构都不一样，因此该方法需要为每个版本都提供一种实现\n\n### code\n\n下面将基于go1.10实现上面两种获取goid的方案。\n\n##### 方法一：\n\n```go\n\tstack := make([]byte, 20) //读取前二十个字节\n\truntime.Stack(stack, false)\n\tgoid,_ :=strconv.Atoi(strings.Split(string(stack),\" \")[1])\n```\n\n在上面的实现中，读取栈的前20个字节，其内容为`goroutine 6 ...`，我们这里只需要关注goid在字符串数组第二的位置，然后通过简单的字符串切割和类型转换就可以获取到goid了\n\n##### 方法二：\n\n因为g的定义在runtime.runtime2.go中，我们需要将其拷贝出来\n\n```go\ntype g struct {\n\tstack       stack\n\tstackguard0 uintptr\n    _defer      uintptr\n\t...\n\tgoid           int64\n\t...\n}\n\ntype stack struct {\n\tlo uintptr\n\thi uintptr\n}\n\ntype gobuf struct {\n\tsp   uintptr\n\tpc   uintptr\n\tg    uintptr\n\tctxt unsafe.Pointer\n\tret  uint64\n\tlr   uintptr\n\tbp   uintptr\n}\n```\n\n拷贝的时候，因为g中还引用了其他类型，也需要一起拷贝出来。这里有个小技巧，因为我们只是需要使用g来计算goid的偏移量，因此如果有的字段是指针类型的，那么可以将其换成`uintptr`类型。比如说`_defer`是`*_defer`类型，那么可以将其换成`uintptr`类型，这样我们就不需要在自己的代码中声明`_defer`结构了。\n\n然后，声明全局变量`offset`\n\n```go\nvar offset =unsafe.Offsetof((*g)(nil).goid)\n```\n\n我们通过`unsafe.Offsetof`方法来计算goid在g中的偏移。\n\n接着，在go文件中声明Goid方法的stub\n\n```go\nfunc Goid()int64\n```\n\n并在goid.s中实现该函数\n\n```assembly\nTEXT ·Goid(SB),NOSPLIT,$0-8\n    MOVQ ·offset(SB),AX\t//获取到全局变量offset\n    MOVQ (TLS),BX\t\t//获取当前g的地址\n    ADDQ BX,AX\t\t\t//计算goid的地址\n    MOVQ (AX),BX\t\t//获取goid的值\n    MOVQ BX,ret+0(FP)\n    RET\n\t//最后的空行必须保留，否则编译报错\n```\n\n在上述实现中，我直接在汇编中计算goid在内存中的地址。还有一种实现是在汇编中获取g的地址，然后将其转换成*g类型并获取goid的值，这样就不需要计算offset的值了，但是在实际测试中，前者的执行速度是后者的两倍。\n\n\n\n以上代码可以在[github](https://github.com/ymcvalu/goid)上查看\n\n\n\n","tags":["go","goid"]},{"title":"go自定义类型的序列化过程","url":"/2018/08/13/go自定义类型的序列化过程/","content":"\n\n\n### 问题引入\n当某个struct存在某个字段为string或者[]byte类型但是实际上保存的内容是json格式的数据时，对其进行json序列化，比如\n```go\ntype Message struct {\n\tFrom string     `json:\"from\"`\n\tTo   string     `json:\"to\"`\n\tData string `json:\"data\"`\n}\n\nfunc main() {\n\tmsg := Message{\n\t\tFrom: \"XiaoMing\",\n\t\tTo:   \"LiGang\",\n\t\tData: `{\"title\":\"test\",\"body\":\"something\"}`,\n\t}\n\tjsonData, err := json.Marshal(msg)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tfmt.Println(string(jsonData))\n}\n```\n在上面的例子中，Data字段是string类型，但是保存的内容是json格式的数据，这个时候，程序输出：\n```json\n{\"from\":\"XiaoMing\",\"to\":\"LiGang\",\"data\":\"{\\\"title\\\":\\\"test\\\",\\\"body\\\":\\\"something\\\"}\"}\n```\n可以看到，序列化之后的data是一个字符串。\n如果Message对应的是数据库中的一张表，而data字段在数据库中是json类型，当我们需要一个接口，查询Message表中的记录返回给客户端。如果直接执行序列化，那么客户端获取到的Data实际上是一个字符串，客户端还需要自行对这个字符串进行json反序列化。\n>这时候我们就会想，有没有什么办法能够在服务端序列化Message时，将data字段序列化成json对象而不是字符串呢？\n\n### 自定义序列化\n因为data字段的值本身就是json类型，为什么不能在序列化时直接使用呢？\n查看json包的官方文档，我们可以发现关于 [自定义序列化](https://godoc.org/encoding/json#ex-package--CustomMarshalJSON)的例子\n当执行json序列化时，如果对应的类型实现了`Marshaler`接口：\n```go\ntype Marshaler interface {\n\tMarshalJSON() ([]byte, error)\n}\n```\n那么就会执行其`MarshalJSON`方法，并将返回的字节数组作为该值的序列化值。\n那么回到上面的例子，我们就很容易实现目标：\n```go\ntype JsonString string\n\nfunc (j JsonString) MarshalJSON() ([]byte, error) {\n\tfmt.Println(\"marshal...\")\n\treturn []byte(j), nil\n}\n\ntype Message struct {\n\tFrom string     `json:\"from\"`\n\tTo   string     `json:\"to\"`\n\tData JsonString `json:\"data\"`\n}\n```\n在上面的代码中基于`string`类型声明了`JsonString`，代表json格式的字符串，并实现了Marshaler接口。因为JsonString代表的就是json字符串，直接将其转换成字节数组返回。\n然后将Message中的Data字段换成JsonString类型。\n再次执行程序，可以看到：\n```json\n{\"from\":\"XiaoMing\",\"to\":\"LiGang\",\"data\":{\"title\":\"test\",\"body\":\"something\"}}\n```\n**Perfect!**","tags":["go"]},{"title":"golang中的defer实现","url":"/2018/04/15/golang中的defer实现/","content":"\n\n\n`defer`是go独有的关键字，可以说是go的一大特色。\n\n被`defer`修饰的函数调用，会在函数返回时被执行，因此常常被用于执行锁或者资源释放等。\n\n在每次获得资源时，都紧接`defer`语句对其进行释放，可以防止在后续的操作中忘记释放资源。\n\n在享受其便捷之后，你有没有想过defer机制是如何实现的呢？\n\n首先编写简单的main函数\n\n```go\nfunc main() {\n\tdefer func() {\n\t\tfmt.Println(\"exit\")\n\t}()\n}\n```\n\n使用`go tool compile -N -S main.go > main.s`命令编译查看输出的汇编代码\n\n```assembly\n\"\".main STEXT size=96 args=0x0 locals=0x18\n\tTEXT\t\"\".main(SB), $24-0\n\t...\n\tMOVL\t$0, (SP)\t;deferproc第一个参数0\n\tLEAQ\t\"\".main.func1·f(SB), AX ;匿名函数被编译成main.func1，保存函数地址到AX\n\tMOVQ\tAX, 8(SP) ;deferproc第二个参数为匿名函数地址\n\tPCDATA\t$0, $0\n\tCALL\truntime.deferproc(SB) ;调用defer函数\n\t...\n\tCALL\truntime.deferreturn(SB) ;返回之前执行deferreturn函数\n\tMOVQ\t16(SP), BP\n\tADDQ\t$24, SP\n\tRET\n\t...\n```\n\n根据输出的汇编代码，可以看到defer语句被替换成了调用`runtime.deferproc`方法，查看具体的实现，而在函数返回时执行`runtime.deferreturn`方法\n\n首先分析`runtime.deferproc`方法\n\n```go\n// Create a new deferred function fn with siz bytes of arguments.\n// The compiler turns a defer statement into a call to this.\n//go:nosplit\n//siz表示fn函数的参数总大小\nfunc deferproc(siz int32, fn *funcval) { // arguments of fn follow fn\n    //deferproc不允许在系统栈执行\n\tif getg().m.curg != getg() {\n\t\t// go code on the system stack can't defer\n\t\tthrow(\"defer on system stack\")\n\t}\n\n\t// the arguments of fn are in a perilous state. The stack map\n\t// for deferproc does not describe them. So we can't let garbage\n\t// collection or stack copying trigger until we've copied them out\n\t// to somewhere safe. The memmove below does that.\n\t// Until the copy completes, we can only call nosplit routines.\n\tsp := getcallersp(unsafe.Pointer(&siz))\n    //fn的参数紧跟在fn之后,因此通过简单的指针运算可以获取fn的参数起始地址\n\targp := uintptr(unsafe.Pointer(&fn)) + unsafe.Sizeof(fn)\n    //获取defer语句的pc\n\tcallerpc := getcallerpc()\n\t//获取一个_defer\n\td := newdefer(siz)\n\tif d._panic != nil {\n\t\tthrow(\"deferproc: d.panic != nil after newdefer\")\n\t}\n\td.fn = fn\n\td.pc = callerpc\n\td.sp = sp\n\tswitch siz {\n\tcase 0:\n\t\t// Do nothing.\n\tcase sys.PtrSize:\n\t\t*(*uintptr)(deferArgs(d)) = *(*uintptr)(unsafe.Pointer(argp))\n\tdefault:\n        //deferArgs:分配_defer时,连同参数存储空间一起分配,参数紧跟_defer之后存储,该函数进行指针运算,返回参数的起始地址：\n        //拷贝参数,因此在执行defer语句语义之前,需要先准备好接收者和参数\n\t\tmemmove(deferArgs(d), unsafe.Pointer(argp), uintptr(siz))\n\t}\n\n\t// deferproc returns 0 normally.\n\t// a deferred func that stops a panic\n\t// makes the deferproc return 1.\n\t// the code the compiler generates always\n\t// checks the return value and jumps to the\n\t// end of the function if deferproc returns != 0.\n\treturn0()\n\t// No code can go here - the C return register has\n\t// been set and must not be clobbered.\n}\n```\n\n具体的逻辑已经很清楚了，这里要说明的是：`runtime.deferproc`接受两个参数，需要延时执行的函数fn的地址以及fn的参数总大小，而fn的参数需要紧跟着分配在`&fn`后面。\n\n在函数中我们看到了`_defer`这个类型，该类型是实现`defer`机制的关键，其声明如下：\n\n```go\n// A _defer holds an entry on the list of deferred calls.\n// If you add a field here, add code to clear it in freedefer.\ntype _defer struct {\n\tsiz     int32\t//参数size\n\tstarted bool\t//是否执行过\n\tsp      uintptr // sp at time of defer\n\tpc      uintptr\n\tfn      *funcval //需要延时执行的函数地址\n\t_panic  *_panic // panic that is running defer\n\tlink    *_defer //每个goroutine中的_defer以链表组织\n}\n```\n\n在`runtime.newdefer`方法中，会获取一个_defer结构，**并将其加入当前goroutine的` _defer`队列头部**。\n\n接着看一下`runtime.deferreturn`方法实现\n\n```go\n// Run a deferred function if there is one.\n// The compiler inserts a call to this at the end of any\n// function which calls defer.\n// If there is a deferred function, this will call runtime·jmpdefer,\n// which will jump to the deferred function such that it appears\n// to have been called by the caller of deferreturn at the point\n// just before deferreturn was called. The effect is that deferreturn\n// is called again and again until there are no more deferred functions.\n// Cannot split the stack because we reuse the caller's frame to\n// call the deferred function.\n\n// The single argument isn't actually used - it just has its address\n// taken so it can be matched against pending defers.\n//go:nosplit\nfunc deferreturn(arg0 uintptr) { //这边的arg0只是为了获取当前的sp\n\tgp := getg()\n\td := gp._defer\t//获取_defer链表头部\n    //如果没有_defer,则返回,详见上面注释\n\tif d == nil {\n\t\treturn\n\t}\n    //确保sp前后一致\n\tsp := getcallersp(unsafe.Pointer(&arg0))\n\tif d.sp != sp {\n\t\treturn\n\t}\n\n\t// Moving arguments around.\n\t//\n\t// Everything called after this point must be recursively\n\t// nosplit because the garbage collector won't know the form\n\t// of the arguments until the jmpdefer can flip the PC over to\n\t// fn.\n    //拷贝参数到sp中\n\tswitch d.siz {\n\tcase 0:\n\t\t// Do nothing.\n\tcase sys.PtrSize:\n\t\t*(*uintptr)(unsafe.Pointer(&arg0)) = *(*uintptr)(deferArgs(d))\n\tdefault:\n\t\tmemmove(unsafe.Pointer(&arg0), deferArgs(d), uintptr(d.siz))\n\t}\n\tfn := d.fn\n\td.fn = nil\n\tgp._defer = d.link //从链表中移除\n\tfreedefer(d) //释放当前_defer\n    //call runtime·jmpdefer,\n    // which will jump to the deferred function such that it appears\n    // to have been called by the caller of deferreturn at the point\n    // just before deferreturn was called. The effect is that deferreturn\n    // is called again and again until there are no more deferred fns.\n    //执行fn,并修改pc为 `CALL\truntime.deferreturn(SB)`,下一条指令再次进入该函数,如果gp.defer为nil或者sp不一致,则返回,否则继续执行defer\n    //每次添加defer时,总是添加到head,处理时则是从head开始处理,因此defer的处理顺序是FILO\n\tjmpdefer(fn, uintptr(unsafe.Pointer(&arg0)))\n}\n```\n\n至此，defer语句的运行机制分析完成了，主要理了大概的执行流程，其中还有一些细节由于篇幅有限并没有细说，可以自行分析。\n\ngo中还有一个比较独特的地方，如果程序发生异常，会保证先执行所有defer声明的延时函数，然后才退出程序；而我们可以在延时函数中获取到当前整个堆栈的信息，比如说：\n\n```\n函数A执行defer语句，调用函数B\n函数B函数B发生panic\n执行函数A的延时函数，这时候是可以获取到函数B的栈帧数据的\n```\n\n按照上面的执行流程，在执行函数A的延时函数时，实际上这时候函数B的栈帧还没有弹出，神奇吧？这是因为执行panic时，就会去遍历当前goroutine的`_defer`链表，并依次执行这些延时函数，而不是返回函数A之后再执行函数A的延时函数。\n\n实际的执行流程是这样的：\n\n```\n函数A执行defer语句，调用函数B\n函数B函数B发生panic\n在panic内部，遍历_defer链表，并依次执行延时函数\n如果有延时函数执行了recover，则在延时函数返回后，直接跳转到_defer.pc，而不会执行后续的延时函数\n```\n\n\n\n最后，`defer`函数虽然方便，但是需要有额外的运行开销，在使用时需要进行取舍，尤其是具有多个参数的时候，会发生多次内存拷贝：\n\n```\nruntime.deferproc执行之前：移动到栈中\nruntime.deferproc执行过程中，拷贝_defer之后\nruntime.deferreturn执行时，移动到栈中\n```\n\n\n\n\n\n\n\n","tags":["go","defer"]},{"title":"go程序启动过程分析","url":"/2018/01/07/go程序启动过程分析/","content":"\n\n\n事实上，编译好的可执⾏⽂件真正执⾏时并⾮我们所写的 main.main 函数，因为编译器\n\n总是会插⼊⼀段引导代码，完成诸如命令⾏参数、运⾏时初始化等⼯作，然后才会进⼊⽤\n\n户逻辑。 \n\n程序的入口因平台而异：\n\n    rt0_android_arm.s rt0_dragonfly_amd64.s rt0_linux_amd64.s ...\n    rt0_darwin_386.s rt0_freebsd_386.s rt0_linux_arm.s ...\n    rt0_darwin_amd64.s rt0_freebsd_amd64.s rt0_linux_arm64.s ...\n\nrt0_linux_amd64.s:\n\n    TEXT _rt0_amd64_linux(SB),NOSPLIT,$-8\n       LEAQ   8(SP), SI ; argv\n       MOVQ   0(SP), DI ; argc\n       MOVQ   $main(SB), AX\t\t;move address of main to ax\n       JMP    AX\n       \n       TEXT main(SB),NOSPLIT,$-8\n       MOVQ   $runtime·rt0_go(SB), AX\t;跳转到runtime.rt0.go执行\n       JMP    AX\n\nasm_amd64.s:\n\n    TEXT runtime·rt0_go(SB),NOSPLIT,$0\n    \t// copy arguments forward on an even stack\n    \tMOVQ\tDI, AX\t\t// argc\n    \tMOVQ\tSI, BX\t\t// argv\n    \tSUBQ\t$(4*8+7), SP\t\t// 2args 2auto\n    \tANDQ\t$~15, SP\n    \tMOVQ\tAX, 16(SP)\n    \tMOVQ\tBX, 24(SP)\n       ..\n    ok:\n    \t; set the per-goroutine and per-mach \"registers\"\n    \tget_tls(BX)\n    \tLEAQ\truntime·g0(SB), CX\t;将g0的地址保存到CX\n    \tMOVQ\tCX, g(BX)\t;设置 g(BX)为g0\n    \tLEAQ\truntime·m0(SB), AX\t\n    \n    \t// save m->g0 = g0\n    \tMOVQ\tCX, m_g0(AX)\t;设置m.g0\n    \t// save m0 to g0->m\n    \tMOVQ\tAX, g_m(CX)\t;设置g.m\n        ...\n    \t;调用初始化函数\n    \tMOVL\t16(SP), AX\t\t// copy argc\n    \tMOVL\tAX, 0(SP)\n    \tMOVQ\t24(SP), AX\t\t// copy argv\n    \tMOVQ\tAX, 8(SP)\n    \tCALL\truntime·args(SB)\t\t;\n    \tCALL\truntime·osinit(SB)\t\t;\n    \tCALL\truntime·schedinit(SB)\t;\n    \n    \t// create a new goroutine to start program\n    \tMOVQ\t$runtime·mainPC(SB), AX\t\t// entry\n    \tPUSHQ\tAX\n    \tPUSHQ\t$0\t\t\t// arg size\n    \t;创建一个新的goroutine并加入到等待队列，该goroutine执行runtime.mainPC所指向的函数\n    \tCALL\truntime·newproc(SB)\n    \tPOPQ\tAX\n    \tPOPQ\tAX\n    \n    \t;该函数内部会调用调度程序，从而调度到刚刚创建的goroutine执行\n    \tCALL\truntime·mstart(SB)\n    \n    \tMOVL\t$0xf1, 0xf1  // crash\n    \tRET\n    \n    ;声明全局的变量mainPC为runtime.main函数的地址，该变量为read only\n    DATA\truntime·mainPC+0(SB)/8,$runtime·main(SB)\t\n    GLOBL\truntime·mainPC(SB),RODATA,$8\n\n\n\nruntime1.go:\n\n    func args(c int32, v **byte) {\n    \targc = c\n    \targv = v\n    \tsysargs(c, v)\n    }\n    func sysargs(argc int32, argv **byte) {\n    }\n\nos_windows.go:\n\n    func osinit() {\n        ...\n    \tncpu = getproccount()\t//获取cpu核数\n        ...\n    }\n\n\n\nproc.go:\n```\n    // The bootstrap sequence is:\n    //\n    //\tcall osinit\n    //\tcall schedinit\n    //\tmake & queue new G\n    //\tcall runtime·mstart\n    //\n    // The new G calls runtime·main.\n    func schedinit() {\n    \t// raceinit must be the first call to race detector.\n    \t// In particular, it must be done before mallocinit below calls racemapshadow.\n    \t_g_ := getg()\t//获取的是g0\n    \tif raceenabled {\n    \t\t_g_.racectx, raceprocctx0 = raceinit()\n    \t}\n    \t//最大系统线程数量限制\n    \tsched.maxmcount = 10000\n    \n    \ttracebackinit()\n    \tmoduledataverify()\n      \t//栈、内存分配器和调度器的相关初始化\n    \tstackinit()\n    \tmallocinit()\n    \tmcommoninit(_g_.m)\n      \n    \talginit()       // maps must not be used before this call\n    \tmodulesinit()   // provides activeModules\n    \ttypelinksinit() // uses maps, activeModules\n    \titabsinit()     // uses activeModules\n    \n    \tmsigsave(_g_.m)\n    \tinitSigmask = _g_.m.sigmask\n    \n      \t//处理命令行参数和环境变量\n    \tgoargs()\n    \tgoenvs()\n      \t\n      \t//处理 GODEBUG、GOTRACEBACK 调试相关的环境变量设置\n    \tparsedebugvars()\n      \n      \t//垃圾回收器初始化\n    \tgcinit()\n    \n    \tsched.lastpoll = uint64(nanotime())\n      \t//通过 CPU核心数和GOMAXPROCS环境变量确定P的数量，P用于调度g到m上\n    \tprocs := ncpu\n    \tif n, ok := atoi32(gogetenv(\"GOMAXPROCS\")); ok && n > 0 {\n    \t\tprocs = n\n    \t}\n    \tif procs > _MaxGomaxprocs {\n    \t\tprocs = _MaxGomaxprocs\n    \t}\n    \tif procresize(procs) != nil {\n    \t\tthrow(\"unknown runnable goroutine during bootstrap\")\n    \t}\n    \n    \tif buildVersion == \"\" {\n    \t\t// Condition should never trigger. This code just serves\n    \t\t// to ensure runtime·buildVersion is kept in the resulting binary.\n    \t\tbuildVersion = \"unknown\"\n    \t}\n    }\n```\n\n```\n    // Called to start an M.\n    //go:nosplit\n    func mstart() {\n    \t....\n    \tmstart1()\n    }\n```\n```\n    func mstart1() {\n         ...\n      \t//调度goroutine\n    \tschedule()\n    }\n\n```\n    // The main goroutine.\n    func main() {\n    \tg := getg()\t//当前获取的g是刚刚在rt0_go内创建的goroutine\n    \n    \t// Racectx of m0->g0 is used only as the parent of the main goroutine.\n    \t// It must not be used for anything else.\n    \tg.m.g0.racectx = 0\n    \n    \t// Max stack size is 1 GB on 64-bit, 250 MB on 32-bit.\n    \t// Using decimal instead of binary GB and MB because\n    \t// they look nicer in the stack overflow failure message.\n      \t//执行栈最大限制：1GB on 64-bit，250MB on 32-bit\n    \tif sys.PtrSize == 8 {\t//64-bit下指针长度是8个字节\n    \t\tmaxstacksize = 1000000000\n    \t} else {\n    \t\tmaxstacksize = 250000000\n    \t}\n    \n    \t// Allow newproc to start new Ms.\n    \tmainStarted = true\n    \n      \t//启动系统后台监控（定期垃圾回收以及并发任务的调度等）\n    \tsystemstack(func() {\n    \t\tnewm(sysmon, nil)\n    \t})\n    \n    \t// Lock the main goroutine onto this, the main OS thread,\n    \t// during initialization. Most programs won't care, but a few\n    \t// do require certain calls to be made by the main thread.\n    \t// Those can arrange for main.main to run in the main thread\n    \t// by calling runtime.LockOSThread during initialization\n    \t// to preserve the lock.\n    \tlockOSThread()\n    \n    \tif g.m != &m0 {\n    \t\tthrow(\"runtime.main not on m0\")\n    \t}\n    \n      \t//执行runtime包内的所有初始化函数 init\n    \truntime_init() // must be before defer\n    \tif nanotime() == 0 {\n    \t\tthrow(\"nanotime returning zero\")\n    \t}\n    \n    \t// Defer unlock so that runtime.Goexit during init does the unlock too.\n    \tneedUnlock := true\n    \tdefer func() {\n    \t\tif needUnlock {\n    \t\t\tunlockOSThread()\n    \t\t}\n    \t}()\n    \n    \t// Record when the world started. Must be after runtime_init\n    \t// because nanotime on some platforms depends on startNano.\n    \truntimeInitTime = nanotime()\n    \n      \t//启动垃圾回收器的后台操作\n    \tgcenable()\n    \n    \tmain_init_done = make(chan bool)\n    \n      \t//执行用户包（包括标准库）的初始化函数 init，程序所有的包的init函数都会在这个函数内被全部执行\n    \tfn := main_init // make an indirect call, as the linker doesn't know the address of the main package when laying down the runtime\n    \tfn()\n    \tclose(main_init_done\n    \tneedUnlock = false\n    \tunlockOSThread()\n    \n      \t//执行用户逻辑入口 main.main 函数\n    \tfn = main_main // make an indirect call, as the linker doesn't know the address of the main package when laying down the runtime\n    \tfn()\n       ...\n      \t//执行结束，程序正常退出\n    \texit(0)\n    }\n \n\n### 总结\n\n• 所有 init 函数都在同⼀个 goroutine 内执⾏\n\n• 所有 init 函数结束后才会执⾏ main.main 函数 \n\n### 参考\n\n- 雨痕的 Go 1.5源码剖析","tags":["go"]},{"title":"libtask分析","url":"/2017/12/29/libtask分析/","content":"\n\n\n`libtask` 是一个开源的 `C` 语言协程库。\n\n`C` 语言协程可以通过更改寄存器，切换协程上下文实现协程调度。\n\n更改寄存器可以通过 `C` 语言内联汇编实现，通过汇编代码直接更改寄存器的内容。\n\n也可以使用 `ucontext` 配合 `getContext` 、 `setContext` 、`makeContext` 、`swapContext` 函数来实现。\n\n`ucontext` 结构封装了寄存器信息和栈信息，是协程执行的上下文，而其他四个函数分别用于获取当前执行的上下文，设置当前上下文，创建上下文和交换上下文，这些函数已经封装了对寄存器内容的交换工作。\n\n##### Task\n\n一个Task可以看成是一个需要异步执行的任务，coroutine的抽象描述。\n\n```c\ntypedef struct Context Context;\t\nstruct Context\n{\n\tucontext_t\tuc;\t//ucontext封装了协程执行的上下文信息\n};\nstruct Task\n{\n\tchar\tname[256];\t// offset known to acid\n\tchar\tstate[256];\n\tTask\t*next;\n\tTask\t*prev;\n\tTask\t*allnext;\n\tTask\t*allprev;\n\tContext\tcontext;\t//协程上下文\n\tuvlong\talarmtime;\n\tuint\tid;\n\tuchar\t*stk;\t//协程栈指针\n\tuint\tstksize;\t//栈大小\n\tint\texiting;\n\tint\talltaskslot;\t//在全局task数组内的index\n\tint\tsystem;\n\tint\tready;\n\tvoid\t(*startfn)(void*);\t//Task需要执行的函数\n\tvoid\t*startarg;\t//startfn 的参数\n\tvoid\t*udata;\n};\n```\n\n##### Task创建\n\n```c\nint taskcreate(void (*fn)(void*), void *arg, uint stack){\n\tint id;\n\tTask *t;\n\n\tt = taskalloc(fn, arg, stack);\t//分配task和stack的空间\n\ttaskcount++;\t\n\tid = t->id;\n  //判断数组是否还有足够空间\n\tif(nalltask%64 == 0){\n      //扩展数组\n\t\talltask = realloc(alltask, (nalltask+64)*sizeof(alltask[0]));\n\t\tif(alltask == nil){\n\t\t\tfprint(2, \"out of memory\\n\");\n\t\t\tabort();\n\t\t}\n\t}\n  \t//保存Task在alltask数组内的index\n\tt->alltaskslot = nalltask;\n\talltask[nalltask++] = t;\t//保存task到alltask数组\n\ttaskready(t);\t//设置为ready，可以被调度执行\n\treturn id;\n}\n\n//taskalloc分配task和stack的空间\nstatic Task* taskalloc(void (*fn)(void*), void *arg, uint stack){\n\tTask *t;\n\tsigset_t zero;\n\tuint x, y;\n\tulong z;\n\n\t/* allocate the task and stack together */\n\tt = malloc(sizeof *t+stack);\t//分配内存，stack紧跟在task之后\n\tif(t == nil){\n\t\tfprint(2, \"taskalloc malloc: %r\\n\");\n\t\tabort();\n\t}\n  \t//清除task的内存\n\tmemset(t, 0, sizeof *t);\n\tt->stk = (uchar*)(t+1);\t//设置stack指针，stack紧跟task之后，t+1指针偏移一个Task大小\n\tt->stksize = stack;\t//设置stack大小\n\tt->id = ++taskidgen;\t//设置id\n\tt->startfn = fn;\t//设置任务需要执行的函数\n\tt->startarg = arg;\t//startfn的参数\n\n\t/* do a reasonable initialization */\n\tmemset(&t->context.uc, 0, sizeof t->context.uc);\n\tsigemptyset(&zero);\n\tsigprocmask(SIG_BLOCK, &zero, &t->context.uc.uc_sigmask);\n\n\t/* must initialize with current context */\n\tif(getcontext(&t->context.uc) < 0){\t//获取当前ucontext，并保存到t->context.uc\n\t\tfprint(2, \"getcontext: %r\\n\");\n\t\tabort();\n\t}\n\n\t/* call makecontext to do the real work. */\n\t/* leave a few words open on both ends */\n  \t//设置栈顶指针和栈大小，两端都保留一点空间\n\tt->context.uc.uc_stack.ss_sp = t->stk+8;\t\n\tt->context.uc.uc_stack.ss_size = t->stksize-64;\n#if defined(__sun__) && !defined(__MAKECONTEXT_V2_SOURCE)\t\t/* sigh */\n#warning \"doing sun thing\"\n\t/* can avoid this with __MAKECONTEXT_V2_SOURCE but only on SunOS 5.9 */\n\tt->context.uc.uc_stack.ss_sp = \n\t\t(char*)t->context.uc.uc_stack.ss_sp\n\t\t+t->context.uc.uc_stack.ss_size;\n#endif\n\t/*\n\t * All this magic is because you have to pass makecontext a\n\t * function that takes some number of word-sized variables,\n\t * and on 64-bit machines pointers are bigger than words.\n\t */\n//print(\"make %p\\n\", t);\n  //计算startfn的参数:y,x\n  /**\n  taskstart的参数是uint，即32位，而指针如果是64位，则需要将指针的高32位和低32位分离，分别传递\n  将指针分离为高32位(x)和低32位(y)，在taskstart内再通过两个参数合成task指针\n  该方法可以同时适用于32位和64位的编译器\n  **/\n\tz = (ulong)t;\n\ty = z;\n\tz >>= 16;\t/* hide undefined 32-bit shift from 32-bit compilers */\n\tx = z>>16;\n  //这里传入的是taskstart函数，在该函数内执调用t->startfn，并传入t->startarg\n\tmakecontext(&t->context.uc, (void(*)())taskstart, 2, y, x);\n\n\treturn t;\n}\n\n/**\n初始化uc_context，set the context of coroutine\n**/\n#ifdef NEEDAMD64MAKECONTEXT\nvoid\nmakecontext(ucontext_t *ucp, void (*func)(void), int argc, ...)\n{\n\tlong *sp;\n\tva_list va;\t//用于遍历可变长参数的指针\n\n\tmemset(&ucp->uc_mcontext, 0, sizeof ucp->uc_mcontext);\n\tif(argc != 2)\n\t\t*(int*)0 = 0;\t//报错\n\tva_start(va, argc);\t//遍历可变参数\n\t//前6个参数可以使用寄存器（%rdi，%rsi，%rdx，%rcx，%r8，%r9）保存，后面参数入栈\n\t//用于传递函数参数，rdi：第一个参数，rsi：第二个参数；调用func时传入rdi和rsi\n\tucp->uc_mcontext.mc_rdi = va_arg(va, int);\n\tucp->uc_mcontext.mc_rsi = va_arg(va, int);\n\tva_end(va);\n\t/**设置栈指针**/\n\tsp = (long*)ucp->uc_stack.ss_sp+ucp->uc_stack.ss_size/sizeof(long);\t//移动sp指针\n\tsp -= argc;\t\n\tsp = (void*)((uintptr_t)sp - (uintptr_t)sp%16);\t/* 16-align for OS X */ //地址对齐\n\t*--sp = 0;\t/* return address */\n\tucp->uc_mcontext.mc_rip = (long)func;\t//ip，rip存放下一条指令地址\n\tucp->uc_mcontext.mc_rsp = (long)sp;\t//栈顶指针\n}\n#endif\n\nstatic void\ntaskstart(uint y, uint x)\n{\n\tTask *t;\n\tulong z;\n\t// t = (x<<32)|y\n\tz = x<<16;\t/* hide undefined 32-bit shift from 32-bit compilers */\n\tz <<= 16;\n\tz |= y;\n\tt = (Task*)z;\t//获取task地址\n\n//print(\"taskstart %p\\n\", t);\n\tt->startfn(t->startarg);\t//调用startfn\n//print(\"taskexits %p\\n\", t);\n\ttaskexit(0);\t//startfn结束，设置退出标志位\n//print(\"not reacehd\\n\");\n}\n```\n\n### Task调度\n\n```c\ntypedef struct Tasklist Tasklist;\nstruct Tasklist\t/* used internally */\n{\n\tTask\t*head;\n\tTask\t*tail;\n};\n```\n\n```c\nContext\ttaskschedcontext;\t\nTasklist\ttaskrunqueue;\nTask\t*taskrunning;\n\nvoid\nneedstack(int n)\n{\n\tTask *t;\n\n\tt = taskrunning;\n\n\tif((char*)&t <= (char*)t->stk\n\t|| (char*)&t - (char*)t->stk < 256+n){\n\t\tfprint(2, \"task stack overflow: &t=%p tstk=%p n=%d\\n\", &t, t->stk, 256+n);\n\t\tabort();\n\t}\n}\n\nvoid\ntaskswitch(void)\n{\n\tneedstack(0);\n\tcontextswitch(&taskrunning->context, &taskschedcontext);\n}\n\nint\nswapcontext(ucontext_t *oucp, const ucontext_t *ucp)\n{\n\tif(getcontext(oucp) == 0)\t//get the context into *oucp\n\t\tsetcontext(ucp);\t//set the context as *ucp\n\treturn 0;\n}\n\nvoid\ntaskready(Task *t)\n{\n\tt->ready = 1;\n\taddtask(&taskrunqueue, t);\t//加入调度队列\n}\n\nint\ntaskyield(void)\n{\n\tint n;\n\t\n\tn = tasknswitch;\n\ttaskready(taskrunning);\t//将当前task加入等待队列\n\ttaskstate(\"yield\");\n\ttaskswitch();\t//切换\n\treturn tasknswitch - n - 1;\n}\n\nint\nanyready(void)\n{\n\treturn taskrunqueue.head != nil;\t//判断等待队列队首是否为空\n}\n\nvoid\ntaskexit(int val)\n{\n\ttaskexitval = val;\n\ttaskrunning->exiting = 1;\n\ttaskswitch();\t//切换上下文，执行调度程序\n}\n\n\nstatic void\ntaskscheduler(void)\n{\n\tint i;\n\tTask *t;\n\n\ttaskdebug(\"scheduler enter\");\n\tfor(;;){\n\t\tif(taskcount == 0)\n\t\t\texit(taskexitval);\n\t\tt = taskrunqueue.head;\n\t\tif(t == nil){\n\t\t\tfprint(2, \"no runnable tasks! %d tasks stalled\\n\", taskcount);\n\t\t\texit(1);\n\t\t}\n\t\tdeltask(&taskrunqueue, t);\n\t\tt->ready = 0;\n\t\ttaskrunning = t;\t//设置taskrunning\n\t\ttasknswitch++;\n\t\ttaskdebug(\"run %d (%s)\", t->id, t->name);\n      //当前context保存到taskschedcontext，即taskschedcontext为调度上下文\n\t\tcontextswitch(&taskschedcontext, &t->context);\t//交换 task context\n//print(\"back in scheduler\\n\");\n\t\ttaskrunning = nil;\n\t\tif(t->exiting){\t//如果退出\n\t\t\tif(!t->system)\n\t\t\t\ttaskcount--;\n\t\t\ti = t->alltaskslot;\n\t\t\talltask[i] = alltask[--nalltask];\t//替换为全局数组的最后一个task\n\t\t\talltask[i]->alltaskslot = i;\n\t\t\tfree(t);\t//释放task\n\t\t}\n\t}\n}\n\n/*\n * startup\n */\n\nstatic int taskargc;\nstatic char **taskargv;\nint mainstacksize;\n\nstatic void\ntaskmainstart(void *v)\n{\n\ttaskname(\"taskmain\");\n\ttaskmain(taskargc, taskargv);\n}\n\nint\nmain(int argc, char **argv)\n{\n\tstruct sigaction sa, osa;\n\n\tmemset(&sa, 0, sizeof sa);\n\tsa.sa_handler = taskinfo;\n\tsa.sa_flags = SA_RESTART;\n\tsigaction(SIGQUIT, &sa, &osa);\n\n#ifdef SIGINFO\n\tsigaction(SIGINFO, &sa, &osa);\n#endif\n\n\targv0 = argv[0];\n\ttaskargc = argc;\n\ttaskargv = argv;\n\n\tif(mainstacksize == 0)\n\t\tmainstacksize = 256*1024;\n\ttaskcreate(taskmainstart, nil, mainstacksize);\n\ttaskscheduler();\n\tfprint(2, \"taskscheduler returned in main!\\n\");\n\tabort();\n\treturn 0;\n}\n```\n","tags":["libtask"]},{"title":"kotlin函数初级入门","url":"/2017/12/11/kotlin函数初级入门/","content":"\n\n\n### 普通函数声明\n使用 `func` 关键字声明一个函数，像这样\n\n```kotlin\nfun add(a:Int,b:Int):Int{\n    return a+b\n}\n```\n**在`kotlin`中，所有函数的参数都是`val`的，即不可变参数**\n如果函数体只有一行代码，可以简洁点：\n```kotlin\nfun add(a: Int, b: Int): Int = a + b\n```\n更简单点，返回值自动推断：\n```kotlin\nfun add(a: Int, b: Int) = a + b\n```\n###带默认值的函数\n可以在声明函数参数的时候，直接指定默认值，如果调用时没有传入，将使用默认值，带有默认值的参数可以在任何位置\n```kotlin\nfun add(a: Int=1, b: Int) = a + b\n```\n调用的时候，可以使用`参数名=值`的形式给出参数\n```kotlin\nadd(b=1)\n```\n换个位置声明默认值：\n```kotlin\nfun add(a: Int , b: Int=1) = a + b\nfun adds (a:Int,b:Int=1,c:Int)= a+b+c\nfun main(vararg args:String){\n    add(1)    //自动匹配第一个参数\n    adds (1,c=2)    //默认值之后的参数需要显示指出参数名\n}\n```\n函数匹配优先级：\n```kotlin\nfun add(a:Int) = a*a\nfun add(a: Int , b: Int=1) = a + b\nfun main(vararg args:String){\n   println(add(3))  //输出 9 \n}\n```\n当有多个函数匹配时，带默认值参数个数少的优先级越高，不带默认值的优先级最高\n\n### 可变参数\n在`kotlin`中，使用 `vararg` 关键字来标识可变参数\n和`java`一样，多个参数会被封装成数组赋值给a\n\n```kotlin\nfun add(vararg a: Int, b: Int):Int{\n    var sum :Int = 0\n    a.forEach { \n        sum+=it\n    }\n    return sum+b\n}\n```\n和`java`不同的是，在java中我们可以直接将一个数组赋值给可变参数，这有时候会引起混淆，因此在kotlin中，我们需要显示使用运算符`*`将数组解构成元素\n比如我们可以这样调用上面的方法：\n```kotlin\nfun main(vararg args: String) {\n    var arr = IntArray(10) { it }\n    add(*arr, b = 1)\n}\n```\n注意，第二个参数我们需要明确指出他的参数名，否则他会被当作可变参数中的一个值\n\n### 使用lambda\n`lambda`是一种特殊的函数。和传统函数不同的是，他可以被存储，传递，并且可以捕获外部变量形成闭包。\n#####`lambda`的类型\n因为`lambda`本质上还是对象，因此他是有类型的。\n `lambda`的类型格式为：\n\n```kotlin\n(参数列表)->返回值类型\n```\n`lambda`的`body`结构为：\n```kotlin\n{形参列表->\n  语句\n  ...\n  最后一个语句的值为返回值（如果需要返回值）\n}\n```\n比如：\n```kotlin\nval max:(Int,Int)->Int = {a,b -> if (a>b) a else b}\n```\n`max`用于比较两个整数，并返回他们中的最大者。因为这边接收了两个参数，因此我们需要在`lambda`的`body`中显示的为这两个参数指定一个名字，就像我们需要为函数指定形参名。\n上面的例子也可以这样写：\n```kotlin\nval max =  { a:Int,b:Int-> if (a>b) a else b}  as (Int,Int)->Unit\n```\n不过这是比较2b的写法了，使用`as`对`lambda`进行类型转换，然后`max`的类型自动推出，这里我只是想说明`lambda`本质上还是个对象，因此一样可以进行类型转换。\n\n### 高阶函数\n`lambda`可以作为函数的参数或者返回值，举个例子：\n\n```kotlin\nfun <T> forEach(list:List<T>,block:(t:T)->Unit){\n    for (t in list){\n        block(t)\n    }\n}\n\nfun main(vararg args:String){\n    var list = listOf(1,2,3,4,5)\n    forEach(list){\n        println(it)\n    }\n}\n```\n在上面的例子中，我们声明了一个`forEach`的函数，他的功能是遍历一个列表，并对列表中的每个元素调用指定的`lambda`，然后我们在`main`函数中调用它。\n值得注意的是，这里当我们的`lambda`是函数的最后一个参数时，我们可以将其写在`()`外面，当函数参数只有一个`lambda`时，可以直接省略`()`；\n还有第二个要注意的是，我们使用了匿名参数，当`lambda`只有一个参数时，我们可以不用显示的指定一个参数名，而是使用默认的`it`来引用。\n\n### 扩展函数\n在`kotlin`中，我们可以很方便的扩展某个类，为其增加方法：\n\n```kotlin\nfun Int.compareWith(a: Int): Int {\n    return when {\n        this > a -> 1\n        this < a -> -1\n        else -> 0\n    }\n}\n\nfun main(vararg args: String) {\n    println(10.compareWith(4))\n}\n```\n如上所示，声明一个扩展函数的语法很简单，只需要在方法名前面加上`类名.`，在方法中我们可以使用`this`来引用他，但是只能访问`public`的成员。这个`类名`我们使用`receiver`来描述它。\n扩展函数只是`kotlin`中众多语法糖中的一个，他并没有真正的扩展这个类，只是将方法的一个参数提到了方法名前面作为`receiver`：\n```kotlin\nfun Int.compareWith(a:Int):Int\n===>\nfun compareWith(this:Int,a:Int):Int  \n```\n所以调用扩展函数和普通的函数调用没有区别，函数的`receiver`本质上还是这个函数的参数，而不是这个方法的所有者，因此在调用时使用的是静态分派，并不支持多态。\n而且当扩展函数与类的方法冲突时，默认使用的是类的方法。\n\n##### 结合泛型的扩展函数\n\n```kotlin\nfun <T:Any> T?.toStr(){\n    println(this?.toString()?:\"this is a null ref\")\n}\nfun main(vararg args:String){\n    null.toStr()\n}\n```\n正如上面的例子中所看到的，我们可以使用泛型参数作为函数的`receiver`，而且我们使用了`T?`，说明支持`null`\n\n##### 函数参数使用扩展函数\n对刚刚的`forEach`函数稍加改造：\n\n```kotlin\nfun <T> forEach(list:List<T>,block:T.()->Unit){\n    for (t in list){\n       t.block()\n    }\n}\n\nfun main(vararg args:String){\n    var list = listOf(1,2,3,4,5)\n    forEach(list){\n        println(this)\n    }\n}\n```\n注意在声明函数参数时，我们使用了`T.()->Unit`，也就是声明了一个具有`receiver`的`lambda`\n\n ","tags":["kotlin"]},{"title":"使用kotlin自定义生成器","url":"/2017/12/02/使用kotlin自定义生成器/","content":"\n使用kotlin的coroutine机制，可以很容易实现一个generator\n\n```kotlin\nimport java.util.concurrent.atomic.AtomicReference\nimport kotlin.coroutines.experimental.*\n\n\nclass Generater<T : Any> private constructor() {\n    private var mContinuation: AtomicReference<Continuation<Unit>?> = AtomicReference(null)\n    private val values: ThreadLocal<T?> = ThreadLocal()\n    /**\n     * -1:结束\n     *  0:未开始\n     *  1:开始\n     */\n    @Volatile\n    private var status: Int = 0\n\n    companion object {\n        fun <T : Any> build(block: suspend Generater<T>.() -> Unit): Generater<T> {\n            val g = Generater<T>()\n            var c = object : Continuation<Unit> {\n                override val context: CoroutineContext\n                    get() = EmptyCoroutineContext\n\n                override fun resume(value: Unit) {\n                    g.status = -1\n                }\n\n                override fun resumeWithException(exception: Throwable) {\n                    g.status = -1\n                    throw exception\n                }\n            }\n            g.mContinuation.compareAndSet(null, block.createCoroutine(g, c))\n            g.status = 1\n            return g\n        }\n    }\n\n    suspend fun yield(t: T?) {\n        suspendCoroutine<Unit> {\n            values.set(t)\n            mContinuation.compareAndSet(null, it)\n            //Thread.sleep(100)\n        }\n    }\n\n    fun next(): T? {\n        while (true) {\n            if (status == -1) {\n                values.set(null)\n                break\n            }\n          \t//可以提到循环外面\n            if (status == 0) {\n                throw IllegalStateException(\"生成器未启动\")\n            }\n            val c = mContinuation.getAndSet(null)\n            c ?: continue\n\n            synchronized(this) {\n                c.resume(Unit)\n            }\n            break\n        }\n        return values.get()\n    }\n\n}\n```\n\n使用\n\n```kotlin\n\nfun main(vararg args: String) {\n\t//声明生成器\n    var g = Generater.build {\n        yield(0L)\n        var i = 0L\n        var j = 1L\n        while (true) {\n            yield(j)\n            var next = i + j\n            i = j\n            j = next\n        }\n    }\n\t//多线程访问\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n}\n```\n\n","tags":["kotlin","coroutine","generator"]},{"title":"使用kotlin协程机制撸一个简易的异步执行库","url":"/2017/11/10/使用kotlin协程机制撸一个简易的异步执行库/","content":"\n\n\n> 由于android限制了只能在UI线程更新视图，而在UI线程中做耗时任务又会导致ANR，因此在平时的开发中，需要将耗时的数据请求工作放到子线程中执行，而视图更新工作放到UI线程中，使用传统的handler或者asyncTask，需要将逻辑分到多个函数内\n\n**使用`kotlin`的协程机制，可以用同步的方式实现异步**\nkotlin的协程机制是基于状态机模型和`C-P-S`风格实现的。\n一个协程通过`resume`启动，当协程内部调用`supended`函数时，协程会被暂停，通过调用 `resume`可以再次启动协程。每次暂停都会修改协程的状态，再次启动协程时，会从新的状态处开始执行。\n\n现在通过kotlin的基础api实现一个简单的异步调用接口，最后的效果如下：\n\n ```\n btn.setOnClickListener {\n            runOnUI {  \n                //执行在主线程，可以做一些初始化操作                         \n                Log.e(\"log\", Thread.currentThread().name)\n                var used = async {               //从工作线程直接返回数据到主线程\n                   //切换到工作线程执行，而且lambda可以直接访问外部变量，构成闭包\n                    Log.e(\"log\", Thread.currentThread().name)\n                    var start = System.currentTimeMillis()\n                    Thread.sleep(3000)\n                    System.currentTimeMillis() - start\n                }\n                //继续执行在主线程\n                Log.e(\"log\", Thread.currentThread().name)\n                Toast.makeText(this@MainActivity, \"后台线程用时${used}ms\", Toast.LENGTH_SHORT).show()\n            }\n        }\n ```\n>在后续的内容中，我将在实现的过程中逐步分析kotlin协程机制的基本原理\n\n首先声明一个创建协程的函数：\n```\n//该函数接收一个 suspend类型的lambda\ninline fun runOnUI(noinline block: suspend () -> Unit) {\n    var continuation = object : Continuation<Unit> {\n      //ThreadSwitcher是ContinuationInterceptor的子类，用于在协程resume时切换到主线程执行\n        override val context: CoroutineContext\n            get() = ThreadSwitcher()  \n\n        override inline fun resume(value: Unit) = Unit\n\n        override inline fun resumeWithException(exception: Throwable) = Unit\n    }\n        //使用suspend类型的lambda创建一个协程并启动\n        block.createCoroutine(continuation).resume(Unit)\n}\n```\n`createCoroutine`是官方提供的一个基础api，该函数如下：\n```\npublic fun <T> (suspend () -> T).createCoroutine(\n        completion: Continuation<T>\n): Continuation<Unit> = SafeContinuation(createCoroutineUnchecked(completion), COROUTINE_SUSPENDED)\n```\n可以看到调用了`createCoroutineUnchecked`创建一个`Coroutine`，继续查看该方法：\n```\n@SinceKotlin(\"1.1\")\n@kotlin.jvm.JvmVersion\npublic fun <T> (suspend () -> T).createCoroutineUnchecked(\n        completion: Continuation<T>\n): Continuation<Unit> =\n//这里的this是执行createCoroutine函数的block\n        if (this !is kotlin.coroutines.experimental.jvm.internal.CoroutineImpl)\n            buildContinuationByInvokeCall(completion) {\n                @Suppress(\"UNCHECKED_CAST\")\n                (this as Function1<Continuation<T>, Any?>).invoke(completion)\n            }\n        else\n//编译时，block会被编译成一个CoroutineImpl的子类，所以走这个分支\n            (this.create(completion) as kotlin.coroutines.experimental.jvm.internal.CoroutineImpl).facade\n```\n查看编译之后生成的`block`：\n```\n//查看在Activity#onCreate调用runOnUI处传入的lambda的编译类\nfinal class ymc/demo/com/asyncframe/MainActivity$onCreate$1$1 \n          extends kotlin/coroutines/experimental/jvm/internal/CoroutineImpl   \n          implements kotlin/jvm/functions/Function1  {      //lambda编译类都实现FunctionN函数\n  ...\n}\n```\n可以看到传入`runOnUI`的`lambda`确实被编译成了一个`CoroutineImpl`，这是因为编译器推断出了这个`lambda`是`suspend`类型的。\n\n继续上面的分析，创建协程所涉及到的两个方法中都出现了 `Continuation`这个类，那么这个类是干嘛的呢？\n首先，先看看`completion`，这个是我们调用`createCoroutine`手动传入的，当协程结束时，他的`resume`会被调用，当协程异常结束时，他的`resumeWithException`会被调用。\n再看看`createCoroutineUnchecked`，这个函数也返回了一个`Continuation`，那么这个又是什么呢？\n```\n (this.create(completion) as kotlin.coroutines.experimental.jvm.internal.CoroutineImpl).facade\n```\n可以看到，返回的是`CoroutineImpl`的`facade`，那这个又是什么呢？\n我们进入`CoroutineImpl`，可以看到\n```\nabstract class CoroutineImpl(\n        arity: Int,\n        @JvmField\n        protected var completion: Continuation<Any?>?\n) : Lambda(arity), Continuation<Any?> {     //Coroutine本身是一个Continuation\n\n  override val context: CoroutineContext\n          get() = _context!!\n\n  private var _facade: Continuation<Any?>? = null\n \n  val facade: Continuation<Any?> get() {\n          if (_facade == null) _facade = interceptContinuationIfNeeded(_context!!, this)\n          return _facade!!\n      }\n  ...\n}\n```\n原来这是一个代理属性，接着查看`interceptContinuationIfNeeded`，\n```\ninternal fun <T> interceptContinuationIfNeeded(\n        context: CoroutineContext,\n        continuation: Continuation<T>\n) = context[ContinuationInterceptor]?.interceptContinuation(continuation) ?: continuation\n```\n这个函数从`Coroutine`的上下文中查找`ContinuationInterceptor`，如果有就调用他的`interceptContinuation`对传入的`continuation`进行包装，否则直接返回传入的`continuation`\n\n**`Continuation`**是一个可**继续执行**体的抽象，每个`Coroutine`都是一个可继续执行体，`Continuation`是一个协程对外的接口，启动/恢复协程的`resume`就是在该接口中定义的。\n协程可以是链式连接的，一个协程可以有子协程，子协程持有父协程的引用，当子协程执行时，父协程暂停，子协程结束时，内部通过调用父协程的`resume`返回父协程。\n\n还记得我们前面用到的`ThreadSwitcher`吗，他就是一个`ContinuationInterceptor`\n我们来看看来看`ThreadSwitcher`的实现：\n```\n/**\nInterceptor用于用于拦截并包装Continuation，让我们有机会在协程resume前做一些额外的操作，比如线程切换\n**/\nclass ThreadSwitcher : ContinuationInterceptor, AbstractCoroutineContextElement(ContinuationInterceptor.Key) {\n\n    override fun <T> interceptContinuation(continuation: Continuation<T>): Continuation<T>\n            = object : Continuation<T> by continuation {\n\n        override fun resume(value: T) {\n          //如果在主线程，直接执行\n            if (Looper.getMainLooper() === Looper.myLooper()) {\n                continuation.resume(value)\n            } else {\n            //否则，使用handler机制post到主线程执行\n                postman.post {\n                    resume(value)\n                }\n            }\n        }\n\n        override fun resumeWithException(exception: Throwable) {\n            if (Looper.getMainLooper() === Looper.myLooper()) {\n                continuation.resumeWithException(exception)\n            } else {\n                postman.post {\n                    resumeWithException(exception)\n                }\n            }\n        }\n    }\n}\n```\n从上面的分析中，我们可以想象，我们创建的协程会被`ThreadSwitcher`包装，\n```\nblock.createCoroutine(continuation).resume(Unit)\n```\n`createCoroutine`返回的实际是`ThreadSwitcher`返回的`Continuation`，所以当我们执行`resume`启动协程时，会先切换到主线程执行。\n\n紧接着，我们来实现`async`：\n```\nsuspend inline fun <T> async(crossinline block: () -> T): T\n        = suspendCoroutine {\n//dispatcher是一个对线程池的封装，将任务分发到子线程中\n    dispatcher.dispatch {\n        it.resume(block())\n    }\n}\n```\n使用`suspend`修饰的方法只可以在协程内部调用，而`suspendCoroutine`方法是`kotlin`提供的一个基础api,用于实现暂停协程。\n我们接着来分析`suspendCoroutine`，查看他的实现：\n```\npublic inline suspend fun <T> suspendCoroutine(crossinline block: (Continuation<T>) -> Unit): T =\n        suspendCoroutineOrReturn { c: Continuation<T> ->\n            val safe = SafeContinuation(c)\n            block(safe)\n            safe.getResult()\n        }\n```\n可以看到这个方法接收的`block`是带`Continuation`参数的\n真正实现功能的是`suspendCoroutineOrReturn`，当我们继续跟进时，发现：\n```\npublic inline suspend fun <T> suspendCoroutineOrReturn(crossinline block: (Continuation<T>) -> Any?): T =\n        throw NotImplementedError(\"Implementation is intrinsic\")\n```\nwhat!直接抛出异常了???\n这是因为这是一个特殊的函数，需要编译器特殊处理，他需要将当前协程内的`_facade`属性，包装成`SafeContinuation`，再作为我们传入的`block`的参数，而且这个`_facade`是经过`ContinuationInterceptor`处理过的，也就是说当我们调用`resume`恢复线程时，会先切换到主线程。\n为了验证上面的分析，我们查看`async`编译之后的字节码：\n```\n//可以看到编译之后，我们的async多了一个Continuation类型的参数\n private final static async(Lkotlin/jvm/functions/Function0;Lkotlin/coroutines/experimental/Continuation;)Ljava/lang/Object;\n   L0\n    LINENUMBER 70 L0\n    NOP\n   L1\n    LINENUMBER 77 L1\n    ICONST_0\n    INVOKESTATIC kotlin/jvm/internal/InlineMarker.mark (I)V\n    ALOAD 1  //将第二个参数，也就是Continuation入栈\n//调用CoroutineIntrinsics.normalizeContinuation \n    INVOKESTATIC kotlin/coroutines/experimental/jvm/internal/CoroutineIntrinsics.normalizeContinuation (Lkotlin/coroutines/experimental/Continuation;)Lkotlin/coroutines/experimental/Continuation;  \n//将返回值存到slot3\n    ASTORE 3\n   L2\n    LINENUMBER 78 L2\n//new 一个SafeContinuation\n    NEW kotlin/coroutines/experimental/SafeContinuation\n    DUP  \n  //将刚刚normalizeContinuation返回的continuation传入SafeContinuation的构造函数\n    ALOAD 3\n    INVOKESPECIAL kotlin/coroutines/experimental/SafeContinuation.<init> (Lkotlin/coroutines/experimental/Continuation;)V\n    ASTORE 4\n   L3\n  ...\n```\n我们可以看到，编译之后的字节码已经没有了`suspendCoroutine`和`suspendCoroutineOrReturn`的身影，因为这两个函数都是`inline`函数。\n我们接着来看`CoroutineIntrinsics.normalizeContinuation`的实现：\n```\nfun <T> normalizeContinuation(continuation: Continuation<T>): Continuation<T> =\n        (continuation as? CoroutineImpl)?.facade ?: continuation\n```\n 还记得我们刚刚分析过`facade`这个属性吗？他是对`_facade`的代理，这个函数返回的是经过拦截器处理过的`Continuation`\n根据刚刚的字节码，我们可以发现`suspend`类型的函数，都会**隐式**额外接受一个当前协程的引用，但是又不能在函数中直接访问。\n\n最后，还有两个上文出现过的线程切换处理类，`postman`和`dispatcher`，使用的是单例模式：\n```\nobject postman : Handler(Looper.getMainLooper()) {\n    override fun handleMessage(msg: Message?) {\n        msg?.callback?.run()\n    }\n}\n\nobject dispatcher {\n    val mCachedThreads = Executors.newCachedThreadPool()\n    inline fun dispatch(noinline block: () -> Unit) {\n        mCachedThreads.execute(block)\n    }\n}\n```\n到此，我们实现了一个简易的异步调用库！","tags":["kotlin","coroutine"]},{"title":"自定义classLoader","url":"/2017/10/19/自定义classLoader/","content":"\n\n\n在`java`中，加载一个类到`jvm`虚拟机并为其实例化一个对象是由`ClassLoader`实现的\n有时候，我们需要实现特殊的类加载方式，就需要自己实现一个`ClassLoader `\n`ClassLoader`中有几个比较重要的方法：\n\n- `loadClass`：\n  该方法实现了双亲委托机制，一般不会重写该方法，他的执行步骤是先委托父加载器加载，如果加载不到，在执行自己的`findClass `加载\n- `findClass`：\n  一般实现自己的`ClassLoader`都是重写该方法，如果方法找不着，则抛出一个`ClassNotFound`异常\n- `defineClass`：\n  该方法是`jvm`提供的一个接口，验证一个`class`字节码数组，并为其创建一个`Class`对象\n>下面简单实现一个`ClassLoader`，用于加载指定目录下的`jar`包内的类\n```java\npublic class JarsClassLoader extends ClassLoader {\n    private String basePath;  //jar包存放的目录\n\n    public JarsClassLoader(String path, ClassLoader parentClasss) {\n        super(parentClasss); //指定父加载器\n        basePath = path;\n    }\n\n    @Override\n    protected Class<?> findClass(String name) throws ClassNotFoundException {\n        byte[] classByte = getClassByte(name); //根据类的全路径名去获取一个字节码数组\n        try {\n            return defineClass(name, classByte, 0, classByte.length);//生成一个class\n        } catch (Exception e) {\n            throw new ClassNotFoundException(\"找不到类：\"+name);\n        }\n    }\n    /**\n     * 该方法遍历basePath下的jar包，查找是否存在指定的类文件\n    **/\n    private byte[] getClassByte(String className) {\n        try {\n            File baseDir = new File(basePath); \n            File[] childrens = baseDir.listFiles();\n            for (File child : childrens) {\n                if (!child.getName().endsWith(\".jar\"))\n                    continue;\n                //jar包的全路径名\n                String jarName = basePath + File.separator + child.getName();\n                //创建一个Zip文件对象\n                ZipFile zip = new ZipFile(jarName);\n                //遍历Zip内的所有实体项\n                Enumeration<ZipEntry> zipEntries = (Enumeration<ZipEntry>) zip.entries();\n                ZipEntry zn;\n                while (zipEntries.hasMoreElements()) {\n                    zn = zipEntries.nextElement();\n                    if (!zn.getName().endsWith(\".class\"))\n                        continue;\n                    //处理实体名，将`/`替换成`.`，并去除`.class`后缀\n                    String znName =\n                            zn.getName().replace(\"/\", \".\").replace(\".class\", \"\");\n                    //如果找到指定的类文件\n                    if (znName.equals(className)) {\n                        BufferedInputStream bis = new BufferedInputStream(zip.getInputStream(zn));\n                        ByteArrayOutputStream bos = new ByteArrayOutputStream((int) zn.getSize());\n                        byte[] bytes = new byte[1024];\n                        int cnt;\n                        while ((cnt = (bis.read(bytes, 0, bytes.length))) > 0) {\n                             bos.write(bytes, 0, cnt);\n                        }\n                        return bos.toByteArray();\n                    }\n                }\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } \n        return null;\n    }\n}\n```","tags":["java","classloader"]},{"title":"java与plsql类型映射","url":"/2017/10/18/java与plsql类型映射/","content":"\n\n\n# java类型与数据库类型\n\n### 场景\n\n需要将`JAVA`中的复杂数据类型作为plsql存储过程参数传递\n\n- 将参数转换为`json`格式的字符串：`json`的转换和解析都需要时间，影响效率，而且需要为schema导入一套`json`处理的`object`，不利于迁移\n- 使用`Struct`和`Array`等，将`java`的类型映射成数据库的`object`和`Array`\n\n### java\n\n首先，定义`java bean`：\n\n```java\npublic class TechnicalInfo {\n    //定时/实时\n    public String timingType;\n    //全量/增量\n    public String amountType;\n    //同步/异步\n    public String syncType;\n    //传输逻辑\n    public String transferLogic;\n    //服务地址\n    public String serviceAddress;\n    //技术场景\n    public String techScene;\n   \n}\n\n/**\n * Fields\n**/\nimport java.sql.Connection;\nimport java.util.List;\nimport java.util.LinkedList;\nimport java.lang.reflect.Field;\nimport oracle.sql.STRUCT;\nimport oracle.sql.StructDescriptor;\n\npublic class Fields {\n    //字段名称\n    public String name;\n    //类型\n    public String type;\n    //长度\n    public String length;\n    //位置\n    public String position;\n    //层级\n    public String level;\n    //描述\n    public String desc;\n    //备注\n    public String remarks;\n\n    public STRUCT toStruct(Connection conn) throws Exception{\n     \t//使用oracle的数据库接口，类型描述符，对应一个object类型\n        StructDescriptor sd = new StructDescriptor(\"SERVICE_FIELDS\",conn);\n         \n        List<Object> objs = new LinkedList<>();\n        Field[] fs = Fields.class.getDeclaredFields();\n        for (Field f : fs){\n            if (f.getType() == String.class){\n                objs.add(f.get(this));\n            }\n        }\n        //创建一个对应plsql中object对象的struct\n        //objs内的数据与object中声明顺序一致，一一对应\n        return new STRUCT(sd,conn,objs.toArray());\n    }\n\n}\n\n/**\n * ServiceInfo\n**/\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.sql.Connection;\nimport java.lang.reflect.Field;\nimport java.sql.Clob;\nimport java.sql.Struct;\nimport oracle.sql.ARRAY;\nimport oracle.sql.ArrayDescriptor;\n\n public class ServiceInfo {\n    //服务编号\n    public String serviceNo;\n    //接口名称\n    public String serviceName;\n    //服务版本\n    public String serviceVersion;\n    //服务提供方\n    public String serviceProvider;\n    //联系人\n    public String contact;\n    //一级分类\n    public String AClass;\n    //二级分类\n    public String BClass;\n    //三级分类\n    public String CClass;\n    //服务描述\n    public String serviceDesc;\n    //业务场景\n    public String businessScene;\n    //备注\n    public String remarks;\n\n    //触发系统报文\n    public String triggeredMsg;\n    //接收系统报文\n    public String receiveMsg;\n\n    //技术信息\n    public TechnicalInfor technicalInfor;\n\n    //字段\n    public List<Fields> fieldses;\n  \n    private ServiceInfo() {\n    }\n\n\n    public static ServiceInfo build() {\n        ServiceInfo si = new ServiceInfo();\n        si.technicalInfor = new TechnicalInfor();\n        si.fieldses = new LinkedList<>();\n        return si;\n    }\n\n    public Struct toStruct(Connection conn) throws Exception {\n      List<Object> objs = new LinkedList<>();\n     \n        Class clazz = this.getClass();\n        Field[] fs = clazz.getDeclaredFields();\n        for (Field f : fs) {\n            if (\"receiveMsg\".equals(f.getName()) || \"triggeredMsg\".equals(f.getName())) {\n                Clob c = conn.createClob();\n                \n                c.setString(1, (String)f.get(this));\n                objs.add(c);\n            } else if (f.getType() == String.class) {\n              objs.add(f.get(this));\n            }else if (f.getType() == TechnicalInfo.class){\n                Field[] ffs = TechnicalInfor.class.getDeclaredFields();\n                for (Field ff: ffs){\n                    if (ff.getType()==String.class){\n                          objs.add(ff.get(this.technicalInfor));\n                    }\n                  \n                }\n            }else  if (\"fieldses\".equals(f.getName()) ){\n                Struct[] paramses = new Struct[fieldses.size()];\n                for (int i=0;i<fieldses.size();i++){\n                    paramses[i]=fieldses.get(i).toStruct(conn);\n                }\n               ArrayDescriptor ad = new ArrayDescriptor(\"ARRAY_OF_FIELDS\",conn);\n                \n                objs.add(new ARRAY(ad,conn,paramses));\n            }\n        }\n        //使用java标准接口创建struct，对应一个plsql的object\n       return     conn.createStruct(\"SERVICE_INFO\",objs.toArray());\n    }\n\n\n}\n```\n\n调用：\n\n```java\n   stmt = am.getDBTransaction().createCallableStatement(\"begin import_service_from_excel.import(:1,:2);    end;\", 1);\n   stmt.registerOutParameter(2, Types.VARCHAR);\n   Struct  serviceStruct =si.toStruct(stmt.getConnection());\n   stmt.setObject(1, serviceStruct);\n   stmt.execute();\n   String msg = stmt.getString(2);\n```\n\n\n\n### plsql\n\n##### object和array\n\n> `object`中的字段需要和`java bean`中的声明字段顺序保持一致\n\n```plsql\ncreate or replace type service_fields as object\n(\n--字段名称\n  field_name varchar2(200),\n--类型\n  field_type varchar2(100),\n--长度\n  field_length varchar2(20),\n--位置\n  field_position varchar2(100),\n--层级\n  field_level varchar2(10),\n--描述\n  field_desc varchar2(100),\n--备注\n  field_remarks varchar2(200)\n)\n\ncreate or replace type array_of_fields as array(1000000) of service_fields not null\n\ncreate or replace type service_info as object\n(\n--服务号\n  service_no varchar2(100),\n--服务名\n  service_name varchar2(100),\n\n--服务版本\n  serviceversion varchar2(50),\n--服务提供方\n  serviceprovider varchar2(50),\n--联系人\n  contact varchar2(50),\n--一级分类\n  aclass varchar2(50),\n--二级分类\n  bclass varchar2(50),\n--三级分类\n  cclass varchar2(50),\n--服务描述\n  servicedesc varchar2(150),\n--业务场景\n  businessscene varchar2(1000),\n--备注\n  remarks varchar2(200),\n--触发系统报文\n  triggeredmsg clob,\n--接收系统报文\n  receivemsg clob,\n--定时/实时\n  timingtype varchar2(20),\n--全量/增量\n  amounttype varchar2(20),\n--同步/异步\n  synctype varchar2(20),\n--传输逻辑\n  transferlogic varchar2(50),\n--服务地址\n  serviceaddress varchar2(1000),\n--技术场景\n  techscene varchar2(1000),\n--参数字段\n  fieldses array_of_fields\n\n)\n```\n\n##### procedure\n\n```plsql\nprocedure import(si  in service_info,\n                   msg out varchar2) is\n    l_cnt number;\n  begin\n   ...\n    \n  end import;\n```\n\n\n","tags":["java","plsql"]},{"title":"kotlin中的object更像是语法糖","url":"/2017/06/10/kotlin中的object更像是语法糖/","content":"\n\n\n### 单例声明\n\n\n\nkotlin中，声明一个单例的语法很简单：\n```\nobject obj\n```\n我们使用`object`关键字替代`class`关键字就可以声明一个单例对象\n`object`一样可以继承其他类，或者实现其他接口：\n```kotlin\ninterface IObj\nabstract class AbstractObj\nobject obj : AbstractObj(),IObj  \n```\n在这里，我们让`obj`这个单例继承了`AbstractObj`，并且实现了`IObj`接口\n声明一个单例对象，和声明一个`class`很类似\n但是，`object`声明的单例对象**不能声明构造函数**，因为单例对象只有一个实例，无需我们手动将它创建出来，因此自然不需要构造函数。\n> 如果需要对单例对象做初始化操作，可以在`init`初始化块内进行\n\n那么`object`是什么时候被创建的呢？\n>官方文档的解释是，`object`是`lazy-init`，即在第一次使用时被创造出来的\n\n`object`单例基本的使用就像上面这样了，基本的用法参照官方的文档说明就好了\n\n### 实现\n\n在java中，我们要使用一个单例模式时，一般使用双重检查锁：\n\n```java\npublic class Obj {\n      private Obj(){}\n      private static volatile Obj INSTANCE;\t\t//volatile防止指令重排\n      public static Obj getObj(){\n          if(INSTANCE==null){\n              synchronized(Obj.class){\n                  if (INSTANCE==null){\n                      INSTANCE=new Obj();\n                  }\n              }\n          }\n          return INSTANCE;\n      }\n}\n```\n而相同的功能，在kotlin只要`object Obj`就搞定了，这样的黑魔法是怎么实现的呢？\n为了探究一二，我们先来看看编译之后的字节码:\n\n```kotlin\n//源代码:\nobject Obj{\n    init{\n        println(\"object init...\")\n    }\n}\n```\n```java\n//对应的字节码：\npublic final class Obj {   //可以看到生成了一个class，而类名就是object name\n  // access flags 0x2\n  private <init>()V     //注意看，<init>的可见性是`private`\n   L0\n    LINENUMBER 8 L0\n    ALOAD 0  //将局部变量表slot 0处的引用入栈，即this引用\n    INVOKESPECIAL java/lang/Object.<init> ()V   //调用父类的<init>\n    ALOAD 0  //和上面一样，将局部变量表slot 0处的引用入栈，即this引用\n    CHECKCAST Obj    //类型检查\n    PUTSTATIC Obj.INSTANCE : LObj;     //保存this引用到`INSTANCE`这个静态域\n   L1\n    LINENUMBER 10 L1\n    LDC \"object init...\"    //从常量池将字符串引用送至栈顶\n    ASTORE 1    //将栈顶的引用保存到局部遍历表第一个slot处\n   L2\n    GETSTATIC java/lang/System.out : Ljava/io/PrintStream;    //获取out实例\n    ALOAD 1    //从局部变量表第一个slot处加载引用到栈顶\n    INVOKEVIRTUAL java/io/PrintStream.println (Ljava/lang/Object;)V   //输出\n   L3\n   L4\n   L5\n    RETURN  //返回\n   L6\n    LOCALVARIABLE this LObj; L0 L6 0\n    MAXSTACK = 2    //操作数栈深度为2\n    MAXLOCALS = 2    //局部变量表为2个slot\n  // access flags 0x19\n  public final static LObj; INSTANCE    //**静态域**，类型为Obj\n  // access flags 0x8\n  static <clinit>()V    //静态初始化块，类初始化时执行\n   L0\n    LINENUMBER 8 L0\n    NEW Obj     //创建一个Obj实例，引用保存在栈顶\n    INVOKESPECIAL Obj.<init> ()V   //调用其<init>，初始化对象，此时会把栈顶引用作为this引用传入\n    RETURN\n    MAXSTACK = 1\n    MAXLOCALS = 0\n}\n```\n从上面的字节码中，我们可以看到，声明一个`object`，实际上就是创建了一个`class`，在类静态初始化时，会创建一个该类的实例，保存到其静态域`INSTANCE`中\n进而可以猜想，源码中对单例的引用会被编译器替换为对`INSTANCE`这个静态域的引用\n为了验证我们的分析，现在来看看使用单例时，对应的字节码\n```kotlin\n源码：\nfun main(args:Array<String>){\n    Obj is Any\n}\n```\n```\n对应的字节码：\npublic final static main([Ljava/lang/String;)V\n    @Lorg/jetbrains/annotations/NotNull;() // invisible, parameter 0\n   L0\n    ALOAD 0\n    LDC \"args\"\n    INVOKESTATIC kotlin/jvm/internal/Intrinsics.checkParameterIsNotNull (Ljava/lang/Object;Ljava/lang/String;)V\n   L1\n    LINENUMBER 5 L1\n    GETSTATIC Obj.INSTANCE : LObj;    //获取Obj的静态域`INSTANCE`\n    INSTANCEOF java/lang/Object        //判断是否是`Object`类型\n    POP\n   L2\n    LINENUMBER 6 L2\n    RETURN\n   L3\n    LOCALVARIABLE args [Ljava/lang/String; L0 L3 0\n    MAXSTACK = 2\n    MAXLOCALS = 1\n```\n\n可以看到，我们在源码中直接使用`object name`访问单例对象，而编译器帮我们做了翻译，实际使用的是内部的静态域`INSTANCE`\n而且，从对上面`Obj`这个生成的类的分析，我们可以发现，`object`在java中的对应的实现是类型这样的：\n\n```java\npublic class  Obj {\n    private Obj(){}\n    private static Obj INSTANCE=null;\n    static {\n        INSTANCE=new Obj();\n    }\n}\n```\n这是最简单的单例实现方法，在类加载器加载class后执行静态初始化时就创建单例对象。\n\n而`object`单例初始化的时机，准确来说，应该是这个类被加载时，静态初始化的时候。\n做个小实验：\n\n```kotlin\nobject Obj{\n    init{\n        println(\"object init...\")\n    }\n}\n```\n```kotlin\nfun main(args:Array<String>){\n         Class.forName(\"Obj\")\n    }\n```\n>控制台输出：object init...\n\n可见，当我们加载这个类的时候，单例就被创建了。\n而单例名就是类名。\n\n那么，`object`真的就是单例吗？\n一般情况下是的，因为字节码中`<init>`方法被声明为`private`，虽然不太准确但是我们可以认为对应了类的一个`private`的无参构造函数，这就使得我们无法创建出一个新的对象出来。\n但是，我们完全可以使用反射机制，从一个`private`的构造函数中创建一个对象出来：\n```kotlin\nfun main(args:Array<String>){\n    println(Obj)\n    var clazz=Class.forName(\"Obj\")\n    var constrouctor=clazz.getDeclaredConstructor()\n    constrouctor.setAccessible(true)\n    var instance=constrouctor.newInstance()\n    constrouctor.setAccessible(false)\n    println(instance)\n}\n输出：\nobject init...\nObj@511d50c0\nobject init...\nObj@60e53b93\n```\n可见，两次输出的对象引用是不一样的。\n\n那么，这就说明kotlin的单例是不安全的吗？这到未必\n我们在原先的基础上，加上几个属性声明：\n```\nobject Obj{\n    var name=\"name\"\n    var age=\"10\"\n    init{\n        println(\"object init...\")\n    }\n}\n```\n观察对应的字节码：\n```\npublic final class Obj {\n  private static Ljava/lang/String; name\n   ...\n  private static Ljava/lang/String; age\n  ....\n  public final static LObj; INSTANCE\n  ...  \n}\n```\n可以看到，这些属性的`field`都被声明为`static`了，尽管可以通过反射手段创建多个`object`的实例，但是它们的状态都是共享的\n总结：\n\n- `object`实际上还是生成一个`class`，但是这个`class`在`kotlin`中是透明的，无法直接访问，比如`Obj.INSTANCE`在kotlin中是不允许的，只能通过`Obj`来引用这个单例\n- `object name`本质上是类名，只是编译器在编译时自动将`object name`换成了 `object`的`INSTANCE`\n- `object`更像是语法糖","tags":["kotlin"]},{"title":"kotlin之代理属性","url":"/2017/05/16/kotlin之代理属性/","content":"\n### 属性代理\n\n##### 委托类\n\n委托类可以自己定义，必须提供`getValue`，如果用于代理var属性，还必须提供`setValue` \n\n```kotlin\nclass Delegate {\n  \t/**\n     * @param thisRef 被代理类实例\n     * @param property 被代理属性\n     */\n    operator fun getValue(thisRef: Any?, property: KProperty<*>): String {\n        return \"$thisRef, thank you for delegating '${property.name}' to me!\"\n    } \n    operator fun setValue(thisRef: Any?, property: KProperty<*>, value: String) {\n        println(\"$value has been assigned to '${property.name} in $thisRef.'\")\n    }\n}\n```\n\n##### 使用\n\n具体的使用方法：\n\n```\nvar 变量名:type by 委托对象\nval 变量名:type by 委托对象\n```\n\n使用代理属性禁止自定义setter和getter，代理的本质就是将setter和getter委托给其他对象\n\nkotlin提供了几个标准的代理工厂方法：\n\n- 懒加载： **the value gets computed only upon first access** \n\n```kotlin\n//通过使用工厂方法lazy()获得Lazy<T>实例\nfun main(args:Array<String>){\n\t//lazy没有提供setter，所以使用lazy代理的属性必须为val\n    val str:String by lazy{  //Lazy<T>懒加载，只会在第一次时执行\n        println(\"lazy\")\n        \"hello\"\n    }\n    println(str)\n    println(str)\n}\n```\n\n- observable properties: **listeners get notified about changes to this property** \n\n```kotlin\nfun main(args:Array<String>){\n    var p=Person()\n    println(p.name)\n    p.name=\"Jim\"\n    println(p.name)\n}\n\nclass Person{\n    var name by Delegates.observable(\"no-name\"){  //set时被调用\n        prop,old,new->\n        println(\"$prop($old->$new)\")\n    }\n}\n```\n\n- **storing properties in a map, not in separate field each **\n\n```kotlin\nfun main(args:Array<String>){\n    var p=Person(mutableMapOf(\"name\" to \"Tim\",\"age\" to 10))\n    println(p.name)\n    println(p.age)\n\n}\n\nclass Person(map:MutableMap<String,Any?>){\n    var name:String by map\n    var age:Int by map\n}\n```\n\n##### 工作原理\n\n```kotlin\nclass C {\n    var prop: Type by MyDelegate()\n} \n// this code is generated by the compiler\n// when the 'provideDelegate' function is available:\nclass C {\n    // calling \"provideDelegate\" to create the additional \"delegate\" property\n    private val prop$delegate = MyDelegate().provideDelegate(this, this::prop)\n    val prop: Type\n        get() = prop$delegate.getValue(this, this::prop)\n}\n```\n\nkotlin 1.1之后，代理属性可以用于local-properties\n\n\n\n### 方法代理\n\n```kotlin\nfun main(args:Array<String>){\n    var b=B(AImpl())\n    b.echo()\n}\n\ninterface A{\n    fun echo()\n}\n\nclass AImpl:A{\n    override fun echo(){\n        println(\"a implemention of A\")\n    }\n}\nclass B(impl:AImpl):A by impl  //impl提供B的接口方法\n```\n方法代理的实现原理就是编译时，自动为B生成echo方法的实现，并在该方法中调用impl的echo方法，因此B实例会持有impl的引用","tags":["kotlin"]},{"title":"使用kotlin写自己的dsl","url":"/2017/04/25/使用kotlin写自己的dsl/","content":"\n\n\n相比于java，kotlin对**FP**更加友好，支持扩展函数和操作符重载，这就为定义dsl提供了支持。\n什么是dsl呢？就是一种面向特定问题的语言。gradle就是是一种用groovy定义的dsl。而kotlin一样对定义dsl提供了友好的支持。\n本篇文章就来定义一个简单用于配置hibernate框架的dsl，写起来就像：\n\n```kotlin\nvar conf= buildConfiguration{\n                connection {\n                    username = \"***\"\n                    password = \"******\"\n                    url = \"jdbc:mysql://localhost:3306/******\"\n                    driver = Driver::class.java\n                }\n                c3p0 {\n                    max_size = 30\n                    min_size = 10\n                    timeout=5000\n                    max_statements=100\n                    idle_test_period=300\n                    acquire_increment=2\n                    validate=true\n                }\n                entity {\n                    mapping = Client::class.java\n                    mapping = Financial_account::class.java\n                    mapping = FundHolding::class.java\n                    mapping=Fund::class.java\n                }\n                dialect=\"org.hibernate.dialect.MySQL5InnoDBDialect\"\n            }\n```\n\n上面是一个对hibernate的简单配置，最后获取一个configuration实例。通过使用dsl，可以避免在运行时解析xml文件，同时又比使用java代码配置简洁，兼具xml的结构化和java的高效。\n那么，这样一个dsl是如何实现的呢？\n\n> 先介绍一下预备知识：\n> 扩展函数：\n```kotlin\nfun Type.foo():Unit{\n  ...\n}\n```\n这样就为`Type`对象创建了一个扩展函数，假如`t`是`Type`的一个实例，就可以：\n```t.foo()```\n`Type`称作`reciver`，而在`foo`函数体内，可以使用`this`访问其`public`成员，甚至可以省略`this`，仿佛`foo`函数是定义在`class Type`内\n而声明一个函数的参数是扩展函数，一般的语法：\n`fun funName(block:Type.(params...)->ReturnType):ReturnType{...}`\n关于扩展函数更多的用法，可以参考官方的文档\n\n首先先声明一个方法：\n```kotlin\nfun buildConfiguration(block:ConfigurationBuilder.()->Unit):Configuration{\n    var cfg=ConfigurationBuilder()\n    cfg.block()\n    return cfg.cfg\n} \n```\n这个方法接收一个有receiver的lambda表达式，因为这样在block的内部就可以直接访问receiver的公共成员了，这一点很重要\n紧接着对这个Configuration这个类进行定义\n```kotlin\nclass ConfigurationBuilder{\n     val TAG=\"hibernate\"\n     val cfg=Configuration()\n     var dialect:String? get() = null\n        set(value){\n            cfg.setProperty(\"$TAG.dialect\",value!!)\n        }\n     inline fun connection(block:ConnectionBuilder.()->Unit)=ConnectionBuilder(cfg).block()\n     inline fun c3p0(block:C3p0Builder.()->Unit)=C3p0Builder(cfg).block()\n     inline fun entity(block:Entity.()->Unit)=Entity(cfg).block()\n}\n```\n\n在里面我定义了三个成员函数，分别对应前面示例中的\n```kotlin\nvar conf= buildConfiguration{\n                connection {\n                    ...\n                }\n                c3p0 {\n                    ...\n                }\n                entity {\n                    ...\n                }\n               ...\n            }\n```\n\n在这个lambda里面，我就直接调用了buildConfiguration的成员函数，那么对象引用呢？还记得我前面说过的吗？buildConfiguration这个方法的参数是一个有receiver的lambda，而在buildConfiguration中声明了一个ConfigurationBuilder对象并通过这个对象调用了这个lambda。那么这个lambda就会在这个对象的上下文中，我们可以直接访问它的公共成员，甚至可以使用this引用这个对象。\n后续的步骤都差不多,我这里为了省事直接就声明了一个Configuration对象，并传到了其他对象里面\n后面的源码\n```kotlin\nclass ConnectionBuilder(val cfg:Configuration){//直接接受了一个configuration对象\n     val TAG=\"hibernate.connection\"\n     var username:String? get() = null  //重写了setter和getter，防止属性有field\n        set(name){\n            cfg.setProperty(\"$TAG.username\",name!!)  //直接硬编码设置属性\n        }\n     var password:String?  get() = null\n        set(password) {\n            cfg.setProperty(\"$TAG.password\", password!!)\n        }\n      var url:String? get() = null\n        set(url){\n            cfg.setProperty(\"$TAG.url\",url!!)\n        }\n      var driver:Class<*>? get() = null\n        set(driver){\n            cfg.setProperty(\"$TAG.driver_class\",driver!!.name)\n        }\n      var pool_size:Int? get() = null\n        set(size){\n            cfg.setProperty(\"$TAG.pool_size\",size!!.toString())\n        }\n}\n//后面的都差不多。。。\n class C3p0Builder(val cfg:Configuration){\n     val TAG=\"hibernate.c3p0\"\n     var max_size:Int? get() = null\n        set(max_size){\n            cfg.setProperty(\"$TAG.max_size\",max_size!!.toString())\n        }\n     var min_size:Int? get() = null\n        set(min_size){\n            cfg.setProperty(\"$TAG.min_size\",min_size!!.toString())\n        }\n     var timeout:Int? get() = null\n        set(timeout){\n            cfg.setProperty(\"$TAG.timeout\",timeout!!.toString())\n        }\n     var max_statements:Int? get() = null\n        set(max_stmt){\n            cfg.setProperty(\"$TAG.max_statements\",max_stmt!!.toString())\n        }\n     var idle_test_period:Int? get() = null\n        set(idle_test_period){\n            cfg.setProperty(\"$TAG.idle_test_period\",idle_test_period!!.toString())\n        }\n     var acquire_increment:Int? get() = null\n        set(acquire){\n            cfg.setProperty(\"$TAG.acquire_increment\",acquire!!.toString())\n        }\n     var validate:Boolean? get() = null\n        set(validate){\n            cfg.setProperty(\"$TAG.validate\",validate!!.toString())\n        }\n}\n class Entity(val cfg:Configuration){\n     var mapping:Class<*>?\n        get()=null\n        set(clazz){\n            cfg.addAnnotatedClass(clazz!!)\n        }\n}\n```\n\n至此，一个简单的dsl就完成了\n总体来说，定义一个dsl的过程基本是一个递归下去的过程，每个步骤都很类似","tags":["kotlin","dsl"]}]