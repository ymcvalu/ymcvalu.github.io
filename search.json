[{"title":"go的接口值","url":"/2019/05/11/go中的iface/","content":"\n# iface - go中的非空接口\n\n本文稍微总结一下`go`中的`iface`这个结构的一些内容\n\n###  结构\n\n```go\ntype iface struct {\n\ttab  *itab\n\tdata unsafe.Pointer\n}\n\ntype itab struct {\n\tinter *interfacetype // 接口类型\n\t_type *_type // 实际类型\n\thash  uint32 // copy of _type.hash. Used for type switches.\n\t_     [4]byte // 4字节填充，与上面的4字节hash凑成8字节，与n内存对齐相关\n    // itab末尾是实现方法的引用，如果多于1个，则其余方法引用紧跟itab内存之后分配，有点像c++的虚函数表\n\tfun   [1]uintptr // variable sized. fun[0]==0 means _type does not implement inter.\n}\n\ntype interfacetype struct {\n\ttyp     _type // 接口类型信息\n\tpkgpath name\t\n\tmhdr    []imethod // 接口声明的方法\n}\n\ntype _type struct {\n\tsize       uintptr\n\tptrdata    uintptr  // size of memory prefix holding all pointers\n\thash       uint32   // 类型hash值\n\ttflag      tflag    // 类型相关一些flag，可以在反射包中使用\n\talign      uint8    // 内存对齐\n\tfieldalign uint8    // 字段对齐\n\tkind       uint8    // 类型kind\n\talg        *typeAlg // 类型的hash和equal方法\n\t// gcdata stores the GC type data for the garbage collector.\n\t// If the KindGCProg bit is set in kind, gcdata is a GC program.\n\t// Otherwise it is a ptrmask bitmap. See mbitmap.go for details.\n\tgcdata    *byte\n\tstr       nameOff   // offset of name\n\tptrToThis typeOff   \n}\n```\n\n这里的`_type`是最基本的类型信息，而实际我们声明的类型还有包含字段、方法等信息，查看下面代码，可以看到`_type`只是实际类型结构的一部分\n\n```go\ntype uncommontype struct {\n\tpkgpath nameOff\n\tmcount  uint16 // 类型声明的方法数\n\txcount  uint16 // 导出的方法数\n\tmoff    uint32 // 该类型的函数引用列表偏移\n\t_       uint32 // unused，内存对齐相关\n}\n\nfunc (t *_type) uncommon() *uncommontype {\n\tif t.tflag&tflagUncommon == 0 { // 如果是common类型，直接返回，即没有声明方法\n\t\treturn nil\n\t}\n    // 不同Kind的类型，其类型结构不一样\n    // go中可以基于其他类型声明新的类型，类型种类是无穷的，但是Kind就那么几种，struct、slice、map、chan、int、uint、float、bool、array、ptr、interface ...\n\tswitch t.kind & kindMask {\n\tcase kindStruct: \n\t\ttype u struct { \n\t\t\tstructtype\n\t\t\tu uncommontype\n\t\t}\n\t\treturn &(*u)(unsafe.Pointer(t)).u\n\tcase kindPtr: \n\t\ttype u struct {\n\t\t\tptrtype\n\t\t\tu uncommontype\n\t\t}\n\t\treturn &(*u)(unsafe.Pointer(t)).u\n\tcase kindFunc:\n\t\ttype u struct {\n\t\t\tfunctype\n\t\t\tu uncommontype\n\t\t}\n\t\treturn &(*u)(unsafe.Pointer(t)).u\n\tcase kindSlice:\n\t\ttype u struct {\n\t\t\tslicetype\n\t\t\tu uncommontype\n\t\t}\n\t\treturn &(*u)(unsafe.Pointer(t)).u\n\tcase kindArray:\n\t\ttype u struct {\n\t\t\tarraytype\n\t\t\tu uncommontype\n\t\t}\n\t\treturn &(*u)(unsafe.Pointer(t)).u\n\tcase kindChan:\n\t\ttype u struct {\n\t\t\tchantype\n\t\t\tu uncommontype\n\t\t}\n\t\treturn &(*u)(unsafe.Pointer(t)).u\n\tcase kindMap:\n\t\ttype u struct {\n\t\t\tmaptype\n\t\t\tu uncommontype\n\t\t}\n\t\treturn &(*u)(unsafe.Pointer(t)).u\n\tcase kindInterface:\n\t\ttype u struct {\n\t\t\tinterfacetype\n\t\t\tu uncommontype\n\t\t}\n\t\treturn &(*u)(unsafe.Pointer(t)).u\n\tdefault:\n\t\ttype u struct {\n\t\t\t_type\n\t\t\tu uncommontype\n\t\t}\n\t\treturn &(*u)(unsafe.Pointer(t)).u\n\t}\n}\n```\n\n\n\n### 通过汇编看iface\n\n```go\nfunc main() {\n\tvar r io.Reader = Arr{}\n\tr.Read(nil)\n}\n\ntype Arr []byte\n\nfunc (Arr) Read(n []byte) (int, error) {\n\treturn 0, nil\n}\n```\n\n```sh\n$ go tool compile -S main.go > main.s\n```\n\n```assembly\n\t0x0000 00000 (test.go:7)\tTEXT\t\"\".main(SB), $88-0\n\t...\n\t0x0024 00036 (test.go:8)\tLEAQ\ttype.[0]uint8(SB), AX  // newobject方法参数\n\t0x002b 00043 (test.go:8)\tMOVQ\tAX, (SP)\n\t0x002f 00047 (test.go:8)\tCALL\truntime.newobject(SB)\n\t0x0034 00052 (test.go:8)\tMOVQ\t8(SP), AX // 这里把返回的指针保存到AX\n\t0x0039 00057 (test.go:8)\tMOVQ\tAX, \"\"..autotmp_1+56(SP) // Arr对象\n\t0x003e 00062 (test.go:8)\tXORPS\tX0, X0\n\t0x0041 00065 (test.go:8)\tMOVUPS\tX0, \"\"..autotmp_1+64(SP)\n\t0x0046 00070 (test.go:8)\tLEAQ\tgo.itab.\"\".Arr,io.Reader(SB), AX // itab\n\t0x004d 00077 (test.go:8)\tMOVQ\tAX, (SP)\n\t0x0051 00081 (test.go:8)\tLEAQ\t\"\"..autotmp_1+56(SP), AX // Arr对象指针\n\t0x0056 00086 (test.go:8)\tMOVQ\tAX, 8(SP)\n\t0x005b 00091 (test.go:8)\tCALL\truntime.convT2Islice(SB) // 生成iface\n\t0x0060 00096 (test.go:8)\tMOVQ\t24(SP), AX // 接口的data字段\n\t0x0065 00101 (test.go:8)\tMOVQ\t16(SP), CX // 接口的tab字段，即itab表\n\t0x006a 00106 (test.go:9)\tMOVQ\t24(CX), CX // itab的24~32为实际方法Read地址\n\t// 110~127构造一个 Arr{0 0 data}结构，来调用方法Read\n\t// 实际上方法的接收者就是方法第一个参数\n\t0x006e 00110 (test.go:9)\tMOVQ\t$0, 8(SP) // 0\n\t0x0077 00119 (test.go:9)\tXORPS\tX0, X0 \n\t0x007a 00122 (test.go:9)\tMOVUPS\tX0, 16(SP) // 0\n\t0x007f 00127 (test.go:9)\tMOVQ\tAX, (SP) // data\n\t0x0083 00131 (test.go:9)\tCALL\tCX // 调用Read方法\n\t0x008e 00142 (test.go:10)\tRET\n\n// 有些itab在编译期间可以自动生成\n// 可能在a文件声明了Arr，b文件中声明了接口Reader，在C包文件c和D包文件d都用到了Arr初始化接口Reader，\n// 则会在c文件和d文件都生成这个itab表，因此声明为dupok，由链接器任意选择一个\ngo.itab.\"\".Arr,io.Reader SRODATA dupok size=32\n\t0x0000 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................\n\t0x0010 d6 ed 1d 4e 00 00 00 00 00 00 00 00 00 00 00 00  ...N............\n\trel 0+8 t=1 type.io.Reader+0\n\trel 8+8 t=1 type.\"\".Arr+0\n\trel 24+8 t=1 \"\".(*Arr).Read+0 // 这里rel告诉链接器要将24~32的符号引用替换成方法的逻辑地址\n```\n\n可以看到，实现接口的方法引用列表会保存在itab末尾，调用时，需要先计算具体调用函数的偏移获取实际方法引用\n\n\n\n### 接口类型转换与itab生成\n\n有的接口赋值在编译时可以分析，因此可以直接生成itab表，但是有的是运行时动态赋值的（比如接口断言），因此需要运行时动态生成itab表\n\n##### 接口类型强制转换\n\n```go\n// 接口转换\nfunc convI2I(inter *interfacetype, i iface) (r iface) {\n   tab := i.tab\n   if tab == nil {\n      return\n   }\n   if tab.inter == inter {\n      r.tab = tab\n      r.data = i.data\n      return\n   }\n   r.tab = getitab(inter, tab._type, false)\n   r.data = i.data\n   return\n}\n```\n\n**将接口值A强制转换成接口B时，需要满足：接口A的方法集包含或者等于接口B的方法集**\n\n接口值之间的类型转换，不会考虑实际类型的方法集，而是简单的对接口的方法集进行判断\n\n```go\nvar r io.ReadCloser = XXX{}\nr.Read(nil)\n_ = io.Reader(r) // ok\n_ = io.ReadCloser(r) // ok\n_ = io.Writer(r) // no\nvar rc io.Reader = XXX{}\n_ = io.ReaderCloser(rc) // no\n```\n\n\n\n##### 接口类型断言\n\n**接口断言：根据接口值的实际类型，判断是否实现了目标接口**\n\n```go\n// 接口断言\nfunc assertI2I(inter *interfacetype, i iface) (r iface) {\n   tab := i.tab\n   if tab == nil {\n      // explicit conversions require non-nil interface value.\n      panic(&TypeAssertionError{nil, nil, &inter.typ, \"\"})\n   }\n    \n   // 如果目标接口类型就是当前接口类型，直接返回\n   if tab.inter == inter {\n      r.tab = tab\n      r.data = i.data\n      return\n   }\n   r.tab = getitab(inter, tab._type, false) // 获取itab，如果失败直接panic\n   r.data = i.data\n   return\n}\n\nfunc assertI2I2(inter *interfacetype, i iface) (r iface, b bool) {\n\ttab := i.tab\n\tif tab == nil {\n\t\treturn\n\t}\n\tif tab.inter != inter {\n\t\ttab = getitab(inter, tab._type, true) // true表示容忍失败\n\t\tif tab == nil { // 不符合，返回false\n\t\t\treturn\n\t\t}\n\t}\n\tr.tab = tab\n\tr.data = i.data\n\tb = true\n\treturn\n}\n\nfunc getitab(inter *interfacetype, typ *_type, canfail bool) *itab {\n\tif len(inter.mhdr) == 0 {\n\t\tthrow(\"internal error - misuse of itab\")\n\t}\n\n\t// easy case\n\tif typ.tflag&tflagUncommon == 0 {\n\t\tif canfail {\n\t\t\treturn nil\n\t\t}\n\t\tname := inter.typ.nameOff(inter.mhdr[0].name)\n\t\tpanic(&TypeAssertionError{nil, typ, &inter.typ, name.name()})\n\t}\n\n\tvar m *itab\n\n\t// First, look in the existing table to see if we can find the itab we need.\n\t// This is by far the most common case, so do it without locks.\n\t// Use atomic to ensure we see any previous writes done by the thread\n\t// that updates the itabTable field (with atomic.Storep in itabAdd).\n    // 先查表是否已经存在需要的itab\n\tt := (*itabTableType)(atomic.Loadp(unsafe.Pointer(&itabTable)))\n\tif m = t.find(inter, typ); m != nil {\n\t\tgoto finish\n\t}\n\n\t// Not found.  Grab the lock and try again.\n\tlock(&itabLock)\n    // 双重锁检查\n\tif m = itabTable.find(inter, typ); m != nil {\n\t\tunlock(&itabLock)\n\t\tgoto finish\n\t}\n\n\t// Entry doesn't exist yet. Make a new entry & add it.\n    // 分配itab内存，itab的内存分配在gc堆之外，不会被垃圾扫描、回收\n\tm = (*itab)(persistentalloc(unsafe.Sizeof(itab{})+uintptr(len(inter.mhdr)-1)*sys.PtrSize, 0, &memstats.other_sys))\n\tm.inter = inter\n\tm._type = typ\n\tm.init() // 初始化\n\titabAdd(m) // 添加到itabTable中，后续直接查表，不需要重新构造\n\tunlock(&itabLock)\nfinish:\n\tif m.fun[0] != 0 { // itab初始化成功\n\t\treturn m\n\t}\n\tif canfail {\n\t\treturn nil\n\t}\n\t// this can only happen if the conversion\n\t// was already done once using the , ok form\n\t// and we have a cached negative result.\n\t// The cached result doesn't record which\n\t// interface function was missing, so initialize\n\t// the itab again to get the missing function name.\n\tpanic(&TypeAssertionError{concrete: typ, asserted: &inter.typ, missingMethod: m.init()})\n}\n\n\n// init fills in the m.fun array with all the code pointers for\n// the m.inter/m._type pair. If the type does not implement the interface,\n// it sets m.fun[0] to 0 and returns the name of an interface function that is missing.\n// It is ok to call this multiple times on the same m, even concurrently.\nfunc (m *itab) init() string {\n\tinter := m.inter\n\ttyp := m._type\n\tx := typ.uncommon() \n\n\t// both inter and typ have method sorted by name,\n\t// and interface names are unique,\n\t// so can iterate over both in lock step;\n\t// the loop is O(ni+nt) not O(ni*nt).\n    // 接口和类型的方法列表是按照名字排序的，因此实际循环时间复杂度是O(ni+nt)\n\tni := len(inter.mhdr) // 目标接口方法总数\n\tnt := int(x.mcount) // 实际类型方法总数\n    // 计算实际类型的方法引用列表的偏移\n\txmhdr := (*[1 << 16]method)(add(unsafe.Pointer(x), uintptr(x.moff)))[:nt:nt]\n\tj := 0\nimethods:\n\tfor k := 0; k < ni; k++ {\n\t\ti := &inter.mhdr[k]\n\t\titype := inter.typ.typeOff(i.ityp) // 目标接口方法类型，与参数和返回值相关\n\t\tname := inter.typ.nameOff(i.name)  // 目标接口方法名\n\t\tiname := name.name()\n\t\tipkg := name.pkgPath() // 接口的包名\n\t\tif ipkg == \"\" {\n\t\t\tipkg = inter.pkgpath.name()\n\t\t}\n\t\tfor ; j < nt; j++ {\n\t\t\tt := &xmhdr[j]\n\t\t\ttname := typ.nameOff(t.name) \n            // 如果实际方法类型和方法名与目标方法的一致\n\t\t\tif typ.typeOff(t.mtyp) == itype && tname.name() == iname {\n\t\t\t\tpkgPath := tname.pkgPath()\n\t\t\t\tif pkgPath == \"\" {\n\t\t\t\t\tpkgPath = typ.nameOff(x.pkgpath).name()\n\t\t\t\t}\n                // 如果方法是导出的或者包名一致\n                // 如果接口有未导出方法，只能在同一个包内被实现，可以用来限制其他包实现该接口\n\t\t\t\tif tname.isExported() || pkgPath == ipkg {\n\t\t\t\t\tif m != nil {\n\t\t\t\t\t\tifn := typ.textOff(t.ifn) //实际函数入口PC\n                        // 保存到itab的方法列表中\n\t\t\t\t\t\t*(*unsafe.Pointer)(add(unsafe.Pointer(&m.fun[0]), uintptr(k)*sys.PtrSize)) = ifn\n\t\t\t\t\t}\n\t\t\t\t\tcontinue imethods\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// didn't find method\n\t\tm.fun[0] = 0 // 没有找到方法，即目标类型没有实现该方法\n\t\treturn iname\n\t}\n\tm.hash = typ.hash\n\treturn \"\"\n}\n```\n\n","tags":["go","interface"]},{"title":"iptables入门","url":"/2019/05/06/iptables入门/","content":"\n# iptables\n\n### Doc\n\n- [iptables tutorial](<https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html>)\n- `iptables -h`\n- `man iptables`\n\n### Tables & Chains\n\n表由链组成，链是一些按顺序排列的规则的列表。比如，默认的 `filter` 表包含 `INPUT`， `OUTPUT` 和 `FORWARD` 3条内建的链，这3条链作用于数据包过滤过程中的不同时间点。\n\n各个表和包含的链关系如下：\n\n| table      | chain                                                        | desc                                                        |\n| ---------- | ------------------------------------------------------------ | ----------------------------------------------------------- |\n| `raw`      | `PREROUTING`、`OUTPUT`                                       | 关闭nat表上使用的连接追踪机制；内核模块：`iptable_raw`      |\n| `filter`   | `INPUT`、`OUTPUT`、`FORWARD`                                 | 负责过滤功能，防火墙；内核模块：`iptable_filter`            |\n| `nat`      | `PREROUTING`、 `POSTROUTING`、 `OUTPUT`、 `INPUT(部分支持)`  | 网络地址转换；内核模块：`iptable_nat`                       |\n| `mangle`   | `PREROUTING`、 `INPUT`、 `FORWARD`、 `OUTPUT `、`POSTROUTING` | 拆解、修改、重封装报文；内核模块：`iptable_mangle`          |\n| `security` |                                                              | 用于强制[访问控制网络](http://lwn.net/Articles/267140/)规则 |\n\n默认情况下，任何链中都没有规则。可以向链中添加自己想用的规则。链的默认规则通常设置为 `ACCEPT`，如果想确保任何包都不能通过规则集，那么可以重置为 `DROP`。默认的规则总是在一条链的最后生效，所以在默认规则生效前数据包需要通过所有存在的规则。用户可以加入自己定义的链，从而使规则集更方便管理，自定义链需要被内置的链引用才能生效。每个链下面可以设置一组规则，执行链时就是执行这组规则。\n\n\n\n### Traversing Chains\n\n\n\n![图1](/img/iptables_traverse.jpg)\n\n上图描述链了在任何接口上收到的网络数据包是按照怎样的顺序穿过表的交通管制链。第一个路由策略包括决定数据包的目的地是本地主机（这种情况下，数据包穿过 `INPUT` 链），还是其他主机（数据包穿过 `FORWARD` 链）；中间的路由策略包括决定给传出的数据包使用那个源地址、分配哪个接口；最后一个路由策略存在是因为先前的` mangle` 与 `nat` 链可能会改变数据包的路由信息。数据包通过路径上的每一条链时，链中的每一条规则按顺序匹配；无论何时匹配了一条规则，相应的` target` 动作将会执行。内置的链有默认的策略，但是用户自定义的链没有默认的策略。在` jump` 到的自定义链中，若每一条规则都不能提供完全匹配，那么数据包像下图描述的一样返回到调用链。在任何时候，若 `DROP` 的规则实现完全匹配，那么被匹配的数据包会被丢弃，不会进行进一步处理。如果一个数据包在链中被 `ACCEPT`，那么这个包就会被`ACCEPT`，不会再遍历后面的规则。\n\n然而，要注意的是，数据包还会以正常的方式继续遍历其他表中的其他链。\n\n![图2](/img/iptable_subtraverse.jpg)\n\n\n\n### Command\n\n```sh\n$ iptables -t 表名 <-A/I/D/R> 规则链名 [规则号] <-i/o 网卡名> -p 协议名 <-s 源IP/源子网> --sport 源端口 <-d 目标IP/目标子网> --dport 目标端口 -j 动作\n```\n\n###### 规则管理命令\n\n- `-A` or `--append` ：将规则加到`chain`末尾\n\n  ```sh\n  $ iptables -t filter -A INPUT -i lo -j DROP #在INPUT链末尾添加规则，拒绝掉来自lo网卡的包\n  ```\n\n- `-I` or `--insert` ：在指定位置添加规则，原来位置的规则后移\n\n  ```sh\n  $ iptables -t filter -I INPUT 1 -i lo -j DROP #在INPUT链头部添加规则，插入位置从1开始计算\n  ```\n\n- `-R` or `--replace` ：替换指定位置规则\n\n  ```sh\n  $ iptables -t filter -R INPUT 1 -i lo -j ACCEPT #修改INPUT链头部规则\n  ```\n\n- `-D` or `--delete`：删除指定位置规则\n\n  ```sh\n  $ iptables -t filter -D INPUT 2 #删除INPUT链第二条规则\n  ```\n\n###### 链管理命令\n\n- `-P` or `--policy`：改变指定链的默认策略，只有内置的链才有默认策略，自定义链没有默认策略\n\n  ```sh\n  $ iptables -P INPUT ACCEPT\n  ```\n\n- `-F` or `--flush` ：清空规则链的所有规则，如果省略规则链，则清空表上所有链的规则\n\n- `-N` or `--new`：创建自定义链\n\n- `-X` or `--delete-chain`：删除指定的链，这个链必须没有被其它任何规则引用，而且这条上必须没有任何规则。如果没有指定链名，则会删除该表中所有非内置的链。\n\n- `-E` or `--rename-chain`：用指定的新名字去重命名指定的链。这并不会对链内部照成任何影响。\n\n  ```sh\n  $ iptables -E oldName newName\n  ```\n\n- `-Z` or `--zero`：把指定链，或者表中的所有链上的所有计数器清零，计数器是规则命中计数。\n\n- `-L` or `--list`：查看指定链或者指定表上的所有规则\n\n###### 规则参数\n\n- `-t` or `--table`：指定操作的表，**如果不指定此选项，默认操作的是 `filter` 表**\n\n- `-p` or `--protocol`：指定协议\n\n- `-i` or `--in-interface`：network interface name，匹配流量流入的网络接口，只对`PREROUTING`、`INPUT`或者`FORWARD`生效；这里的网络接口不一定是网卡，比如`docker0`等虚拟网桥也可以；前缀`!`表示非，比如`! -i 127.0.0.1`表示非本机发送过来的数据包。\n\n- `-o` or `--out-interface`：network interface name，匹配流量输出的网络接口，只对`OUTPUT`、`FORWARD`或`POSTROUTING`生效\n\n- `-s` or `--source`：源地址，`ip`地址或者`CIDR`表示指定范围地址\n\n- `--sport `：匹配来源端口\n\n- `-d` or `--destination`：目标地址，`ip`地址或者`CIDR`表示指定范围地址\n\n- `--dport`：匹配目标端口\n\n- `-j` or `--jump`：规则目标，即满足规则时应该执行什么样的动作。目标可以是内置目标，也可以是用户自定义的链，内置的目标有：\n\n  - `ACCEPT`：接收数据包，如果当前规则匹配成功则结束当前链及父链（如果当前是自定义子链）\n  - `DROP`：丢弃数据包，不做任何响应。\n  - `REJECT`：拒绝当前包，会返回拒绝数据包。\n  - `REDIRECT`：重定向、映射、透明代理。\n  - `SNAT`：源地址转换。\n  - `DNAT`：目标地址转换。\n  - `MASQUERADE`：`IP`伪装（`NAT`），用于`ADSL`。\n  - `LOG`：日志记录，继续匹配下一个规则，不会结束当前链。\n\n- `-m` or `--match`：使用扩展包匹配模块，可以使用`man iptables-extensions`命令查看扩展模块\n\n  > iptables can use extended packet matching modules. **These are loaded in two ways: implicitly, when -p or --protocol is specified, or with the -m or --match options, followed by the matching module name**; after these, various extra command line options become available, depending on the specific module. You can specify multiple extended match modules in one line, and you can use the -h or --help options after the module has been specified to receive help specific to that module.\n\n  - `statistic`：基于一些统计条件匹配\n\n    ```sh\n    $ iptables -A INPUT -m statistic --mode random --probability 0.5 -s 127.0.0.1 -p icmp -j DROP # 来自本机的ping包，有50%的几率被丢弃\n    ```\n\n  - `comment`：允许添加注释（最多256给字符）\n\n    ```sh\n    $ iptables -A INPUT -m comment --comment \"a comment demo\" -j ACCEPT\n    ```\n\n\n\n### DNAT & SNAT\n\n##### SNAT\n\n`SNAT`: Source Network Address Translation，修改网络包源ip地址。\n\n比如内网机器只有私有ip，无法正常访问外网，可以在网关进行SNAT，将ip包的源地址替换为网关的公网ip，等请求返回的时候，网关再把返回的ip包的目标地址还原为原来的内网ip，然后由网关转发给具体的机器。\n\n`SNAT`是多对一的映射，比如多个内网机器同时映射同一个网关的公网ip，不同内网机器可能使用同一个源端口，系统是通过源IP，源端口，目标ip和目标端口和协议等5元组来区分不同的连接的，因此执行`SNAT`时，除了修改源ip，还需要重新分配源端口号。\n\n系统需要通过`SNAT`表来保存原来的ip/端口与转换后的ip/端口之间的映射关系，以便能够在数据流入流出时进行跟踪。\n\n在容器网络中，当容器内部主动向外部发起网络请求时，需要使用`SNAT`将容器ip替换成主机的ip。\n\n##### DNAT\n\n`DNAT`用于将内网机器的端口映射到外网。当网关接收到数据包时，通过DNAT将目标ip和端口替换成内网机器的ip和端口，然后进行转发。\n\n在容器网络中，容器的端口映射就是使用`DNAT`实现的。通过将容器的端口映射到主机端口上，当由数据包发送到该主机端口时，`netfilter`会将其替换成容器的ip和端口。","tags":["linux","iptables"]},{"title":"rs纠删码","url":"/2019/05/06/rs纠删码/","content":"\n# RS纠删码\n\n在存储系统中，需要采用数据冗余技术来保证数据的可靠性，相比使用多副本复制机制外，使用纠删码能够以更小的数据冗余度获得更高的数据可靠性。`Reed Solomon Coding`是存储领域常用的一种纠删码。\n\n### 基本原理\n\nRS纠删码将原始文件分成n个数据块，同时为这**n个数据块**生成**m个校验块**，而能够容忍最多丢失（只保证丢失而不保证数据篡改）这（n+m)个块中的任意m个数据或者校验块。\n\nRS编码以word为单位进行编码和解码（word字长一般为8或者16），而大的数据块拆分成一个个word进行编解码。\n\n假如有数据块内容为`ABCDEFGHIJKLMNOP`，将其分为四个数据块，每个数据块包含四个word（字长为8），我们使用矩阵来表示这四个数据块，对应的数据矩阵如下：\n\n![](/img/blog-rs-1.png)\n\n接着使用编码矩阵来对数据矩阵进行编码，产生数据块和校验块：\n\n![](/img/blog-rs-2.webp)\n\n上图左边的矩阵为编码矩阵，该矩阵由上面一个`4X4`的单位矩阵和下面一个`2X4`的`Vandermonder`矩阵组成。这里的`2`对应上面的`m`，表明需要生成2个校验块，`4`是因为原数据分成了4个数据块。我们可以看到右边经过编码矩阵处理后的结果，比原来的数据矩阵多了两行，即对应两个校验块。\n\n因为`m`取的是2，因此最多允许丢失2个块，这里我们假设`IJKL`和`MNOP`两个块被丢失了：\n\n![](/img/blog-rs-3.webp)\n\n我们在编码矩阵和结果矩阵将对应的第3，4行删除，等式两边仍然成立：\n\n![](/img/RS-post-pic-4.png)\n\n现在的编码矩阵是原来的一部分，我们将其记为`C1`，接着我们分别在两边乘以编码矩阵的逆矩阵：\n\n![](/img/RS-post-pic-5.png)\n\n![](/img/RS-post-pic-5-5.webp)\n\n![](/img/blog-rs-7.png)\n\n我们可以看到，我们可以从编码产生的6个块中的任意4个块中恢复原数据。\n\n### Vandermonder矩阵\n\n![](/img/Vandermonder.svg)\n\n在上面中，为了恢复原数据，需要计算编码矩阵（这里指的是`C1`）的逆矩阵，这也是为什么上面编码矩阵是由一个单位矩阵和一个`Vandermonder`矩阵组成的，因为`Vandermonder`矩阵任意两行之间都线性无关，可以求解出逆矩阵。\n\n### 伽罗华域\n\nRS纠删码是按照word为单位对数据进行编解码，这也就要求对一个字进行编码后，产生的结果仍然是一个字，因此RS纠删码基于伽罗华域[GF(2^n)](<http://mcll.top/2019/05/05/%E6%9C%89%E9%99%90%E5%9F%9F/>)及其四则运算来进行编解码。\n\n### 举个栗子\n\n这里使用`GF(2^4)`，并且取`n`和`m`都为3来举个例子。\n\n首先，`GF(2^4)`共有0~15这16个元素，首先构造`exp`表和`log`表：\n\n| i    | 0    | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   | 11   | 12   | 13   | 14   | 15   |\n| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |\n| log  | -    | 0    | 1    | 4    | 2    | 8    | 5    | 10   | 3    | 14   | 9    | 7    | 6    | 13   | 11   | 12   |\n| exp  | 1    | 2    | 4    | 8    | 3    | 6    | 12   | 11   | 5    | 10   | 7    | 14   | 15   | 13   | 9    | 1    |\n\n假设原始数据 D, Vandermonde 矩阵 F, 冗余数据 C，则：\n\n![](/img/blog-rs-demo1.png)\n\n上面计算矩阵F时，根据`GF(2^4)`的计算规则，3^2^ = 3*3 = exp(log(3)+log(3)) = 5\n\n将矩阵F与3*3的单位矩阵E集合，可得：\n\n![](/img/blog-rs-demo2.png)\n\n根据上面的定义，任意丢失3份数据，都可以恢复原来的数据，这里假设丢失了D2，D3和C3，则恢复过程：\n\n![](/img/blog-rs-demo3.png)\n\n可以看到，成功恢复原来的数据。\n\n\n\n\n### 参考\n\n- [RS纠删算法原理](<https://github.com/RobinLiew/RobinLiew.github.io/blob/master/%E7%AE%97%E6%B3%95/RS%E7%BA%A0%E5%88%A0%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8E%E9%A1%B9%E7%9B%AE%E6%BA%90%E7%A0%81.md>)\n- [Reed-Solomon 编码算法](<https://www.gaccob.com/publish/2017-08-27-reed-solomon.html>)\n- [reed-solomon](<https://www.backblaze.com/blog/reed-solomon/>)","tags":["rs纠删码"]},{"title":"有限域","url":"/2019/05/05/有限域/","content":"\n# Finite fields - 有限域\n\n有限域（`Finite fields`）是代数的一个分支，在加密算法、数据压缩算法和纠错算法中都有重要的作用。\n\n### 概念\n\n##### 域 - *field*\n\n如果集合`F`的所有元素与定义在其上的二元操作符`+`和` · `满足下面条件，即构成一个域：\n\n- 闭包（`Closure`）： 对于任意`F`中的元素`x`和`y`，`x+y`和`x·y`也都是`F`中的元素\n- 结合律（`Associative`)：对于`F`中的任意`x`，`y`和`z`，满足`(x+y)+z = x+(y+z)`和`(x·y)·z = x·(y·z)`\n- 交换律（`Commutative`）：对于`F`中的任意元素`x`和`y`，满足`x+y = y+x`和`x·y = y·x`\n- 分配率（`Distributive`）：对于`F`中的任意元素`x`，`y`和`z`，满足`x·(y+z) = (x·y)+(x·z)`\n- `Identity`：`F`中存在加法单位元，记作`0`，对`F`中的任意元素`x`满足`x+0 = x`；存在乘法单位元，记作`1`，对`F`中的任意元素`x`满足`x·1 = x`\n- `Inverse`：对`F`中的任意元素`x`，在`F`中都能找到对应的`y`满足`x+y = 0`，即`y = -x`，`x`与`y`互为负元；对于`F`中除`0`外的任意元素`x`，在`F`中都能找到对应的`y`满足`x·y = 1`，即`y = 1/x`，`x`与`y`互为逆元\n\n比如，实数集`R`与定义在其上的加法和乘法运算，就构成了一个域。\n\n但是整数集`Z`不是一个域，因为`Z`中的非零元素并不都有乘法逆元，比如`1/2`不在`Z`中。\n\n虽然`Z`不是一个域，但是**整数模上任意一个素数的集合可以构成一个域**。比如`mod 5`的集合是`{0, 1, 2, 3, 4}`，记为`Z/5`，对应的`+`运算为`(x+y)%5`，`·`为`(x·y)%5`，这时候加法单位元是`0`，乘法单位元是`1`，可以发现，`(2*3)%5 = 1`，所以`2`的乘法逆元为`3`\n\n**对于任意一个素数`p`，`Z/p`是一个域，`+`运算为`(x+y) % p`，`·`运算为`(x·y) %p`**\n\n##### 有限域 - *finite field*\n\n如果一个域的元素个数是有限的，那么这个域称为有限域。\n\n作为一个程序员，我们接触到最多的有限域是`Z/2`，只包含`0`和`1`两个元素。`+`运算即为`XOR`，而`·`运算为`AND`。\n\n### 多项式\n\n早在19世纪初期，数学家最开始提出域的概念就是为了构造多项式。\n\n我们引入一个符合变量`x`，那么所有使用域`F`内的元素作为系数与`x`构成的多项式的集合，记为`F[x]`。\n\n例如，如果我们使用`R`作为构造多项式的域，那么`x^2+1`、`x+2`、`3.14x^2-2.72x+1.41`等都属于`R[x]`。同整数一样，多项式也可以有加法和乘法运算，但不总是有除法运算，比如无法得出`(x^2+1)/(x+2)`的结果，因此`R[x]`并不是一个域，因为`1/(x+2)`可以看成是`(x+2)`的逆元，但是并不属于`R[x]`中。\n\n然而，正如整数模上任意一个素数构成的集合可以构成一个域，**多项式模上一个素多项式构成的集合可以构成域**\n\n**素多项式（`prime polynomial`）：系数为整数并且不能被因式分解成低阶多项式。**比如上面的`x^2+1`，在实数范围内不可被因式分解。因此，`R[x]/(x^2+1)`就是一个域，这个域中的多项式中`x`的最高次幂最大只能是`1`\n\n对于域`Z/p`，`mod`一个`n`次素多项式`f(x)`的结果为一个具有`p^n`个元素的域`(Z/p)[x]/f(x)`。关于`f(x)`这个素多项式的选择并不重要，因为任意两个大小为`p^n`的有限域具有相同的结构，**将大小为`p^n`的有限域记为`GF(p^n)`。**\n\n对于多项式，例如`x^8+x^4+x^3+x+1`，我们可以看作是一个向量`[1,0,0,0,1,1,0,1,1]`。\n\n### GF(2^n)\n\n作为程序员，对我们来说最有趣的是`GF(2^n)`，即`Z/2`的多项式扩展，因为`GF(2^n)`的元素为长度为`n`的位向量。\n\n例如，`(Z/2)[x]/(x^8+x^4+x^3+x+1)`，这个域共有`2^8`个元素，每一个元素为一个长度为`8`的位向量，代表一个单字节：一个字节的二进制形式 *b~7~b~6~b~5~b~4~b~3~b~2~b~1~b~0~* 代表多项式 *b~7~x^7^+b~6~x^6^+b~5~x^5^+b~4~x^4^+b~3~x^3^+b~2~x^2^+b~1~x+b~0~*。\n\n##### 加法操作\n\n多项式的加法操作，即把相同次数的项系数相加，因为系数是`Z/2`的元素，因此系数相加意味着`XOR`操作\n\n```\n(x^2 + x) + (x + 1) = x^2 + 2x + 1 = x^2 + 1\n```\n\n换成二进制形式：*110~2~+011~2~=101~2~*\n\n##### 乘法操作\n\n多项式的乘法操作比较复杂，需要基于加法的`XOR`操作\n\n```\n(x^2 + x) · (x + 1) = x^3 + x^2 + x^2 + x = x^3 + x\n```\n\n换成二进制形式，具体的计算过程如下：\n\n```\n     110\n x   011\n---------\n     110\n    110\n + 000\n---------\n   01010\n```\n\n计算后的结果可能溢出，需要模上对应的素多项式，比如 *(Z/2)[x]/(x^8^+x^4^+x^3^+x+1)*这个域内的元素的乘法，最后的结果需要模上素多项式式*x^8^+x^4^+x^3^+x+1*。\n\n我们可以看到，上面的乘法过程中，需要分别执行`n`次乘法和加法，这个`n`为具体位向量的长度。而在实际实现域的乘法时，我们会使用查找表来进行优化。这里的查找表不是说建立例如九九乘法表那样的表格，在介绍具体的优化原理之前，需要先介绍一下**生成元**的概念。\n\n**在一个有限域中，至少存在一个元素α，使得域内任意一个非零元素都可以表示为该元素的方幂**。\n\n**假设一个有限域的非零元素个素为n，并且一个生成元为α，那么 α^n^ = 1**。\n\n例如，2是 *Z/5* 的一个生成元，{α, α^2^, α^3^, α^4^} = {2, 4, 3, 1}。对于`GF(p^n)`计算会更复杂，但是同样生效。\n\n通过生成元`α`，域中的任意非零元素都可以表示为`α`的方幂，我们就可以将元素的乘法转换为幂的加法。因此，**我们在实现乘法时，可以先生成一张`exp`表和一张`log`表，其中 *exp[i] = α^i^*， 而 *log[α^i^] = i*。通过这两张查找表，针对非零元素a和b的乘法可以转换为：*a·b = exp[log[a] + log[b]]*，只需要执行1次加法和3次查表操作即可。**\n\n\n\n### Code\n\n因为`GF(2^8)`中一个元素就是一个长度为8的位向量，正好是一个字节大小，因此`GF(2^8)`在计算机科学中使用最广泛。现在来实现一下`GF(2^8)`的运算。\n\n首先定义一个域，包含用来优化乘法运算的`exp`表和`log`表和素多项式：\n\n```go\ntype Field struct {\n\tpoly int\n\texp  [255]byte\n\tlog  [256]byte // log[0] is unused\n}\n```\n\n构造函数的实现，需要传入一个素多项式和生成元，`x^8+x^4+x^3+x+1`是`GF(2^8)`最广泛使用的素多项式，对于的二进制为`100011011`，对于十进制为`283`，`3`是`GF(2^8)`的一个生成元。\n\n```go\nfunc NewField(poly, a int) *Field {\n\tvar f Field\n\tx := 1\n    // 填充exp和log表\n\tfor i := 0; i < 255; i++ {\n\t\tf.exp[i] = byte(x)\n\t\tf.log[x] = byte(i)\n\t\tx = mul(x, a, poly)\n\t}\n\tf.poly = poly\n\treturn &f\n}\n\nfunc mul(x, y, poly int) int {\n\tz := 0\n\tfor x > 0 {\n\t\tif x&1 != 0 {\n\t\t\tz ^= y\n\t\t}\n\t\tx >>= 1\n\t\ty <<= 1\n\t\tif y&0x100 != 0 {\n\t\t\ty ^= poly\n\t\t}\n\t}\n\treturn z\n}\n```\n\n两个查表方法：\n\n```go\nfunc (f *Field) Exp(e int) byte {\n\tif e < 0 {\n\t\treturn 0\n\t}\n\treturn f.exp[e%255] // e^255 = 1\n}\n\nfunc (f *Field) Log(x byte) int {\n\tif x == 0 {\n\t\treturn -1\n\t}\n\n\treturn int(f.log[x])\n}\n```\n\n优化后的乘法运算就是`exp[log[a]+log[b]]`：\n\n```go\nfunc (f *Field) Mul(a, b byte) byte {\n\tif a == 0 || b == 0 {\n\t\treturn 0\n\t}\n\treturn f.Exp(f.Log(a) + f.Log(b))\n}\n```\n\n加法操作就是异或操作：\n\n```go\nfunc (f *Field) Add(a, b byte) byte {\n\treturn a ^ b\n}\n```\n\n求乘法逆元：\n\n```go\nfunc (f *Field) Inv(x byte) byte {\n\tif x == 0 {\n\t\treturn 0\n\t}\n\treturn f.Exp(255 - f.Log(x))\n}\n```\n\n\n\n### 参考\n\n- [Finite Field Arithmetic and Reed-Solomon Coding](<https://research.swtch.com/field>)\n\n","tags":["代数"]},{"title":"go函数栈布局","url":"/2019/04/29/go函数栈布局/","content":"\n# Go函数调用布局\n\n### 函数具有局部变量（栈帧大小大于0）\n\n![](/img/go-func-statck1.png)\n\n从上图我们可以看到，函数调用时，参数和返回值是通过栈来传递的，通过栈来传递函数，能够很好的实现多返回值，而且当发生`goroutine`的调度时，只需要切换`SP/BP`等少量寄存器，而不需要对通用寄存器进行切换，而且，当我们使用**命名返回值**时，是直接在对应的栈上进行更新，因此我们可以在`defer`函数内更新返回值。\n\n##### 测试代码\n\n```go\nfunc frameInfo(i int) (uintptr, uintptr, uintptr, uintptr,int,int)\nfunc main() {\n\tfmt.Println(frameInfo(15))\n}\n```\n\n```assembly\nTEXT ·frameInfo(SB),$8-54 // 这里8表示函数局部栈帧8个字节，参数和返回值共54个字节\n    MOVQ SP, AX // 取硬件寄存器SP的内容，作为第一个返回值\n    MOVQ AX, ret0+8(FP)\n    LEAQ i+0(SP), AX // 取pseudo_sp的值，作为第二个返回值\n    MOVQ AX, ret2+16(FP)\n    MOVQ BP, AX  // 取硬件寄存器BP的值，作为第三个返回值\n    MOVQ AX, ret1+24(FP)\n    LEAQ i+0(FP), AX // 取pseudo_fp的值，作为第四个返回值\n    MOVQ AX, ret3+32(FP)\n    MOVQ i+0(FP), AX // 通过伪寄存器fp获取参数i作为第五个返回值\n    MOVQ AX, ret4+40(FP)\n    MOVQ i+16(SP), AX // 通过伪寄存器sp获取参数i作为第六给返回值\n    MOVQ AX, ret5+48(FP)\n    RET\n\n```\n\n查看输出内容：\n\n```sh\n$ go run .\n824634146480 824634146488 824634146488 824634146504 15 15\n```\n\n可以看到伪寄存器`SP`和栈底寄存器`BP`指向的是同一个地址，而伪寄存器`FP`比伪寄存器`SP`大`16`个字节，其中高`8`个字节保存函数的返回地址，而低`8`个字节保存函数调用者的`BP`；而硬件`SP`和伪寄存器`SP\t`之间相差的字节数刚好是函数栈帧（这里的函数栈帧不包含保存调用者`BP`的`8`个字节）的大小，可以通过调整函数的局部栈帧大小观察其关系\n\n```assembly\nTEXT ·frameInfo(SB),$16-54 // 调整栈帧大小为16字节\n```\n\n查看输出内容：\n\n```sh\n$ go run .\n824634187432 824634187448 824634187448 824634187464 15 15\n```\n\n可以看到，新的输出中，硬件`SP`和伪寄存器`SP`之间相差为`16`字节，正好为栈帧大小。\n\n\n\n### 函数栈帧大小为0\n\n当函数栈帧大小为`0`时，情况就有点不同了。\n\n因为这个时候，当前函数没有分配栈帧，因此硬件寄存器`BP`不需要保存当前函数栈的栈底，也就不需要在栈上额外分配一个`8`字节的空间来保存函数调用者的`BP`寄存器内容，也就是说当前`BP`寄存器直接保存的就是函数调用者的`BP`寄存器信息。\n\n这时候的栈结构：\n\n![](/img/go-func-statck2.png)\n\n##### 测试代码\n\n```go\nfunc getBp() (uintptr, uintptr)\nfunc zeroFrame(i int) (uintptr, uintptr, uintptr, uintptr, int, int, uintptr)\nfunc main() {\n\tfmt.Println(getBp())\n\tfmt.Println(zeroFrame(11))\n}\n```\n\n```assembly\nTEXT ·getBp(SB),$8-16\n    MOVQ 0(BP), AX // 获取调用者函数的栈底地址\n    MOVQ AX, ret0+0(FP)\n    MOVQ ra+8(SP), AX // 获取当前函数的返回地址\n    MOVQ AX, ret0+8(FP)\n    RET\n\nTEXT ·zeroFrame(SB),$0-64\n    MOVQ SP, AX // 取硬件寄存器SP的内容，作为第一个返回值\n    MOVQ AX, ret0+8(FP)\n    LEAQ i+0(SP), AX // 取pseudo_sp的值，作为第二个返回值\n    MOVQ AX, ret1+16(FP)\n    MOVQ BP, AX  // 取硬件寄存器BP的值，作为第三个返回值\n    MOVQ AX, ret2+24(FP)\n    LEAQ i+0(FP), AX // 取pseudo_fp的值，作为第四个返回值\n    MOVQ AX, ret3+32(FP)\n    MOVQ i+0(FP), AX // 通过伪寄存器fp获取参数i作为第五个返回值\n    MOVQ AX, ret4+40(FP)\n    MOVQ i+8(SP), AX // 通过伪寄存器sp获取参数i作为第六给返回值\n    MOVQ AX, ret5+48(FP)\n    MOVQ addr+0(SP), AX // 获取当前函数的返回地址\n    MOVQ AX, ret6+56(FP)\n    RET\n\n```\n\n查看输出内容：\n\n```sh\n$ go run .\n824634187656 4776270\n824634187392 824634187392 824634187656 824634187400 11 11 4776438\n```\n\n函数`getBp`返回了调用者也即`main`函数的栈底信息，和当前函数的返回地址\n\n然后调用函数`zeroFrame`，该函数栈帧大小为`0`，可以看到执行该函数时，`BP`寄存器依然是`824634187656`，而且硬件寄存器`SP`和伪寄存器`SP`指向同一个位置，并且和伪寄存器`FP`只相差`8`个字节，而这`8`个字节保存的是当前函数的返回地址，我们可以看到两个函数的返回地址是在同一个段中的。","tags":["go"]},{"title":"mutex解析","url":"/2019/04/14/go中的锁实现探究/","content":"\n`go`的基础包`sync`提供了两种锁的实现，分别是`Mutex`和`RWMutex`。其中`Mutex`是互斥锁，一次只允许一个协程获取锁，`RWMutex`是读写锁，允许同时有多个协程获取读锁，但是只能有一个协程获取读锁，并且读写互斥。\n\n### Mutex\n\n好习惯，看源码先看注释：\n\n```\n// Mutex fairness.\n//\n// Mutex can be in 2 modes of operations: normal and starvation.\n// In normal mode waiters are queued in FIFO order, but a woken up waiter\n// does not own the mutex and competes with new arriving goroutines over\n// the ownership. New arriving goroutines have an advantage -- they are\n// already running on CPU and there can be lots of them, so a woken up\n// waiter has good chances of losing. In such case it is queued at front\n// of the wait queue. If a waiter fails to acquire the mutex for more than 1ms,\n// it switches mutex to the starvation mode.\n//\n// In starvation mode ownership of the mutex is directly handed off from\n// the unlocking goroutine to the waiter at the front of the queue.\n// New arriving goroutines don't try to acquire the mutex even if it appears\n// to be unlocked, and don't try to spin. Instead they queue themselves at\n// the tail of the wait queue.\n//\n// If a waiter receives ownership of the mutex and sees that either\n// (1) it is the last waiter in the queue, or (2) it waited for less than 1 ms,\n// it switches mutex back to normal operation mode.\n//\n// Normal mode has considerably better performance as a goroutine can acquire\n// a mutex several times in a row even if there are blocked waiters.\n// Starvation mode is important to prevent pathological cases of tail latency.\n```\n\n##### 结构声明\n\n首先我们来看一下`Mutex`的声明\n\n```go\ntype Mutex struct {\n\tstate int32 \n\tsema  uint32  \n}\n```\n\n可以看到，`Mutex`只包含两个字段，其中`state`用于记录锁的状态，第一位表示锁是否被占用，第二位表示当前是否有未阻塞的协程在抢占锁，第三位表示是否处于饥饿模式，从第四位到第32位则用于记录当前阻塞在等待锁的协程数量；而`sema`是用于在多个协程之间进行同步的信号量，这个后面再说。\n\n##### 抢占锁\n\n我们首先来看一下`Lock`方法实现：\n\n```go\n// Lock locks m.\n// If the lock is already in use, the calling goroutine\n// blocks until the mutex is available.\nfunc (m *Mutex) Lock() {\n\t// 首先先尝试获取unlock的锁\n    if atomic.CompareAndSwapInt32(&m.state, 0, mutexLocked) {\n        // 竞争检查，忽略。。。\n\t\tif race.Enabled {\n\t\t\trace.Acquire(unsafe.Pointer(m))\n\t\t}\n        // 表示cas操作成功，获取锁，直接返回\n\t\treturn\n\t}\n\t\n    // 记录开始等待的时间\n\tvar waitStartTime int64\n\t// 是否处于饥饿模式\n    starving := false\n    // 是否有运行中的抢占锁的协程\n\tawoke := false\n    // 记录自旋次数\n\titer := 0\n    // 获取当前的状态\n\told := m.state\n\tfor {\n\t\t// 如果当前锁处于Locked状态，并且允许自旋，则进入自旋状态\n        // 允许自旋的条件：不处于饥饿模式，自旋次数小于4，running on a multicore machine and GOMAXPROCS>1 and there is at least one other running P and local runq is empty\n\t\tif old&(mutexLocked|mutexStarving) == mutexLocked && runtime_canSpin(iter) {\n\t\t\t// 更新state的第二位，表示当前有运行中的协程在抢占锁\n\t\t\tif !awoke && old&mutexWoken == 0 && old>>mutexWaiterShift != 0 &&\n\t\t\t\tatomic.CompareAndSwapInt32(&m.state, old, old|mutexWoken) {\n\t\t\t\tawoke = true\n\t\t\t}\n            // 执行自旋，所谓自旋，就是一种busy wait，当前协程不阻塞，等待一会儿重新尝试获取锁，这里的doSpin是在runtime包中实现的\n\t\t\truntime_doSpin()\n\t\t\titer++ // 添加自旋次数\n\t\t\told = m.state\n\t\t\tcontinue \n\t\t}\n\t\tnew := old\n\t\t// 如果不处于饥饿模式，设置状态位尝试获取锁\n        if old&mutexStarving == 0 {\n\t\t\tnew |= mutexLocked\n\t\t}\n        // 如果已经锁住或者处于饥饿模式，阻塞的协程数量加1\n\t\tif old&(mutexLocked|mutexStarving) != 0 {\n\t\t\tnew += 1 << mutexWaiterShift\n\t\t}\n\t\t// 如果需要进入饥饿状态，则设置饥饿标志位\n\t\tif starving && old&mutexLocked != 0 {\n\t\t\tnew |= mutexStarving\n\t\t}\n        // 清除awoke状态位\n\t\tif awoke {\n\t\t\t// The goroutine has been woken from sleep,\n\t\t\t// so we need to reset the flag in either case.\n\t\t\tif new&mutexWoken == 0 {\n\t\t\t\tthrow(\"sync: inconsistent mutex state\")\n\t\t\t}\n\t\t\tnew &^= mutexWoken\n\t\t}\n        // cas更新锁状态\n\t\tif atomic.CompareAndSwapInt32(&m.state, old, new) {\n            // 更新成功，并且原来锁为unlock并且不属于饥饿模式，直接返回\n            // 这种情况是锁处于正常模式，新的协程与旧的协程竞争锁，并且竞争成功\n\t\t\tif old&(mutexLocked|mutexStarving) == 0 {\n\t\t\t\tbreak // locked the mutex with CAS\n\t\t\t}\n\t\t\t// 如果waitStartTime大于0，表示当协程原来阻塞等待锁，现在被唤醒了\n\t\t\tqueueLifo := waitStartTime != 0\n            // 设置开始等待时间\n\t\t\tif waitStartTime == 0 {\n\t\t\t\twaitStartTime = runtime_nanotime()\n\t\t\t}\n            // 当前协程抢占锁失败，阻塞等待，这里需要传入信号量sema和queueLifo\n            // 信号量sema用来在多个协程之间同步\n            // queueLifo如果为true，表示当前协程与新的协程竞争锁失败，加入队首，否则加入队尾\n\t\t\truntime_SemacquireMutex(&m.sema, queueLifo)\n            // 执行到这里表明协程被从等待队列中唤醒了\n            // 如果等待时间大于1ms则进入饥饿模式\n\t\t\tstarving = starving || runtime_nanotime()-waitStartTime > starvationThresholdNs\n\t\t\told = m.state\n            // 当前锁处于饥饿模式，表明没有其他协程会与当前协程竞争锁\n\t\t\tif old&mutexStarving != 0 {\n\t\t\t\t// 检查状态位\n\t\t\t\tif old&(mutexLocked|mutexWoken) != 0 || old>>mutexWaiterShift == 0 {\n\t\t\t\t\tthrow(\"sync: inconsistent mutex state\")\n\t\t\t\t}\n                // 更新状态位，饥饿模式，只有当前协程能够抢占锁\n                // 阻塞等待锁的协程数量需要减1\n\t\t\t\tdelta := int32(mutexLocked - 1<<mutexWaiterShift)\n                // 如果不需要进入饥饿模式，或者当前等待队列为空，则清空饥饿模式\n\t\t\t\tif !starving || old>>mutexWaiterShift == 1 {\n\t\t\t\t\tdelta -= mutexStarving\n\t\t\t\t}\n                // 这里使用原子Add而不是CAS操作，因为可能在这个时刻有新的协程因为等待锁而阻塞，这时候如果使用CAS会失败\n\t\t\t\tatomic.AddInt32(&m.state, delta)\n\t\t\t\tbreak // 返回\n\t\t\t}\n            // 当前锁处于正常模式，因此需要和新加入的协程竞争锁\n\t\t\tawoke = true\n\t\t\titer = 0\n\t\t} else { // cas失败，重试\n\t\t\told = m.state\n\t\t}\n\t}\n\n\tif race.Enabled {\n\t\trace.Acquire(unsafe.Pointer(m))\n\t}\n}\n```\n\n接下来我们看一下`runtime_SemacquireMutex`这个方法，该方法的实现在`runtime`包中：\n\n```go\n// 这里使用`go:linkname`告诉链接器将该方法与sync包的runtime_SemacquireMutex方法链接\n//go:linkname sync_runtime_SemacquireMutex sync.runtime_SemacquireMutex\nfunc sync_runtime_SemacquireMutex(addr *uint32, lifo bool) {\n\tsemacquire1(addr, lifo, semaBlockProfile|semaMutexProfile)\n}\n\nfunc semacquire1(addr *uint32, lifo bool, profile semaProfileFlags) {\n    // 获取当前g\n\tgp := getg()\n    // 不允许在系统栈执行Lock方法\n\tif gp != gp.m.curg {\n\t\tthrow(\"semacquire not on the G stack\")\n\t}\n\n\t// 尝试捕获信号量，成功则直接返回\n\tif cansemacquire(addr) {\n\t\treturn\n\t}\n\t\n    // sudog用来表示一个阻塞的g，同一个锁的等待协程会构成一条sudog链表，多条链表会组织成一颗平衡树\n\ts := acquireSudog()\n   // 通过sema的地址获取对应的root，一个root中有多个sema的等待队列\n\troot := semroot(addr)\n\tt0 := int64(0)\n\ts.releasetime = 0\n\ts.acquiretime = 0\n\ts.ticket = 0\n\tif profile&semaBlockProfile != 0 && blockprofilerate > 0 {\n\t\tt0 = cputicks()\n\t\ts.releasetime = -1\n\t}\n\tif profile&semaMutexProfile != 0 && mutexprofilerate > 0 {\n\t\tif t0 == 0 {\n\t\t\tt0 = cputicks()\n\t\t}\n\t\ts.acquiretime = t0\n\t}\n\tfor {\n\t\tlock(&root.lock)\n\t\t// Add ourselves to nwait to disable \"easy case\" in semrelease.\n\t\tatomic.Xadd(&root.nwait, 1)\n\t\t// 再次尝试捕获信号量\n\t\tif cansemacquire(addr) {\n\t\t\tatomic.Xadd(&root.nwait, -1)\n\t\t\tunlock(&root.lock)\n\t\t\tbreak\n\t\t}\n\t\t// 加入等待队列，一个root内有多个等待队列，这些等待队列通过平衡树来组织，等待队列通过addr来标识，每个等待队列就是一个sudog列表\n\t\troot.queue(addr, s, lifo)\n        // 阻塞当前g\n\t\tgoparkunlock(&root.lock, waitReasonSemacquire, traceEvGoBlockSync, 4)\n\t\t// g被唤醒，如果ticket不为0或者再次尝试捕获信号量成功\n        if s.ticket != 0 || cansemacquire(addr) {\n\t\t\tbreak // 捕获成功\n\t\t}\n\t}\n\tif s.releasetime > 0 {\n\t\tblockevent(s.releasetime-t0, 3)\n\t}\n    // 释放sudog\n\treleaseSudog(s)\n}\n```\n\n##### 释放锁\n\n现在来看一下`Unlock`方法实现：\n\n```go\nfunc (m *Mutex) Unlock() {\n\tif race.Enabled {\n\t\t_ = m.state\n\t\trace.Release(unsafe.Pointer(m))\n\t}\n\n\t// Fast path: drop lock bit.\n    // 清空锁状态\n\tnew := atomic.AddInt32(&m.state, -mutexLocked)\n    // 检查状态位\n\tif (new+mutexLocked)&mutexLocked == 0 {\n\t\tthrow(\"sync: unlock of unlocked mutex\")\n\t}\n    // 如果不处于饥饿模式\n\tif new&mutexStarving == 0 {\n\t\told := new\n\t\tfor {\n\t\t\t// 如果没有阻塞等待的队列，或者当前有woken的锁等待者，直接返回\n\t\t\tif old>>mutexWaiterShift == 0 || old&(mutexLocked|mutexWoken|mutexStarving) != 0 {\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// 唤醒一个等待的协程，参与锁竞争\n\t\t\tnew = (old - 1<<mutexWaiterShift) | mutexWoken\n\t\t\tif atomic.CompareAndSwapInt32(&m.state, old, new) {\n\t\t\t\truntime_Semrelease(&m.sema, false)\n\t\t\t\treturn\n\t\t\t}\n\t\t\told = m.state\n\t\t}\n\t} else {\n\t\t// 当前处于饥饿模式，从等待队列唤醒协程\n\t\truntime_Semrelease(&m.sema, true)\n\t}\n}\n```\n\n接下来看一下`runtime_Semrelease`方法：\n\n```go\n//go:linkname sync_runtime_Semrelease sync.runtime_Semrelease\nfunc sync_runtime_Semrelease(addr *uint32, handoff bool) {\n\tsemrelease1(addr, handoff)\n}\n\nfunc semrelease1(addr *uint32, handoff bool) {\n\troot := semroot(addr)\n\tatomic.Xadd(addr, 1) // addr值加1\n\n\t// Easy case: no waiters?\n\t// This check must happen after the xadd, to avoid a missed wakeup\n\t// (see loop in semacquire).\n\tif atomic.Load(&root.nwait) == 0 {\n\t\treturn\n\t}\n\n\t// Harder case: search for a waiter and wake it.\n\tlock(&root.lock)\n\tif atomic.Load(&root.nwait) == 0 {\n\t\t// The count is already consumed by another goroutine,\n\t\t// so no need to wake up another goroutine.\n\t\tunlock(&root.lock)\n\t\treturn\n\t}\n    // 从队首获取等待的sudog\n\ts, t0 := root.dequeue(addr)\n\tif s != nil {\n\t\tatomic.Xadd(&root.nwait, -1)\n\t}\n\tunlock(&root.lock)\n\tif s != nil { // May be slow, so unlock first\n\t\tacquiretime := s.acquiretime\n\t\tif acquiretime != 0 {\n\t\t\tmutexevent(t0-acquiretime, 3)\n\t\t}\n\t\tif s.ticket != 0 {\n\t\t\tthrow(\"corrupted semaphore ticket\")\n\t\t}\n        // 如果handoff为true，则尝试捕获信号量\n\t\tif handoff && cansemacquire(addr) {\n            // 成功，则更新ticket为1\n\t\t\ts.ticket = 1\n\t\t}\n        // 唤醒g\n\t\treadyWithTime(s, 5)\n\t}\n}\n```\n\n\n\n### RWMutex\n\n现在来看一下`RWMutex`，同样都，先看注释：\n\n```\n// A RWMutex is a reader/writer mutual exclusion lock.\n// The lock can be held by an arbitrary number of readers or a single writer.\n// The zero value for a RWMutex is an unlocked mutex.\n//\n// A RWMutex must not be copied after first use.\n//\n// If a goroutine holds a RWMutex for reading and another goroutine might\n// call Lock, no goroutine should expect to be able to acquire a read lock\n// until the initial read lock is released. In particular, this prohibits\n// recursive read locking. This is to ensure that the lock eventually becomes\n// available; a blocked Lock call excludes new readers from acquiring the\n// lock.\n```\n\n##### 结构声明\n\n```go\ntype RWMutex struct {\n\tw           Mutex  // held if there are pending writers\n\twriterSem   uint32 // semaphore for writers to wait for completing readers\n\treaderSem   uint32 // semaphore for readers to wait for completing writers\n\treaderCount int32  // number of pending readers\n\treaderWait  int32  // number of departing readers\n}\n```\n\n\n\n##### 抢占读锁\n\n```go\nfunc (rw *RWMutex) RLock() {\n   if race.Enabled {\n      _ = rw.w.state\n      race.Disable()\n   }\n    // readCount加1，如果小于0，表明当前有写锁正在等待，则阻塞等待\n   if atomic.AddInt32(&rw.readerCount, 1) < 0 {\n      // A writer is pending, wait for it.\n      runtime_SemacquireMutex(&rw.readerSem, false)\n   }\n   if race.Enabled {\n      race.Enable()\n      race.Acquire(unsafe.Pointer(&rw.readerSem))\n   }\n}\n```\n\n##### 释放读锁\n\n```go\nfunc (rw *RWMutex) RUnlock() {\n   if race.Enabled {\n      _ = rw.w.state\n      race.ReleaseMerge(unsafe.Pointer(&rw.writerSem))\n      race.Disable()\n   }\n    // readerCount减1，小于0说明有等待写\n   if r := atomic.AddInt32(&rw.readerCount, -1); r < 0 {\n      if r+1 == 0 || r+1 == -rwmutexMaxReaders {\n         race.Enable()\n         throw(\"sync: RUnlock of unlocked RWMutex\")\n      }\n      // A writer is pending.\n       // readerWait减1，如果为0表示读锁释放完，唤醒等待读\n      if atomic.AddInt32(&rw.readerWait, -1) == 0 {\n         // The last reader unblocks the writer.\n         runtime_Semrelease(&rw.writerSem, false)\n      }\n   }\n   if race.Enabled {\n      race.Enable()\n   }\n}\n```\n\n##### 抢占写锁\n\n```go\nfunc (rw *RWMutex) Lock() {\n\tif race.Enabled {\n\t\t_ = rw.w.state\n\t\trace.Disable()\n\t}\n\t// First, resolve competition with other writers.\n\trw.w.Lock()\n\t// Announce to readers there is a pending writer.\n\tr := atomic.AddInt32(&rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders\n\t// Wait for active readers.\n\tif r != 0 && atomic.AddInt32(&rw.readerWait, r) != 0 {\n\t\truntime_SemacquireMutex(&rw.writerSem, false)\n\t}\n\tif race.Enabled {\n\t\trace.Enable()\n\t\trace.Acquire(unsafe.Pointer(&rw.readerSem))\n\t\trace.Acquire(unsafe.Pointer(&rw.writerSem))\n\t}\n}\n```\n\n##### 释放写锁\n\n ```go\nfunc (rw *RWMutex) Unlock() {\n\tif race.Enabled {\n\t\t_ = rw.w.state\n\t\trace.Release(unsafe.Pointer(&rw.readerSem))\n\t\trace.Disable()\n\t}\n\n\t// Announce to readers there is no active writer.\n\tr := atomic.AddInt32(&rw.readerCount, rwmutexMaxReaders)\n\tif r >= rwmutexMaxReaders {\n\t\trace.Enable()\n\t\tthrow(\"sync: Unlock of unlocked RWMutex\")\n\t}\n\t// Unblock blocked readers, if any.\n\tfor i := 0; i < int(r); i++ {\n\t\truntime_Semrelease(&rw.readerSem, false)\n\t}\n\t// Allow other writers to proceed.\n\trw.w.Unlock()\n\tif race.Enabled {\n\t\trace.Enable()\n\t}\n}\n ```\n\n","tags":["go"]},{"title":"go网络io模型分析","url":"/2019/04/07/go网络io模型分析/","content":"\n在过去，传统的网络编程模型是多线程模型，在主线程中开启一个网络监听，然后每次有一个客户端进行连接，就会单独开启一个线程来处理这个客户端请求。\n\n然而，如果并发量比较大，服务端就会创建大量的线程，而且会有大量的线程阻塞在网络IO上，频繁的线程上下文切换会占用大量的cpu时间片，严重影响服务性能，而且大量的线程也需要占用大量的系统资源\n\n这样就引出著名的`C10K`问题，如何在单台服务器上支持并发`10K`量级的连接\n\n我们知道，虽然同一时间有大量的并发连接，但是同一时刻，只有少数的连接是可读/写的，我们完全可以只使用一个线程来服务提供服务，这也是目前解决`C10K`问题的主要思路，对应的解决方案叫做**IO多路复用**，现在主流的高性能网络服务器/框架都是基于该网络模型，比如`nginx`、`redis`或者`netty`网络库等。\n\n说到这，就不得不提[`epoll`](<http://man7.org/linux/man-pages/man7/epoll.7.html>)，这是`linux`内核提供的用于实现**IO多路复用**的系统调用，其他操作系统上也有类似的接口，关于`epoll`具体内容网上有一大堆的[资料](<http://man7.org/linux/man-pages/man7/epoll.7.html>)，这里就不重复介绍了\n\n**IO多路复用模型**，也可以称作是**事件驱动模型**，虽然能够有效解决`C10K`问题，但是相对传统的多线程模型也带来了一点复杂性。比如说，在多线程模型下，每个连接独占一个线程，而线程本身有自己的上下文；而如果是IO多路复用模型，需要在一个线程中处理多个连接，而每个需要有自己的上下文，需要开发者手动管理。比如服务端还没有接收到一个完整的协议报文时，我们需要把先前接收的部分内容保存到当前连接上下文中，等到下次其余内容到底时再一起处理。\n\n今天，我们主要来看一下`go`中的网络模型。\n\n在`go`中我们可以像传统的多线程模型那样为每个网络连接单独使用一个`goroutine`来提供服务，但是`goroutine`的资源占用相比系统级线程来说非常小，而且其切换在运行在用户态的，并且只需要交换很少的寄存器，因此`goroutine`的上下文切换代价也是极小的，更重要的是，其底层也是基于`epoll`（linux系统下）来实现事件通知的，因此只需要占用很少的系统级线程。\n\n很明显可以看出，`go`中的网络IO模型是传统多线程模型和IO多路复用模型的结合，既有前者的易用性，又有后者的效率，因此使用`go`可以很容易地开发高性能服务器。\n\n今天我们就来看一下，`go`中的网络IO模型是如何实现的。\n\n### 一切从创建Listener开始\n\n我们从创建`Listener`开始说起。\n\n先看下面代码：\n\n```go\nln,_ :=net.Listen(\"tcp\",\":80\")\n```\n\n我们使用`Listen`来创建一个`Listener`，那么底层具体会发生什么呢？让我们一步一步来揭开\n\n首先查看`net.Listen`方法\n\n```go\nfunc Listen(network, address string) (Listener, error) {\n\tvar lc ListenConfig\n\treturn lc.Listen(context.Background(), network, address)\n}\n```\n\n可以看到实际上工作的是`ListenConfig.Listen`,我们继续往下看：\n\n```go\nfunc (lc *ListenConfig) Listen(ctx context.Context, network, address string) (Listener, error) {\n    ...\n\tvar l Listener\n\tla := addrs.first(isIPv4)\n\tswitch la := la.(type) {\n\tcase *TCPAddr:\n\t\tl, err = sl.listenTCP(ctx, la)\n\t...\n\treturn l, nil\n}\n```\n\n因为我们创建的是`tcp`连接，这里我们只关注`sl.listenTCP`方法，继续往下\n\n```go\nfunc (sl *sysListener) listenTCP(ctx context.Context, laddr *TCPAddr) (*TCPListener, error) {\n\tfd, err := internetSocket(ctx, sl.network, laddr, nil, syscall.SOCK_STREAM, 0, \"listen\", sl.ListenConfig.Control)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &TCPListener{fd}, nil\n}\n```\n\n我们看函数第一行，调用了`internetSocket`，很明显里面就是创建实际`socket`的逻辑了，继续往下走\n\n```go\nfunc internetSocket(ctx context.Context, net string, laddr, raddr sockaddr, sotype, proto int, mode string, ctrlFn func(string, string, syscall.RawConn) error) (fd *netFD, err error) {\n\tif (runtime.GOOS == \"windows\" || runtime.GOOS == \"openbsd\" || runtime.GOOS == \"nacl\") && mode == \"dial\" && raddr.isWildcard() {\n\t\traddr = raddr.toLocal(net)\n\t}\n\tfamily, ipv6only := favoriteAddrFamily(net, laddr, raddr, mode)\n\treturn socket(ctx, net, family, sotype, proto, ipv6only, laddr, raddr, ctrlFn)\n}\n```\n\n这里我们只看`linux`的情况，因此继续看`socket`方法：\n\n```go\nfunc socket(ctx context.Context, net string, family, sotype, proto int, ipv6only bool, laddr, raddr sockaddr, ctrlFn func(string, string, syscall.RawConn) error) (fd *netFD, err error) {\n    // 这里是实际创建socket的代码\n\ts, err := sysSocket(family, sotype, proto)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n    // 设置socket选项\n\tif err = setDefaultSockopts(s, family, sotype, ipv6only); err != nil {\n\t\tpoll.CloseFunc(s)\n\t\treturn nil, err\n\t}\n    // 根据socket创建netFD，netFD是net包对底层socket的封装\n\tif fd, err = newFD(s, family, sotype, net); err != nil {\n\t\tpoll.CloseFunc(s)\n\t\treturn nil, err\n\t}\n\n\tif laddr != nil && raddr == nil {\n\t\tswitch sotype {\n        // 看上面的参数，我们传入的sotype是SOCK_STREAM，因此会走这个分支\n\t\tcase syscall.SOCK_STREAM, syscall.SOCK_SEQPACKET:\n\t\t\tif err := fd.listenStream(laddr, listenerBacklog, ctrlFn); err != nil {\n\t\t\t\tfd.Close()\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn fd, nil\n\t\tcase syscall.SOCK_DGRAM:\n\t\t\tif err := fd.listenDatagram(laddr, ctrlFn); err != nil {\n\t\t\t\tfd.Close()\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn fd, nil\n\t\t}\n\t}\n\tif err := fd.dial(ctx, laddr, raddr, ctrlFn); err != nil {\n\t\tfd.Close()\n\t\treturn nil, err\n\t}\n\treturn fd, nil\n}\n```\n\n我们先来看`sysSocket`方法：\n\n```go\nfunc sysSocket(family, sotype, proto int) (int, error) {\n    // 这里的socketFunc实际上是创建socket的系统调用\n    // \tsocketFunc func(int, int, int) (int, error)  = syscall.Socket\n    // 注意这里传入的SOCK_NONBLOCK，表明我们创建的是非阻塞的socket\n    // 这里的SOCK_CLOEXEC表明在执行fork系统调用时，当执行exec时需要关闭从父进程继承的文件设备\n\ts, err := socketFunc(family, sotype|syscall.SOCK_NONBLOCK|syscall.SOCK_CLOEXEC, proto)\n\tswitch err {\n\tcase nil:\n\t\treturn s, nil\n\tdefault:\n\t\treturn -1, os.NewSyscallError(\"socket\", err)\n        // 低版本内核不支持创建时指定SOCK_NONBLOCK或者SOCK_CLOEXEC\n        // 这时候需要分两步，先创建socket，然后再设置flag\n\tcase syscall.EPROTONOSUPPORT, syscall.EINVAL:\n\t}\n\n    // 这里需要加锁，与fork操作互斥，防止在创建socket而没有设置`SOCK_CLOEXEC`时执行了fork和exec\n\tsyscall.ForkLock.RLock()\n    // 创建socket\n\ts, err = socketFunc(family, sotype, proto)\n\tif err == nil {\n        // 设置SOCK_COLEXEC\n\t\tsyscall.CloseOnExec(s)\n\t}\n\tsyscall.ForkLock.RUnlock()\n\tif err != nil {\n\t\treturn -1, os.NewSyscallError(\"socket\", err)\n\t}\n    // 设置非阻塞IO\n\tif err = syscall.SetNonblock(s, true); err != nil {\n\t\tpoll.CloseFunc(s)\n\t\treturn -1, os.NewSyscallError(\"setnonblock\", err)\n\t}\n\treturn s, nil\n}\n```\n\n`sysSocket`主要通过系统调用创建了`socket`，**同时设置了`SOCK_NONBLOCK`标志位**，这点非常重要，这里要明确，我们在`go`中使用的网络连接一般都是非阻塞的。关于阻塞IO和非阻塞IO的区别网上有一大堆的资料，这里就不重复说明了。使用非阻塞IO的主要的原因是，**在go中，当使用阻塞系统调用时，当前goroutine对应的底层系统级线程就会被占用，无法与当前g解绑为其他g提供服务**，这样当需要执行其他`g`时就需要创建新的线程来执行\n\n接着来看`netFd.listenStream`\n\n```go\nfunc (fd *netFD) listenStream(laddr sockaddr, backlog int, ctrlFn func(string, string, syscall.RawConn) error) error {\n\t...\n    // 为socket绑定监听的ip和端口\n\tif err = syscall.Bind(fd.pfd.Sysfd, lsa); err != nil {\n\t\treturn os.NewSyscallError(\"bind\", err)\n\t}\n    // listenFunc func(int, int) error = syscall.Listen\n    // 这里的listenFunc实际上是系统调用Listen\n    // 开始监听\n\tif err = listenFunc(fd.pfd.Sysfd, backlog); err != nil {\n\t\treturn os.NewSyscallError(\"listen\", err)\n\t}\n    // 执行初始化操作\n\tif err = fd.init(); err != nil {\n\t\treturn err\n\t}\n\tlsa, _ = syscall.Getsockname(fd.pfd.Sysfd)\n\tfd.setAddr(fd.addrFunc()(lsa), nil)\n\treturn nil\n}\n```\n\n这里就是常规的绑定监听地址和端口，然后开始监听，这里重要的是`netFD.init`函数，先来看`netFD`的结构：\n\n```go\n// Network file descriptor.\ntype netFD struct {\n\tpfd poll.FD\n\n\t// immutable until Close\n\tfamily      int\n\tsotype      int\n\tisConnected bool // handshake completed or use of association with peer\n\tnet         string\n\tladdr       Addr\n\traddr       Addr\n}\n\n// FD is a file descriptor. The net and os packages use this type as a\n// field of a larger type representing a network connection or OS file.\ntype FD struct {\n\t// Lock sysfd and serialize access to Read and Write methods.\n\tfdmu fdMutex\n\n\t// System file descriptor. Immutable until Close.\n\tSysfd int\n\n\t// I/O poller.\n\tpd pollDesc\n\n\t// Writev cache.\n\tiovecs *[]syscall.Iovec\n\n\t// Semaphore signaled when file is closed.\n\tcsema uint32\n\n\t// Non-zero if this file has been set to blocking mode.\n\tisBlocking uint32\n\n\t// Whether this is a streaming descriptor, as opposed to a\n\t// packet-based descriptor like a UDP socket. Immutable.\n\tIsStream bool\n\n\t// Whether a zero byte read indicates EOF. This is false for a\n\t// message based socket connection.\n\tZeroReadIsEOF bool\n\n\t// Whether this is a file rather than a network socket.\n\tisFile bool\n}\n```\n\n接着看上面的`netFD.init`函数：\n\n```go\nfunc (fd *netFD) init() error {\n    // 这里的pfd实际上就是poll.FD，用来表示一个网络连接或者打开的系统文件\n\treturn fd.pfd.Init(fd.net, true)\n}\n```\n\n我们来看一下`pollFD.Init`：\n\n```go\nfunc (fd *FD) Init(net string, pollable bool) error {\n\t// We don't actually care about the various network types.\n\tif net == \"file\" {\n\t\tfd.isFile = true\n\t}\n\tif !pollable {\n\t\tfd.isBlocking = 1\n\t\treturn nil\n\t}\n    // 这里又有个init，这里的pd是pollDesc类型\n\terr := fd.pd.init(fd)\n\tif err != nil {\n\t\t// If we could not initialize the runtime poller,\n\t\t// assume we are using blocking mode.\n\t\tfd.isBlocking = 1\n\t}\n\treturn err\n}\n```\n\n可以看到上面又有个`init`函数，我们先来看一下`fd.pd`对应的`pollDesc`类型：\n\n```go\ntype pollDesc struct {\n\truntimeCtx uintptr // 这个运行时上下文很重要\n}\n```\n\n我们来看一下`init`函数：\n\n```go\nvar serverInit sync.Once\n\nfunc (pd *pollDesc) init(fd *FD) error {\n\t// 保证runtime_pollServerInit只会执行一次\n    serverInit.Do(runtime_pollServerInit)\n    // 执行runtime_pollOpen\n\tctx, errno := runtime_pollOpen(uintptr(fd.Sysfd))\n\tif errno != 0 {\n\t\tif ctx != 0 {\n\t\t\truntime_pollUnblock(ctx)\n\t\t\truntime_pollClose(ctx)\n\t\t}\n\t\treturn syscall.Errno(errno)\n\t}\n    // 把返回值保存到runtimeCtx中\n\tpd.runtimeCtx = ctx\n\treturn nil\n}\n```\n\n上面这个函数才是关键所在，这里涉及到了`runtime_pollServerInit`和`runtime_pollOpen`两个函数，从命名可以很容易看出这两个函数是在`runtime`包中实现的，然后在链接器链接过来的\n\n先来看一下`runtime_pollServerInit`实现：\n\n```go\nfunc poll_runtime_pollServerInit() {\n\tnetpollinit()\n\tatomic.Store(&netpollInited, 1)\n}\n\nfunc netpollinit() {\n    // 执行系统调用创建epoll\n    // 先尝试使用create1系统调用\n\tepfd = epollcreate1(_EPOLL_CLOEXEC)\n\tif epfd >= 0 {\n\t\treturn\n\t}\n    // 这边的1024是历史原因，只要大于0就好了\n    // 原先epoll底层使用hash表实现，需要传入一个size指定hash表的大小，后面基于rb-tree实现，因此这个参数没有实际意义了，大于0即可\n\tepfd = epollcreate(1024)\n\tif epfd >= 0 {\n\t\tcloseonexec(epfd)\n\t\treturn\n\t}\n\tprintln(\"runtime: epollcreate failed with\", -epfd)\n\tthrow(\"runtime: netpollinit failed\")\n}\n```\n\n很简单，就是创建了一个`epoll`\n\n再来看一下`runtime_pollOpen`的实现：\n\n```go\nfunc poll_runtime_pollOpen(fd uintptr) (*pollDesc, int) {\n\t// 分配一个pollDesc，这个pollDesc是runtime的pollDesc，和上面的pollDesc不是同一个东西，但是他们之间又有关联\n    pd := pollcache.alloc()\n\tlock(&pd.lock)\n\tif pd.wg != 0 && pd.wg != pdReady {\n\t\tthrow(\"runtime: blocked write on free polldesc\")\n\t}\n\tif pd.rg != 0 && pd.rg != pdReady {\n\t\tthrow(\"runtime: blocked read on free polldesc\")\n\t}\n\tpd.fd = fd\n\tpd.closing = false\n\tpd.seq++\n\tpd.rg = 0\n\tpd.rd = 0\n\tpd.wg = 0\n\tpd.wd = 0\n\tunlock(&pd.lock)\n\n\tvar errno int32\n\terrno = netpollopen(fd, pd)\n    // 这里返回了pd的地址，也就是poll.pollDesc中的runtimeCtx实际上保存的就是runtime.pollDesc的地址\n\treturn pd, int(errno)\n}\n\nfunc netpollopen(fd uintptr, pd *pollDesc) int32 {\n\tvar ev epollevent\n    // 设置需要通知的实际类型，这里设置了边缘触发模式，关于epoll的边缘触发和水平触发模式可以网上有一堆的资料\n\tev.events = _EPOLLIN | _EPOLLOUT | _EPOLLRDHUP | _EPOLLET\n    // 可以看到，这里把pollDesc的地址存到了ev.Data中\n\t*(**pollDesc)(unsafe.Pointer(&ev.data)) = pd\n    // 执行epollctl系统调用，添加socket到epoll中\n\treturn -epollctl(epfd, _EPOLL_CTL_ADD, int32(fd), &ev)\n}\n```\n\n至此一个`net.Listener`就创建完成了，总结一下主要的逻辑：\n\n1. 创建一个非阻塞`socket`，并执行`bind`和`listen`\n2. 如果没有初始化过`runtime`包的`epoll`，则执行初始化，创建一个`epoll`\n3. 以边缘触发模式将`socket`添加到`epoll`中\n4. 返回封装后的`net.Listener`\n\n### Accept又是如何执行的呢\n\n接下来我们来看一下执行`Accept`时会发生什么\n\n```go\nfunc (l *TCPListener) Accept() (Conn, error) {\n\tif !l.ok() {\n\t\treturn nil, syscall.EINVAL\n\t}\n\tc, err := l.accept()\n\tif err != nil {\n\t\treturn nil, &OpError{Op: \"accept\", Net: l.fd.net, Source: nil, Addr: l.fd.laddr, Err: err}\n\t}\n\treturn c, nil\n}\n\nfunc (ln *TCPListener) accept() (*TCPConn, error) {\n\tfd, err := ln.fd.accept()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn newTCPConn(fd), nil\n}\n```\n\n我们上面创建的是一个`TcpListener`，因此自然是执行对应的`Accept`，可以看到是调用`netFD.Accept`：\n\n```go\nfunc (fd *netFD) accept() (netfd *netFD, err error) {\n    // 执行poll.FD的Accept方法，获取新的客户端连接\n\td, rsa, errcall, err := fd.pfd.Accept()\n\tif err != nil {\n\t\tif errcall != \"\" {\n\t\t\terr = wrapSyscallError(errcall, err)\n\t\t}\n\t\treturn nil, err\n\t}\n\t// 封装netFD\n\tif netfd, err = newFD(d, fd.family, fd.sotype, fd.net); err != nil {\n\t\tpoll.CloseFunc(d)\n\t\treturn nil, err\n\t}\n    // 这里的netFD.init上面分析过了，就是将新的socket加入到epoll中\n\tif err = netfd.init(); err != nil {\n\t\tfd.Close()\n\t\treturn nil, err\n\t}\n\tlsa, _ := syscall.Getsockname(netfd.pfd.Sysfd)\n\tnetfd.setAddr(netfd.addrFunc()(lsa), netfd.addrFunc()(rsa))\n\treturn netfd, nil\n}\n```\n\n接下来看一下`poll.FD`的`Accept`方法：\n\n```go\nfunc (fd *FD) Accept() (int, syscall.Sockaddr, string, error) {\n    // 尝试加锁\n\tif err := fd.readLock(); err != nil {\n\t\treturn -1, nil, \"\", err\n\t}\n\tdefer fd.readUnlock()\n    \n\tif err := fd.pd.prepareRead(fd.isFile); err != nil {\n\t\treturn -1, nil, \"\", err\n\t}\n\tfor {\n        /// 首先尝试直接获取客户端连接\n\t\ts, rsa, errcall, err := accept(fd.Sysfd)\n\t\tif err == nil { // 获取成功，直接返回\n\t\t\treturn s, rsa, \"\", err\n\t\t}\n\t\tswitch err {\n            // 因为我们创建的socket是非阻塞的，当没有新的连接可以accept时会直接返回EAGAIN而不是阻塞\n\t\tcase syscall.EAGAIN:\n            // 如果是可轮询的，表明可以等到epoll事件通知\n\t\t\tif fd.pd.pollable() {\n                // \n\t\t\t\tif err = fd.pd.waitRead(fd.isFile); err == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\tcase syscall.ECONNABORTED:\n\t\t\t// This means that a socket on the listen\n\t\t\t// queue was closed before we Accept()ed it;\n\t\t\t// it's a silly error, so try again.\n\t\t\tcontinue\n\t\t}\n\t\treturn -1, nil, errcall, err\n\t}\n}\n\nfunc accept(s int) (int, syscall.Sockaddr, string, error) {\n    // var Accept4Func func(int, int) (int, syscall.Sockaddr, error) = syscall.Accept4\n    // 首先使用系统调用accept4获取一个非阻塞的socket\n\tns, sa, err := Accept4Func(s, syscall.SOCK_NONBLOCK|syscall.SOCK_CLOEXEC)\n\tswitch err {\n\tcase nil:\n\t\treturn ns, sa, \"\", nil\n\tdefault: // errors other than the ones listed\n\t\treturn -1, sa, \"accept4\", err\n\tcase syscall.ENOSYS: // syscall missing\n\tcase syscall.EINVAL: // some Linux use this instead of ENOSYS\n\tcase syscall.EACCES: // some Linux use this instead of ENOSYS\n\tcase syscall.EFAULT: // some Linux use this instead of ENOSYS\n\t}\n\t// 有些内核不支持accept4\n\tns, sa, err = AcceptFunc(s)\n\tif err == nil {\n\t\tsyscall.CloseOnExec(ns)\n\t}\n\tif err != nil {\n\t\treturn -1, nil, \"accept\", err\n\t}\n    // 设置非阻塞模式\n\tif err = syscall.SetNonblock(ns, true); err != nil {\n\t\tCloseFunc(ns)\n\t\treturn -1, nil, \"setnonblock\", err\n\t}\n\treturn ns, sa, \"\", nil\n}\n```\n\n接着来看`pollDesc.waitRead`实现：\n\n```go\nfunc (pd *pollDesc) waitRead(isFile bool) error {\n\treturn pd.wait('r', isFile)\n}\n\nfunc (pd *pollDesc) wait(mode int, isFile bool) error {\n\tif pd.runtimeCtx == 0 {\n\t\treturn errors.New(\"waiting for unsupported file type\")\n\t}\n    // 又是一个runtime包的方法\n\tres := runtime_pollWait(pd.runtimeCtx, mode)\n\treturn convertErr(res, isFile)\n}\n```\n\n接着看一下`runtime_pollWait`实现：\n\n```go\nfunc poll_runtime_pollWait(pd *pollDesc, mode int) int {\n\terr := netpollcheckerr(pd, int32(mode))\n\tif err != 0 {\n\t\treturn err\n\t}\n\t// As for now only Solaris uses level-triggered IO.\n\tif GOOS == \"solaris\" {\n\t\tnetpollarm(pd, mode)\n\t}\n    // 实际干活的是netpollblock\n\tfor !netpollblock(pd, int32(mode), false) {\n\t\terr = netpollcheckerr(pd, int32(mode))\n\t\tif err != 0 {\n\t\t\treturn err\n\t\t}\n\t\t// Can happen if timeout has fired and unblocked us,\n\t\t// but before we had a chance to run, timeout has been reset.\n\t\t// Pretend it has not happened and retry.\n\t}\n\treturn 0\n}\n\nfunc netpollblock(pd *pollDesc, mode int32, waitio bool) bool {\n    // 这里如果是'r'模式，则gpp是&pd.rg\n    // 'w'模式则是'&pd.wg'\n\tgpp := &pd.rg\n\tif mode == 'w' {\n\t\tgpp = &pd.wg\n\t}\n\n\t// cas操作，设置gpp为pdwait\n\tfor {\n\t\told := *gpp\n\t\tif old == pdReady {\n\t\t\t*gpp = 0\n\t\t\treturn true\n\t\t}\n\t\tif old != 0 {\n\t\t\tthrow(\"runtime: double wait\")\n\t\t}\n\t\tif atomic.Casuintptr(gpp, 0, pdWait) {\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// 这里直接执行gopark，将当前协程挂起 ^-^\n\tif waitio || netpollcheckerr(pd, mode) == 0 {\n        // 这里netpollblockcommit会被调用，把当前g的引用保存到gpp中，也就是pollDesc的rg或者wg中\n\t\tgopark(netpollblockcommit, unsafe.Pointer(gpp), waitReasonIOWait, traceEvGoBlockNet, 5)\n\t}\n\t// be careful to not lose concurrent READY notification\n\told := atomic.Xchguintptr(gpp, 0)\n\tif old > pdWait {\n\t\tthrow(\"runtime: corrupted polldesc\")\n\t}\n\treturn old == pdReady\n}\n```\n\n至此，`Accept`的流程也很清晰了：\n\n1. 首先直接尝试通过`socket`执行`accept`来获取可能的客户端连接\n2. 如果此时客户端没有连接，因为`socket`是非阻塞模式，会直接返回`EAGAIN`\n3. 调用`runtime.poll_runtime_pollWait`将当前协程挂起，并且根据是等待读还是等待写将当前`g`的引用保存到`pollDesc`中的`rg`或者`wg`中\n4. 当有新的客户端连接到来时，`epoll`会通知将当前阻塞的协程恢复，然后重新执行第一步\n\n### 那么epoll的wait又是什么时候调用的呢\n\n我们可以在协程的调度逻辑中看到这样一段代码段：\n\n```go\n\tif netpollinited() && atomic.Load(&netpollWaiters) > 0 && atomic.Load64(&sched.lastpoll) != 0 {\n        // 这里的netpoll的参数false表示不阻塞\n\t\tif gp := netpoll(false); gp != nil { \n            // 这里获取的可能是一个列表，将后面多余的g加入调度队列，这里调度一次只能调度一个\n\t\t\tinjectglist(gp.schedlink.ptr())\n            // 设置g为runnable\n\t\t\tcasgstatus(gp, _Gwaiting, _Grunnable)\n\t\t\tif trace.enabled {\n\t\t\t\ttraceGoUnpark(gp, 0)\n\t\t\t}\n\t\t\treturn gp, false\n\t\t}\n\t}\n```\n\n我们来看一下`netpoll`的执行：\n\n```go\nfunc netpoll(block bool) *g {\n\tif epfd == -1 {\n\t\treturn nil\n\t}\n\twaitms := int32(-1)\n    // 调度逻辑中传入的是0\n\tif !block {\n\t\twaitms = 0\n\t}\n\tvar events [128]epollevent\nretry:\n    // 执行epoll_wait系统调用\n\tn := epollwait(epfd, &events[0], int32(len(events)), waitms)\n\tif n < 0 {\n\t\tif n != -_EINTR {\n\t\t\tprintln(\"runtime: epollwait on fd\", epfd, \"failed with\", -n)\n\t\t\tthrow(\"runtime: netpoll failed\")\n\t\t}\n\t\tgoto retry\n\t}\n    // 这里gp是一个链表\n\tvar gp guintptr\n\tfor i := int32(0); i < n; i++ {\n\t\tev := &events[i]\n\t\tif ev.events == 0 {\n\t\t\tcontinue\n\t\t}\n\t\tvar mode int32\n\t\tif ev.events&(_EPOLLIN|_EPOLLRDHUP|_EPOLLHUP|_EPOLLERR) != 0 {\n\t\t\tmode += 'r'\n\t\t}\n\t\tif ev.events&(_EPOLLOUT|_EPOLLHUP|_EPOLLERR) != 0 {\n\t\t\tmode += 'w'\n\t\t}\n\t\tif mode != 0 {\n            // 从ev.data取出pollDesc，还记得上面分析过，在加入epoll时会把对应的pollDesc保存到ev.Data中，而协程阻塞时会把g指针保存在pollDesc中的rg或者wg中\n\t\t\tpd := *(**pollDesc)(unsafe.Pointer(&ev.data))\n\t\t\t// 这里执行netpollready，把对应阻塞的g加到gp链表头部\n\t\t\tnetpollready(&gp, pd, mode)\n\t\t}\n\t}\n\tif block && gp == 0 {\n\t\tgoto retry\n\t}\n\treturn gp.ptr()\n}\n\nfunc netpollready(gpp *guintptr, pd *pollDesc, mode int32) {\n\tvar rg, wg guintptr\n\tif mode == 'r' || mode == 'r'+'w' {\n        // 这里调用了netpollunblock，获取对应的g\n\t\trg.set(netpollunblock(pd, 'r', true))\n\t}\n\tif mode == 'w' || mode == 'r'+'w' {\n\t\twg.set(netpollunblock(pd, 'w', true))\n\t}\n    // 链表设置，将新的g添加到链表头部\n\tif rg != 0 {\n\t\trg.ptr().schedlink = *gpp\n\t\t*gpp = rg\n\t}\n\tif wg != 0 {\n\t\twg.ptr().schedlink = *gpp\n\t\t*gpp = wg\n\t}\n}\n\nfunc netpollunblock(pd *pollDesc, mode int32, ioready bool) *g {\n    // 如果是等待读则rg是阻塞的g的引用\n    // 如果是等待写则wg是阻塞的g的引用\n\tgpp := &pd.rg\n\tif mode == 'w' {\n\t\tgpp = &pd.wg\n\t}\n\n\tfor {\n\t\told := *gpp\n\t\tif old == pdReady {\n\t\t\treturn nil\n\t\t}\n\t\tif old == 0 && !ioready {\n\t\t\t// Only set READY for ioready. runtime_pollWait\n\t\t\t// will check for timeout/cancel before waiting.\n\t\t\treturn nil\n\t\t}\n\t\tvar new uintptr\n\t\tif ioready {\n\t\t\tnew = pdReady\n\t\t}\n        // 状态为ready\n\t\tif atomic.Casuintptr(gpp, old, new) {\n\t\t\tif old == pdReady || old == pdWait {\n\t\t\t\told = 0\n\t\t\t}\n\t\t\treturn (*g)(unsafe.Pointer(old))\n\t\t}\n\t}\n}\n```\n\n可以看到，在执行协程的调度时，会执行`epoll_wait`系统调用，获取已经准备好的`socket`，并唤醒对应的`goroutine`\n\n除了在调度时会执行`epoll_wait`，在后台线程`sysmon`中也会定时执行`epoll_wait`：\n\n```go\nfunc sysmon() {\n\t...\n\tfor {\n\t\t...\n\t\tif netpollinited() && lastpoll != 0 && lastpoll+10*1000*1000 < now {\n\t\t\tatomic.Cas64(&sched.lastpoll, uint64(lastpoll), uint64(now))\n\t\t\tgp := netpoll(false) // non-blocking - returns list of goroutines\n\t\t\tif gp != nil {\n\t\t\t\tincidlelocked(-1)\n\t\t\t\tinjectglist(gp)\n\t\t\t\tincidlelocked(1)\n\t\t\t}\n\t\t}\n\t\t...\n\t}\n}\n```\n\n### 大同小异的读写操作\n\n那么接下来，我们来看一下`Read`操作，实际上`Read`最后会执行\n\n```go\nfunc (c *conn) Read(b []byte) (int, error) {\n   if !c.ok() {\n      return 0, syscall.EINVAL\n   }\n   n, err := c.fd.Read(b)\n   if err != nil && err != io.EOF {\n      err = &OpError{Op: \"read\", Net: c.fd.net, Source: c.fd.laddr, Addr: c.fd.raddr, Err: err}\n   }\n   return n, err\n}\n\nfunc (fd *netFD) Read(p []byte) (n int, err error) {\n\tn, err = fd.pfd.Read(p)\n\truntime.KeepAlive(fd)\n\treturn n, wrapSyscallError(\"read\", err)\n}\n```\n\n最后到了`poll.FD`的`Read`方法：\n\n```go\nfunc (fd *FD) Read(p []byte) (int, error) {\n    // 这里执行对应的加锁操作\n\t...\n\tfor {\n        // 首先尝试直接读，如果无可读内容，因为是非阻塞模式，会返回EAGAIN\n\t\tn, err := syscall.Read(fd.Sysfd, p)\n\t\tif err != nil {\n\t\t\tn = 0\n\t\t\tif err == syscall.EAGAIN && fd.pd.pollable() {\n                // 这里的waitRead有没有似曾相识？这个方法在accept流程的时候已经分析过了，最后会将当前协程挂起\n\t\t\t\tif err = fd.pd.waitRead(fd.isFile); err == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// On MacOS we can see EINTR here if the user\n\t\t\t// pressed ^Z.  See issue #22838.\n\t\t\tif runtime.GOOS == \"darwin\" && err == syscall.EINTR {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\terr = fd.eofError(n, err)\n\t\treturn n, err\n\t}\n}\n```\n\n再来看一下写过程，最后会执行：\n\n```go\nfunc (fd *FD) Write(p []byte) (int, error) {\n    // 这里执行对应的加锁操作\n\t...\n    // 记录已经写入字节数\n\tvar nn int\n\tfor {\n\t\tmax := len(p)\n\t\tif fd.IsStream && max-nn > maxRW {\n\t\t\tmax = nn + maxRW\n\t\t}\n\t\tn, err := syscall.Write(fd.Sysfd, p[nn:max])\n\t\tif n > 0 {\n\t\t\tnn += n\n\t\t}\n        // 写入方法与读方法的区别在于，读方法只要读取到内容就会返回\n        // 而写入需要将传入的字节切片全部写入才返回\n\t\tif nn == len(p) {\n\t\t\treturn nn, err\n\t\t}\n        // 这里的waitWrite和上面的waitRead类似\n\t\tif err == syscall.EAGAIN && fd.pd.pollable() {\n\t\t\tif err = fd.pd.waitWrite(fd.isFile); err == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nn, err\n\t\t}\n\t\tif n == 0 {\n\t\t\treturn nn, io.ErrUnexpectedEOF\n\t\t}\n\t}\n}\n\n// 其实最后都是调用的pd.wait\nfunc (pd *pollDesc) waitWrite(isFile bool) error {\n\treturn pd.wait('w', isFile)\n}\n\n// 最终调用runtime_pollWait将当前协程挂起\nfunc (pd *pollDesc) wait(mode int, isFile bool) error {\n\tif pd.runtimeCtx == 0 {\n\t\treturn errors.New(\"waiting for unsupported file type\")\n\t}\n\tres := runtime_pollWait(pd.runtimeCtx, mode)\n\treturn convertErr(res, isFile)\n}\n```\n\n### 差点被遗忘的close\n\n接着来看一下`Close`方法，实际执行的是：\n\n```go\nfunc (c *conn) Close() error {\n\tif !c.ok() {\n\t\treturn syscall.EINVAL\n\t}\n    // 这里执行netFD.Close\n\terr := c.fd.Close()\n\tif err != nil {\n\t\terr = &OpError{Op: \"close\", Net: c.fd.net, Source: c.fd.laddr, Addr: c.fd.raddr, Err: err}\n\t}\n\treturn err\n}\n\nfunc (fd *netFD) Close() error {\n    // 清除finalizer\n\truntime.SetFinalizer(fd, nil)\n    // 调用poll.FD的Close方法\n\treturn fd.pfd.Close()\n}\n\n\nfunc (fd *FD) Close() error {\n\tif !fd.fdmu.increfAndClose() {\n\t\treturn errClosing(fd.isFile)\n\t}\n\n\t// 这里evict方法唤醒所有阻塞读写的g\n\tfd.pd.evict()\n\t// 减少引用，如果引用为0则关闭\n\terr := fd.decref()\n\n\tif fd.isBlocking == 0 {\n\t\truntime_Semacquire(&fd.csema)\n\t}\n\n\treturn err\n}\n\nfunc (pd *pollDesc) evict() {\n\tif pd.runtimeCtx == 0 {\n\t\treturn\n\t}\n\truntime_pollUnblock(pd.runtimeCtx)\n}\n\nfunc poll_runtime_pollUnblock(pd *pollDesc) {\n\tlock(&pd.lock)\n\tif pd.closing {\n\t\tthrow(\"runtime: unblock on closing polldesc\")\n\t}\n\tpd.closing = true\n\tpd.seq++\n\tvar rg, wg *g\n\tatomicstorep(unsafe.Pointer(&rg), nil)\n    // 获取阻塞的g\n\trg = netpollunblock(pd, 'r', false)\n\twg = netpollunblock(pd, 'w', false)\n\tif pd.rt.f != nil {\n\t\tdeltimer(&pd.rt)\n\t\tpd.rt.f = nil\n\t}\n\tif pd.wt.f != nil {\n\t\tdeltimer(&pd.wt)\n\t\tpd.wt.f = nil\n\t}\n\tunlock(&pd.lock)\n\tif rg != nil {\n        // 调用goready唤醒g\n\t\tnetpollgoready(rg, 3)\n\t}\n\tif wg != nil {\n        // 唤醒g\n\t\tnetpollgoready(wg, 3)\n\t}\n}\n\n\nfunc (fd *FD) decref() error {\n\t// 减少引用，如果引用为0，则返回true\n    if fd.fdmu.decref() {\n        // 关闭连接\n\t\treturn fd.destroy()\n\t}\n\treturn nil\n}\n\nfunc (fd *FD) destroy() error {\n\t// 调用runtime_pollClose方法\n\tfd.pd.close()\n    // var CloseFunc func(int) error = syscall.Close\n    // 这里的CloseFunc就是系统调用close\n\terr := CloseFunc(fd.Sysfd)\n\tfd.Sysfd = -1\n\truntime_Semrelease(&fd.csema)\n\treturn err\n}\n\nfunc (pd *pollDesc) close() {\n\tif pd.runtimeCtx == 0 {\n\t\treturn\n\t}\n\truntime_pollClose(pd.runtimeCtx)\n\tpd.runtimeCtx = 0\n}\n\nfunc poll_runtime_pollClose(pd *pollDesc) {\n\tif !pd.closing {\n\t\tthrow(\"runtime: close polldesc w/o unblock\")\n\t}\n\tif pd.wg != 0 && pd.wg != pdReady {\n\t\tthrow(\"runtime: blocked write on closing polldesc\")\n\t}\n\tif pd.rg != 0 && pd.rg != pdReady {\n\t\tthrow(\"runtime: blocked read on closing polldesc\")\n\t}\n    // 从epoll中删除fd\n\tnetpollclose(pd.fd)\n    // 释放pollDesc\n\tpollcache.free(pd)\n}\n\nfunc netpollclose(fd uintptr) int32 {\n\tvar ev epollevent\n    // 系统调用epoll_ctl删除对应的fd\n\treturn -epollctl(epfd, _EPOLL_CTL_DEL, int32(fd), &ev)\n}\n```\n\n综上，关闭一个连接时：\n\n1. 设置pollDesc相关flag为已关闭，唤醒该连接上阻塞的协程\n2. 减少对应poll.FD的引用，如果引用为0，则只需真正的关闭\n3. 执行关闭操作，先从epoll删除对应的fd，然后执行close系统调用关闭\n\n### 最后\n\n可以看到，`go`使用非阻塞IO来防止大量系统线程阻塞带来的上下文切换，取而代之的是让轻量级的协程阻塞在IO事件上，然后通过`epoll`来实现IO事件通知，唤醒阻塞的协程。","tags":["go"]},{"title":"golang内存逃逸","url":"/2019/03/31/golang内存逃逸/","content":"\n`golang`中，编译器在编译时会通过内存逃逸分析确定变量分配在堆上还是栈上。\n\n```go\ntype Dog struct {\n}\n\nfunc (d *Dog) Eat() {\n}\n\ntype Animal interface {\n\tEat()\n}\n\nfunc main() {\n\tdog1 := new(Dog)\n\tnoneEscape(dog1)\n\tnop(dog1)\n\tdog2 := new(Dog)\n\tescape(dog2)\n\tdog3 := Dog{}\n\tfmt.Println(&dog3)\n}\n\n//go:noinline\nfunc nop( a Animal){\n}\n\n//go:noinline\nfunc noneEscape(d *Dog) {\n\td.Eat()\n}\n\n//go:noinline\nfunc escape(a Animal) {\n\ta.Eat()\n}\n\n```\n\n可以通过`--gcflags=\"-m -m\"`参数，在编译时打印出内存逃逸分析信息，`-m`最多可以指定四个，越多打印的信息越详细。上面代码中的`go:noinline`用于告诉编译器禁止对该函数进行内联优化。\n\n运行：\n\n```sh\n$ go build -gcflags=\"-m -m\" .\n```\n\n查看打印结果：\n\n```\n# just-for-fun/escape\n.\\main.go:8:6: can inline (*Dog).Eat as: method(*Dog) func() {  }\n.\\main.go:30:6: cannot inline noneEscape: marked go:noinline\n.\\main.go:31:7: inlining call to (*Dog).Eat method(*Dog) func() {  }\n.\\main.go:26:6: cannot inline nop: marked go:noinline\n.\\main.go:35:6: cannot inline escape: marked go:noinline\n.\\main.go:15:6: cannot inline main: function too complex: cost 355 exceeds budget 80\n.\\main.go:8:7: (*Dog).Eat d does not escape\n.\\main.go:30:17: noneEscape d does not escape\n.\\main.go:26:11: nop a does not escape\n.\\main.go:35:13: leaking param: a\n.\\main.go:35:13:        from a.Eat() (receiver in indirect call) at .\\main.go:36:7\n.\\main.go:20:8: dog2 escapes to heap\n.\\main.go:20:8:         from dog2 (passed to call[argument escapes]) at .\\main.go:20:8\n.\\main.go:19:13: new(Dog) escapes to heap\n.\\main.go:19:13:        from dog2 (assigned) at .\\main.go:19:7\n.\\main.go:19:13:        from dog2 (interface-converted) at .\\main.go:20:8\n.\\main.go:19:13:        from dog2 (passed to call[argument escapes]) at .\\main.go:20:8\n.\\main.go:22:14: &dog3 escapes to heap\n.\\main.go:22:14:        from ... argument (arg to ...) at .\\main.go:22:13\n.\\main.go:22:14:        from *(... argument) (indirection) at .\\main.go:22:13\n.\\main.go:22:14:        from ... argument (passed to call[argument content escapes]) at .\\main.go:22:13\n.\\main.go:22:14: &dog3 escapes to heap\n.\\main.go:22:14:        from &dog3 (interface-converted) at .\\main.go:22:14\n.\\main.go:22:14:        from ... argument (arg to ...) at .\\main.go:22:13\n.\\main.go:22:14:        from *(... argument) (indirection) at .\\main.go:22:13\n.\\main.go:22:14:        from ... argument (passed to call[argument content escapes]) at .\\main.go:22:13\n.\\main.go:21:2: moved to heap: dog3\n.\\main.go:16:13: main new(Dog) does not escape\n.\\main.go:18:5: main dog1 does not escape\n.\\main.go:22:13: main ... argument does not escape\n<autogenerated>:1: leaking param: .this\n<autogenerated>:1:      from .this.Eat() (receiver in indirect call) at <autogenerated>:1\n```\n\n从上面的信息中可以看到，`dog1`分配在栈上，而`dog2`和`dog3`都分配在堆上。\n\n`dog1`在方法`noneEscape`中，调用了`Eat`方法，因为`Eat`方法并没有发生内存逃逸，因此`dog1`在`noneEscape`中没有内存逃逸。而`nop`方法内`dog1`没有执行任何操作，也不会发生内存逃逸。可见，即使是使用`new`分配的变量，也不一定是分配在堆上。\n\n而`dog2`在方法`escape`中，调用了`Eat`方法，因为这时候`dog2`是`Animal`接口类型，`golang`中接口类型的方法是动态派发的，编译器并不知道具体调用的是哪个`Eat`方法，从而无法确定`dog2`在`Eat`是否有发生内存逃逸。在这种情况下，编译器会认为`dog2`发生了内存逃逸，并将其分配在堆上。如果编译器能够在编译时就对接口的实际类型进行分析，对`Eat`方法进行静态派发，就可以发现`dog2`并没有内存逃逸。\n\n\n\n### fun thing\n\n代码1：\n\n```go\nfunc main() {\n   byts := []byte(\"\")\n   s1 := append(byts,'a')\n   s2:= append(byts,'b')\n   fmt.Println(string(s1),string(s2)) // b b\n}\n```\n\n代码2：\n\n```go\nfunc main() {\n   byts := []byte(\"\")\n   s1 := append(byts,'a')\n   s2:= append(byts,'b')\n   fmt.Println(byts)\n   fmt.Println(string(s1),string(s2)) // a b\n}\n```\n\n观察上面两个程序，只是添加了一行代码，两次执行结构却完全不同。导致结果完全不同的原因在于，`fmt.Println(byts)`导致`byts`逃脱到堆上。\n\n查看两份代码编译后的`[]byte(\"\")`对应的汇编代码片段：\n\n代码1：\n\n```asm\n0x0036 00054 (main.go:6)\tLEAQ\t\"\"..autotmp_6+120(SP), AX\n0x003b 00059 (main.go:6)\tPCDATA\t$2, $0\n0x003b 00059 (main.go:6)\tMOVQ\tAX, (SP)\n0x003f 00063 (main.go:6)\tXORPS\tX0, X0\n0x0042 00066 (main.go:6)\tMOVUPS\tX0, 8(SP)\n0x0047 00071 (main.go:6)\tCALL\truntime.stringtoslicebyte(SB)\n```\n\n代码2：\n\n```asm\n0x0036 00054 (main.go:6)\tMOVQ\t$0, (SP)\n0x003e 00062 (main.go:6)\tXORPS\tX0, X0\n0x0041 00065 (main.go:6)\tMOVUPS\tX0, 8(SP)\n0x0046 00070 (main.go:6)\tCALL\truntime.stringtoslicebyte(SB)\n```\n\n可以看到，两次调用`runtime.stringtoslicebyte`时传递的参数不同，第一次的第一个参数是非空的，而第二次的第一次参数的空的，查看该函数实现：\n\n```go\nconst tmpStringBufSize = 32\n\ntype tmpBuf [tmpStringBufSize]byte\n\nfunc stringtoslicebyte(buf *tmpBuf, s string) []byte {\n\tvar b []byte\n    // 如果buf不为空，并且len(buf)小于len(s)，会直接使用buf作为底层数组，而buf的长度为32\n\tif buf != nil && len(s) <= len(buf) {\n\t\t*buf = tmpBuf{}\n\t\tb = buf[:len(s)]\n\t} else {\n\t\tb = rawbyteslice(len(s))\n\t}\n\tcopy(b, s)\n\treturn b\n}\n\n// rawbyteslice allocates a new byte slice. The byte slice is not zeroed.\nfunc rawbyteslice(size int) (b []byte) {\n\tcap := roundupsize(uintptr(size))\n\tp := mallocgc(cap, nil, false)\n\tif cap != uintptr(size) {\n\t\tmemclrNoHeapPointers(add(p, uintptr(size)), cap-uintptr(size))\n\t}\n\n\t*(*slice)(unsafe.Pointer(&b)) = slice{p, size, int(cap)}\n\treturn\n}\n```\n\n通过上面的代码，我们可以得知，代码1中的`byts`，`cap`为`32`，而代码2中的`byts`，`cap`为0。\n\n因为在代码1中，`cap`为`32`，则两次`append`都不会对底层数组发送重分配，而且都是修改第一个元素，因此第二次操作会覆盖第一次操作。而在代码2中，每次`append`都会重新分配一个底层数组。\n\n\n\n","tags":["go"]},{"title":"go map分析","url":"/2019/03/30/go-map分析/","content":"\n`map`其实就是一个`hash table`，今天我们来看一下`go`中`map`的实现，相关代码位于`runtime/map.go`中。\n\n### 结构定义\n\n我们首先来看一下`map`的相关结构定义\n\n```go\ntype hmap struct {\n\tcount     int // 当前map中存放的元素，我们可以通过内置函数`len`来获取\n\tflags     uint8\n\tB         uint8  // 当前map的backet数量为2^B，其中最大能够存放loadFactor * 2^B个元素，当超过这个阈值时就会进行扩容，loadFactor默认为13/2，这个值是全局定义的常量\n\tnoverflow uint16 // 总的overflow的数量\n\thash0     uint32 // hash seed\n\n\tbuckets    unsafe.Pointer // bucket数组，长度为2^B，这里的bucket其实本质上是一个bmap链表\n\toldbuckets unsafe.Pointer // 如果发生扩容，旧的buckets就会保存到oldbuckets\n\tnevacuate  uintptr        // 扩容时需要从原来的buckets将数据迁移到新的buckets中，该字段表示小于该数值的buckets当前都已经迁移完成\n\n\textra *mapextra // 如果map中保存的key和value都没有包含指针，那么gc时就不需要对buckets里面的内容进行扫描，但是每个bucket本质上是一个链表，buckets头部保存的是每个bucket链表的头节点，这时候会将每个链表的后续节点保存到该字段内，从而gc时可以对这些后续节点进行扫描，防止被回收\n}\n```\n\n上面`extra`字段对应的`mapextra`类型：\n\n```go\ntype mapextra struct {\n\toverflow    *[]*bmap // 这里保存bucket链表的后续节点，实际上bucket就是一个bmap\n\toldoverflow *[]*bmap // 这里保存oldbucket链表的后续节点，实际上bucket就是一个bmap\n\n\t// nextOverflow holds a pointer to a free overflow bucket.\n\tnextOverflow *bmap // 分配bmap时，可能会预先分配一些，当需要时可以直接从这里获取\n}\n```\n\n上面说的，每个`bucket`实际上是一个`bmap`链表，而`hmap`中的`buckets`是一个`bmap`链表数组，这是不是和开散列很像呢？和开散列不同的是，开散列中，链表中每个节点都只保存一个键值对，但是这里，**一个`bmap`中保存了8个键值对**，下面来看一下`bmap`的定义：\n\n```go\n// A bucket for a Go map.\ntype bmap struct {\n\t// 这里bucketCnt是一个全局声明的常量，大小为8，也就是限制每个bmap中保存8个键值对\n    // 当判断一个key是否在当前bmap中时，会先获取这个key的hash的高8位，然后在tophash中查找是否有匹配的索引，如果有再进一步比较key是否相同，如果当前bmap中没有找到，则到下一个bmap中查找\n\ttophash [bucketCnt]uint8\n\t// tophash后面紧跟着保存在当前bmap中的8个key和8个value\n    // 因为不同类型的key和value内存大小是不同的，这里需要在运行时根据指针运算来访问\n    // 在bmap中是按照 `k1,k2,..,k8,v1,v2,...,v8` 这样来排列的，而不是按照直观上的`k1,v1,k2,v2,...,k8,v8`这样来排列，主要是为了减少内存对齐时额外的内存开销\n    // 8个键值对之后还有一个overflow指针，用来链接下一个bmap，正如上面说的，每个bucket实际上是一个bmap链表，这里通过overflow链接的这些bmap被称为`overflow bucket`\n}\n```\n\n如上面`bmap`所见，键值对并没有显示声明出来，而是需要在运行时根据指针运算来访问，这里来看一下一个全局声明的常量`dataOffset`，这个常量在后续会经常看到：\n\n```go\nconst(\n    ...\n\tdataOffset = unsafe.Offsetof(struct {\n\t\tb bmap\n\t\tv int64\n\t}{}.v)\n    ...\n)\n```\n\n因为`bmap`实际上只声明了一个`uint8`类型的数组，因此这里`v`字段的偏移量就是实际`bmap`中第一个`key`值的偏移量\n\n这里假设`bmap`的地址是`bptr`，`key`的类型大小是`ksize`，`val`的类型大小是`vsize`，那么访问第`i`个`key`和`val`的地址可以通过下面公式计算（`i`从`0`开始计算）：\n\n```\nith key: bptr + dataOffset + i * ksize\nith val: bptr + dataOffset + bucketCnt * ksize + i * vsize\n```\n\n至此，我们对`map`的结构有了一个大体的了解，其键值对的存储结构大致可以用下图来描述：\n\n```\n    bucket数组         bmap中的overflow指向下一个bmap \n  实际上是bmap数组    这些由overflow引用的bucket被称作overflow bucket\n|-----------------|  |-----------------|\n|k1,..,k8,v1,..,v8|->|k1,..,k8,v1,..,v8|-> ...\t\t  \n|-----------------|  |-----------------|\n|k1,..,k8,v1,..,v8|-> ...\n|-----------------|\n|k1,..,k8,v1,..,v8|-> ...\n|-----------------|\n|k1,..,k8,v1,..,v8|-> ...\n|-----------------|\n```\n\n\n\n> 从上面可以看到，一个`bucket`实际上是一个`bmap`，而且`bmap`可以通过`overflow`指针来形成链表，这些通过`overflow`引用的`bmap`被称作`overflow bucket`\n>\n> 个人认为把`bucket`当作一个`bmap`链表会比较好理解。\n\n### map创建\n\n当我们使用`make`创建`map`时，可以指定一个`size`参数，当我们没有指定`size`时，或者`size`在编译时已知是一个不大于`8`的数值时（也就是size是一个常量），会通过`makemap_small`来创建一个`map`：\n\n```go\n// makehmap_small implements Go map creation for make(map[k]v) and\n// make(map[k]v, hint) when hint is known to be at most bucketCnt\n// at compile time and the map needs to be allocated on the heap.\nfunc makemap_small() *hmap {\n\th := new(hmap)\n\th.hash0 = fastrand() // 初始化hash seed\n\treturn h\n}\n```\n\n可以看到，通过`makemap_small`创建的`map`，此时的`B`是0，`buckets`是`nil`，在第一次写入的时候才会去创建具体的`buckets`\n\n对应的，当我们指定了一个合适的`size`时，会通过另一个函数来创建`map`：\n\n```go\n// makemap implements Go map creation for make(map[k]v, hint).\n// If the compiler has determined that the map or the first bucket\n// can be created on the stack, h and/or bucket may be non-nil.\n// If h != nil, the map can be created directly in h.\n// If h.buckets != nil, bucket pointed to can be used as the first bucket.\nfunc makemap(t *maptype, hint int, h *hmap) *hmap {\n    // 如果小于0或者过大，则设为0\n\tif hint < 0 || hint > int(maxSliceCap(t.bucket.size)) {\n\t\thint = 0\n\t}\n\n\t// initialize Hmap\n    // 编译器可能会进行优化，在栈上创建map，因此h可能不为空\n\tif h == nil {\n\t\th = new(hmap)\n\t}\n\th.hash0 = fastrand()\n\n\t// find size parameter which will hold the requested # of elements\n\tB := uint8(0)\n    // 根据传入的size来计算B的大小，这里的B是buckets的数量，前文说过，map最多可以容纳 0.65*2^B 个键值对，当超过这个阈值时，会执行扩容\n\tfor overLoadFactor(hint, B) { \n\t\tB++\n\t}\n\th.B = B\n\n\t// allocate initial hash table\n\t// if B == 0, the buckets field is allocated lazily later (in mapassign)\n\t// If hint is large zeroing this memory could take a while.\n\tif h.B != 0 {\n\t\tvar nextOverflow *bmap\n        // 创建bucket数组，这里可能会预先分配几个bmap，后续可以直接使用而不需要执行内存分配\n\t\th.buckets, nextOverflow = makeBucketArray(t, h.B, nil)\n\t\tif nextOverflow != nil {\n\t\t\th.extra = new(mapextra)\n\t\t\th.extra.nextOverflow = nextOverflow\n\t\t}\n\t}\n\n\treturn h\n}\n```\n\n当我们创建一个`map`时，如果`map`中要存储的键值对数据可以估计的话，最好在创建的时候指定好`size`，这样可以预先分配好`bucket`的数量。\n\n\n\n### map的访问\n\n通常我们对`map`的访问有`get`、`set`、`delete`、和`for range`操作，在分析具体的实现下时，我们要先来了解一下如果定位一个`key`的位置，这里先不涉及在执行扩容时的场景。\n\n我们再回顾一下图：\n\n```\n    bucket数组         bmap中的overflow指向下一个bmap \n  实际上是bmap数组    这些由overflow引用的bucket被称作overflow bucket\n|-----------------|  |-----------------|\n|k1,..,k8,v1,..,v8|->|k1,..,k8,v1,..,v8|-> ...\t\t  \n|-----------------|  |-----------------|\n|k1,..,k8,v1,..,v8|-> ...\n|-----------------|\n|k1,..,k8,v1,..,v8|-> ...\n|-----------------|\n|k1,..,k8,v1,..,v8|-> ...\n|-----------------|\n```\n\n要定位一个`key`，我们需要先确定这个`key`是落在哪个`bucket`中，也就是哪一条`bmap`链表中，通过计算`key`的哈希值，然后通过`hash%bucket数量`的来定位 ，具体的逻辑如下：\n\n```go\nalg := t.key.alg // 这里的t是map的类型描述\nhash := alg.hash(key, uintptr(h.hash0)) // 计算hash值\nm := bucketMask(h.B) // 这里的m为 1<<B-1\n// 这里的hash&m等价于求模操作\nb := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + (hash&m)*uintptr(t.bucketsize))) \n```\n\n当定位到具体的`bucket`后，只需要从头开始遍历该`bmap`链表，因为`bmap`中有个`tophash`数组，保存了每个`key`对应的哈希值的高八位，因此我们不需要挨个对每个`key`进行比较，只需要先比较哈希值的高八位是否相同就行了，如果相同才接着比较`key`是否相等，具体代码如下：\n\n```go\ntop := tophash(hash) // 取key的hash值的高八位\n\t// 这里b是一个bmap指针，如果当前bmap没有，则查找下一个bmap\n\tfor ; b != nil; b = b.overflow(t) { \n        // 遍历当前bmap，这里bucketCnt是常量8，限制一个bmap中最多只有8个键值对\n\t\tfor i := uintptr(0); i < bucketCnt; i++ {\n            // 先比较哈希值高八位，如果不相等则continue\n\t\t\tif b.tophash[i] != top {\n\t\t\t\tcontinue\n\t\t\t}\n            // 计算当前的key的位置\n\t\t\tk := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\n            // 是否间接存储（存储的是实际key的地址）\n\t\t\tif t.indirectkey {\n\t\t\t\tk = *((*unsafe.Pointer)(k))\n\t\t\t}\n            // 比较key是否相等\n\t\t\tif alg.equal(key, k) {\n\t\t\t\t......\n\t\t\t}\n\t\t}\n\t}\n```\n\n##### get\n\n与`get`相关的方法有多个：\n\n```go\n// val := m[key]\nfunc mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer\n// val,has := m[key]\nfunc mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool) \n// for-range时，用于获取key和val\nfunc mapaccessK(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, unsafe.Pointer)\n```\n\n这三个方法大同小异，这里只分析第一个方法：\n\n先看该函数的注释，如果`key`不存在时，返回的是对应的`val`类型的空值。\n\n```go\n// mapaccess1 returns a pointer to h[key].  Never returns nil, instead\n// it will return a reference to the zero object for the value type if\n// the key is not in the map.\n// NOTE: The returned pointer may keep the whole map live, so don't\n// hold onto it for very long.\nfunc mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {\n    // 如果没有内容，则返回对应类型的零值\n\tif h == nil || h.count == 0 {\n\t\treturn unsafe.Pointer(&zeroVal[0])\n\t}\n    // map不是并发安全的，如果存在写操作则panic，因此我们需要在多个goroutine对map进行并发读写时，需要加锁保护\n\tif h.flags&hashWriting != 0 {\n\t\tthrow(\"concurrent map read and map write\")\n\t}\n\talg := t.key.alg\n    // 计算key的哈希值\n\thash := alg.hash(key, uintptr(h.hash0))\n    // 获取buckets数组长度的掩码\n\tm := bucketMask(h.B)\n    // 定位key所在的bucket\n\tb := (*bmap)(add(h.buckets, (hash&m)*uintptr(t.bucketsize)))\n    // 当前是否处于扩容操作，当发生扩容操作时，或重新分配buckets数组，并且需要将旧的buckets内的键值对迁移到新的buckets数组中，这个迁移过程不是一次性完成的而是分批完成的\n\tif c := h.oldbuckets; c != nil {\n       \t// 扩容操作有两种：第一种，如果是因为当前的键值对数量已经达到了阈值0.65*2^B，则会触发扩容，这时候新的buckets数组的数量为原来的2倍；第二种是当前键值对数量并没有达到阈值，但是当前存在太多的overflow bucket，可能是因为之前存储了太多的键值对，但是后面又被删除掉了，这时候有的bucket链表会比较长，但是实际上存储的键值对比较稀疏，这样会影响查找效率，这种情况会触发sameSizeGrow，即扩容时buckets数组长度与原来一致\n        // 如果是前一种，则原先的buckets数量的掩码是m>>1\n\t\tif !h.sameSizeGrow() {\n\t\t\t// There used to be half as many buckets; mask down one more power of two.\n\t\t\tm >>= 1\n\t\t}\n        // 计算该key落在的oldbuckets中的哪个bucket中\n\t\toldb := (*bmap)(add(c, (hash&m)*uintptr(t.bucketsize)))\n        // 如果当前bucket还没有迁移，则在该bucket中查询，迁移操作是按照bucket为单位进行的\n\t\tif !evacuated(oldb) {\n\t\t\tb = oldb\n\t\t}\n\t}\n    // 获取哈希值高八位\n\ttop := tophash(hash)\n    // 遍历bmap链表\n\tfor ; b != nil; b = b.overflow(t) {\n\t\tfor i := uintptr(0); i < bucketCnt; i++ {\n            // 比较哈希值高八位\n\t\t\tif b.tophash[i] != top {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tk := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\n\t\t\tif t.indirectkey {\n\t\t\t\tk = *((*unsafe.Pointer)(k))\n\t\t\t}\n            // 比较key是否相等\n\t\t\tif alg.equal(key, k) {\n                // 获取key对应的val，这里的计算公式在前面结构定义一节中已经说明过\n\t\t\t\tv := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize))\n                // 如果这里存储的是val的地址\n\t\t\t\tif t.indirectvalue {\n\t\t\t\t\tv = *((*unsafe.Pointer)(v))\n\t\t\t\t}\n\t\t\t\treturn v\n\t\t\t}\n\t\t}\n\t}\n\treturn unsafe.Pointer(&zeroVal[0])\n}\n```\n\n##### set \n\n`set`操作对应的方法是`mapassign`，这个方法为指定的`key`分配一个用于存放`val`的槽，或者返回已经存在的槽，新的`val`直接写入这个槽中，即完成了`map`的`set`操作。\n\n在写入时，因为可能该`key`已经存在，因此需要先遍历目标`bucket`的`bmap`链表，具体代码如下：\n\n```go\n// Like mapaccess, but allocates a slot for the key if it is not present in the map.\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {\n\t// 不允许写入空map\n    if h == nil {\n\t\tpanic(plainError(\"assignment to entry in nil map\"))\n\t}\n    // 如果有并发写操作，直接panic\n\tif h.flags&hashWriting != 0 {\n\t\tthrow(\"concurrent map writes\")\n\t}\n\talg := t.key.alg\n    // 计算key的哈希值\n\thash := alg.hash(key, uintptr(h.hash0))\n\n\t// Set hashWriting after calling alg.hash, since alg.hash may panic,\n\t// in which case we have not actually done a write.\n    // 设置写标志\n\th.flags |= hashWriting\n\t// 如果buckets数组为空，则会创建一个长度为1的buckets数组\n\tif h.buckets == nil {\n\t\th.buckets = newobject(t.bucket) // newarray(t.bucket, 1)\n\t}\n\nagain:\n    // 计算目标bucket在buckets数组中的索引\n\tbucket := hash & bucketMask(h.B)\n    // 如果当前正在执行扩容操作，则会执行迁移操作，前面说过扩容时的迁移操作是分批进行的，而迁移是按照bucket为单位进行的，而触发迁移的时机是执行写操作\n\tif h.growing() {\n        // 该函数会执行迁移操作，迁移的目标是bucket%len_of_oldbuckets\n\t\tgrowWork(t, h, bucket) \n\t}\n    // 计算要写入的bucket\n\tb := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize)))\n    // 计算哈希值高八位\n\ttop := tophash(hash)\n\t// 在bmap中要插入的索引，如果前文所说，一个bmap最多可以有8个键值对\n\tvar inserti *uint8\n    // 要插入key的地址\n\tvar insertk unsafe.Pointer\n    // 对应的val的地址\n\tvar val unsafe.Pointer\n    // 因为前面已经执行过扩容操作，因此写入只需要对新的bucket进行操作\n\tfor {\n        // 遍历当前bmap\n\t\tfor i := uintptr(0); i < bucketCnt; i++ {\n            // 高八位哈希值不相同\n\t\t\tif b.tophash[i] != top {\n                // 对第一个遇到的空槽，设置为待定槽，因为可能在后续遍历中发现当前key已经存在，则直接返回对应的val就好了\n\t\t\t\tif b.tophash[i] == empty && inserti == nil {\n\t\t\t\t\tinserti = &b.tophash[i]\n\t\t\t\t\tinsertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\n\t\t\t\t\tval = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize))\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n            // 这里说明哈希值高八位一致，因此需要比较key是否相等\n\t\t\tk := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\n\t\t\tif t.indirectkey {\n\t\t\t\tk = *((*unsafe.Pointer)(k))\n\t\t\t}\n            // 如果不相等，继续遍历下一个\n\t\t\tif !alg.equal(key, k) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// 如果key已经存在，直接返回对应的val地址就好了\n\t\t\tif t.needkeyupdate {\n\t\t\t\ttypedmemmove(t.key, k, key)\n\t\t\t}\n\t\t\tval = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize))\n            // goto大法好\n\t\t\tgoto done\n\t\t}\n        // 当前bmap没有找到对应的key，则继续遍历下一个bmap\n\t\tovf := b.overflow(t)\n\t\tif ovf == nil { // 如果当前bucket已经遍历完成，则跳出\n\t\t\tbreak\n\t\t}\n\t\tb = ovf\n\t}\n\t\n    // 首先判断是否需要进行扩容：如果当前没有扩容操作正在执行并且数据达到阈值或者存在太多的bmap，则会触发扩容操作\n\tif !h.growing() && (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) {\n        // 触发扩容操作，然后跳到开头重新执行上面流程\n\t\thashGrow(t, h)\n\t\tgoto again // Growing the table invalidates everything, so try again\n\t}\n\t// 如果不需要扩容操作，并且没有可以使用的空槽，则需要分配一个新的overflow bucket，这里是分配在链表尾部，当前的b指向的就是整条bmap链表的最后一个节点\n\tif inserti == nil {\n\t\t// all current buckets are full, allocate a new one.\n\t\tnewb := h.newoverflow(t, b)\n        // 插入第一个槽中\n\t\tinserti = &newb.tophash[0]\n\t\tinsertk = add(unsafe.Pointer(newb), dataOffset)\n\t\tval = add(insertk, bucketCnt*uintptr(t.keysize))\n\t}\n\n\t// store new key/value at insert position\n    // 设置key\n    // 这里针对是否需要对key或者val进行间接存储的处理\n\tif t.indirectkey {\n\t\tkmem := newobject(t.key)\n\t\t*(*unsafe.Pointer)(insertk) = kmem\n\t\tinsertk = kmem\n\t}\n\tif t.indirectvalue {\n\t\tvmem := newobject(t.elem)\n\t\t*(*unsafe.Pointer)(val) = vmem\n\t}\n\ttypedmemmove(t.key, insertk, key)\n\t*inserti = top\n\th.count++\t// map中元素数据加1\n\ndone:\n    // 检查写操作标志位\n\tif h.flags&hashWriting == 0 {\n\t\tthrow(\"concurrent map writes\")\n\t}\n    // 清除写操作\n\th.flags &^= hashWriting\n\tif t.indirectvalue {\n\t\tval = *((*unsafe.Pointer)(val))\n\t}\n\treturn val\n}\n```\n\n##### delete\n\n删除操作流程如下：\n\n```go\nfunc mapdelete(t *maptype, h *hmap, key unsafe.Pointer) {\n   if h == nil || h.count == 0 {\n      return\n   }\n    // 设置写操作标志位\n   if h.flags&hashWriting != 0 {\n      throw(\"concurrent map writes\")\n   }\n\n   alg := t.key.alg\n   hash := alg.hash(key, uintptr(h.hash0))\n\n   // Set hashWriting after calling alg.hash, since alg.hash may panic,\n   // in which case we have not actually done a write (delete).\n   h.flags |= hashWriting\n\n   bucket := hash & bucketMask(h.B)\n    // 如果正在扩容，先执行迁移操作\n   if h.growing() {\n      growWork(t, h, bucket)\n   }\n   b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize)))\n   top := tophash(hash)\nsearch:\n    // 查找要删除的可以，因为前面已经执行了迁移操作，因此这里只需要在新的bucket中查找即可\n   for ; b != nil; b = b.overflow(t) {\n      for i := uintptr(0); i < bucketCnt; i++ {\n         if b.tophash[i] != top {\n            continue\n         }\n         k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\n         k2 := k\n         if t.indirectkey {\n            k2 = *((*unsafe.Pointer)(k2))\n         }\n         if !alg.equal(key, k2) {\n            continue\n         }\n         // 执行清除操作\n         // Only clear key if there are pointers in it.\n         if t.indirectkey {\n            *(*unsafe.Pointer)(k) = nil\n         } else if t.key.kind&kindNoPointers == 0 {\n            memclrHasPointers(k, t.key.size)\n         }\n         v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize))\n         if t.indirectvalue {\n            *(*unsafe.Pointer)(v) = nil\n         } else if t.elem.kind&kindNoPointers == 0 {\n            memclrHasPointers(v, t.elem.size)\n         } else {\n            memclrNoHeapPointers(v, t.elem.size)\n         }\n         b.tophash[i] = empty // 将tophash中的值设为empty，表示空槽\n         h.count-- // 数量减一\n         break search\n      }\n   }\n\n   if h.flags&hashWriting == 0 {\n      throw(\"concurrent map writes\")\n   }\n   h.flags &^= hashWriting\n}\n```\n\n##### for-range\n\n执行`for-range`操作时，需要一个迭代器，我们先来看迭代器的声明：\n\n```go\n// A hash iteration structure.\ntype hiter struct {\n\tkey         unsafe.Pointer // key值，nil表示迭代结束\n\tvalue       unsafe.Pointer // val值\n\tt           *maptype\n\th           *hmap\n\tbuckets     unsafe.Pointer // bucket ptr at hash_iter initialization time\n\tbptr        *bmap          // 当前正在迭代的buckete的指针\n\toverflow    *[]*bmap       // keeps overflow buckets of hmap.buckets alive\n\toldoverflow *[]*bmap       // keeps overflow buckets of hmap.oldbuckets alive\n\tstartBucket uintptr        // 记录这次迭代从哪个bucket开始\n\toffset      uint8          // 记录这次迭代从hmap中的哪个offset开始\n\twrapped     bool           // already wrapped around from end of bucket array to beginning\n\tB           uint8\n\ti           uint8\n\tbucket      uintptr\n\tcheckBucket uintptr\n}\n```\n\n`hiter`的创建：\n\n```go\nfunc mapiterinit(t *maptype, h *hmap, it *hiter) {\n\tif h == nil || h.count == 0 {\n\t\treturn\n\t}\n\n\tit.t = t // 记录map类型信息\n\tit.h = h // 引用map\n\n\t// grab snapshot of bucket state\n\tit.B = h.B // 记录当前的B\n\tit.buckets = h.buckets // 记录当前的buckets\n    // 如果当前map中的键值对没有指针\n\tif t.bucket.kind&kindNoPointers != 0 {\n\t\t// Allocate the current slice and remember pointers to both current and old.\n\t\t// This preserves all relevant overflow buckets alive even if\n\t\t// the table grows and/or overflow buckets are added to the table\n\t\t// while we are iterating.\n\t\th.createOverflow()\n\t\tit.overflow = h.extra.overflow\n\t\tit.oldoverflow = h.extra.oldoverflow\n\t}\n\n\t// decide where to start\n    // 这里随机选举一个开始迭代的位置，因此我们对map进行for-range操作，每次输出的序列都是不同的\n\tr := uintptr(fastrand())\n\tif h.B > 31-bucketCntBits {\n\t\tr += uintptr(fastrand()) << 31\n\t}\n    // 设置开始的bucket和offset\n\tit.startBucket = r & bucketMask(h.B)\n\tit.offset = uint8(r >> h.B & (bucketCnt - 1))\n\n\t// 当前迭代的bucket索引\n\tit.bucket = it.startBucket\n\n\t// 设置迭代标志位\n\tif old := h.flags; old&(iterator|oldIterator) != iterator|oldIterator {\n\t\tatomic.Or8(&h.flags, iterator|oldIterator)\n\t}\n\t// 执行next操作\n\tmapiternext(it)\n}\n```\n\n`mapiternext`方法用于推进迭代器前进到下一个键值对，对应逻辑：\n\n```go\n\nfunc mapiternext(it *hiter) {\n\th := it.h\n\tif h.flags&hashWriting != 0 {\n\t\tthrow(\"concurrent map iteration and map write\")\n\t}\n\tt := it.t\n\tbucket := it.bucket\n\tb := it.bptr // 当前正在遍历的bucket\n\ti := it.i\n\tcheckBucket := it.checkBucket\n\talg := t.key.alg\n\nnext:\n\tif b == nil { // 如果it.bptr还没有初始化，需要根据it.bucket进行初始化，第一次执行或者每次遍历完一个bucket都会清空bptr\n\t\tif bucket == it.startBucket && it.wrapped {\n\t\t\t// end of iteration\n\t\t\tit.key = nil\n\t\t\tit.value = nil\n\t\t\treturn\n\t\t}\n        // 如果正在执行扩容，并且迭代是在扩容之后开始的，这时候如果旧的bucket还没有迁移到新的bucket中，那么需要到旧的bucket中遍历\n\t\tif h.growing() && it.B == h.B {\n            // 获取当前要迭代的bucket对应的oldbucket\n\t\t\toldbucket := bucket & it.h.oldbucketmask()\n\t\t\tb = (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)))\n            // 如果oldbucket中的元素还没有迁移到新的bucket中\n\t\t\tif !evacuated(b) {\n\t\t\t\tcheckBucket = bucket // oldbucket中的键值对迁移到新的bucket中时，可能会迁移到两个bucket中，比如原来长度是4，hash%4等于3，限制长度是8，hash%8可能为4也可能为7，这里的checkBucket记录当前正在遍历h.buckets数组中的哪个bucket，用于后面的判断\n\t\t\t} else {\n                // 已经迁移完成，直接在新的bucket中遍历\n\t\t\t\tb = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize)))\n\t\t\t\tcheckBucket = noCheck\n\t\t\t}\n\t\t} else { // 当前没有扩容操作，直接在新的bucket中遍历\n\t\t\tb = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize)))\n\t\t\tcheckBucket = noCheck\n\t\t}\n\t\tbucket++ // 下一次遍历的bucket的索引\n        // 因为开始迭代的bucket位置是随机的，如果越界了，从第一个bucket开始\n\t\tif bucket == bucketShift(it.B) {\n\t\t\tbucket = 0\n\t\t\tit.wrapped = true\n\t\t}\n\t\ti = 0\n\t}\n    // 遍历bmap中键值对\n\tfor ; i < bucketCnt; i++ {\n        // 计算开始遍历的偏移位置\n\t\toffi := (i + it.offset) & (bucketCnt - 1)\n        // 如果空槽，则跳过\n\t\tif b.tophash[offi] == empty || b.tophash[offi] == evacuatedEmpty {\n\t\t\tcontinue\n\t\t}\n        // 获取key\n\t\tk := add(unsafe.Pointer(b), dataOffset+uintptr(offi)*uintptr(t.keysize))\n\t\tif t.indirectkey {\n\t\t\tk = *((*unsafe.Pointer)(k))\n\t\t}\n        // 获取val\n\t\tv := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+uintptr(offi)*uintptr(t.valuesize))\n        // 如果正在执行扩容，并且正在遍历的bucket还没有迁移完成，并且扩容是由于键值对达到阈值触发的，这时候扩容后的buckets数组的长度为原来的两倍，原来的一个bucket中的键值对迁移时会迁移到新的两个bucket中，因为目标bucket是通过哈希取模计算的，而这时候bucket数组长度扩大了两倍，比如原理数组长度是4，取模后是3，现在数组长度是8，取模后可能为3也可能为7\n\t\tif checkBucket != noCheck && !h.sameSizeGrow() {\n            // 如果key==key，正常都是走这个逻辑\n\t\t\tif t.reflexivekey || alg.equal(k, k) { \n\t\t\t\t// 如果当前的key不是落在当前的bucket中的，比如现在正在遍历的bucket为3，但是key现在的hash是7，以后迁移时将迁移到索引为7的bucket中，因此这个时候应该跳过这个key\n\t\t\t\thash := alg.hash(k, uintptr(h.hash0))\n\t\t\t\tif hash&bucketMask(it.B) != checkBucket {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t} else { // key != key的情况，比如math.NaN() != math.NaN()\n\t\t\t\tif checkBucket>>(it.B-1) != uintptr(b.tophash[offi]&1) {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t} \n\t\t}\n        // 走到这里，可能有一种情况，在迭代开始之后发生了扩容（比如我们在for-range里面插入新的键值对，这时候触发了迁移），这时候迭代的是扩容之前的键值对，即只会迭代当前的oldbuckets里面键值对，这时候如果这些键值对还没有发生迁移或者说key是不可比较的，比如key为math.NAN()，因为key!=key，因此这个key不会被删除或者更新，可以直接返回\n\t\tif (b.tophash[offi] != evacuatedX && b.tophash[offi] != evacuatedY) ||\n\t\t\t!(t.reflexivekey || alg.equal(k, k)) {\n\t\t\tit.key = k\n\t\t\tif t.indirectvalue {\n\t\t\t\tv = *((*unsafe.Pointer)(v))\n\t\t\t}\n\t\t\tit.value = v\n\t\t} else { // 走到这里说明发生了迁移，使用mapaccessK来获取\n\t\t\trk, rv := mapaccessK(t, h, k)\n\t\t\tif rk == nil { // 已经被删除了\n\t\t\t\tcontinue // key has been deleted\n\t\t\t}\n\t\t\tit.key = rk\n\t\t\tit.value = rv\n\t\t}\n        // 更新迭代器状态\n\t\tit.bucket = bucket\n\t\tif it.bptr != b { // avoid unnecessary write barrier; see issue 14921\n\t\t\tit.bptr = b\n\t\t}\n\t\tit.i = i + 1\n\t\tit.checkBucket = checkBucket\n\t\treturn\n\t}\n    // 当前bmap遍历完成，遍历下一个bmap，如果已经是bmap链表的最后一个节点，则返回的b为nil，这时候会触发遍历下一个bucket\n\tb = b.overflow(t)\n\ti = 0\n\tgoto next\n}\n```\n\n\n\n### 扩容\n\n当写入时，如果当前`bucket`已经满了，则会触发扩容检查，如果当前不处于扩容状态并且满足：\n\n- 当前键值对格式已经达到 `0.65*2^B`\n- 当前`bmap`的数量达到`1<<(B&15)`，这里的`B`如果大于15，按照15计算\n\n下面看一下开始扩容的逻辑：\n\n```go\nfunc hashGrow(t *maptype, h *hmap) {\n\t// If we've hit the load factor, get bigger.\n\t// Otherwise, there are too many overflow buckets,\n\t// so keep the same number of buckets and \"grow\" laterally.\n\tbigger := uint8(1)\n    // 如果键值对数量没有达到阈值，则说明是overflow bucket过多触发的\n\tif !overLoadFactor(h.count+1, h.B) {\n\t\tbigger = 0\n\t\th.flags |= sameSizeGrow\n\t}\n\toldbuckets := h.buckets\n    // 分配新的buckets\n\tnewbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil)\n\t// 设置更新迭代标志位\n\tflags := h.flags &^ (iterator | oldIterator)\n\tif h.flags&iterator != 0 {\n\t\tflags |= oldIterator\n\t}\n\t// commit the grow (atomic wrt gc)\n    // 更新hmap字段\n\th.B += bigger\n\th.flags = flags\n\th.oldbuckets = oldbuckets\n\th.buckets = newbuckets\n\th.nevacuate = 0\n\th.noverflow = 0\n\n\tif h.extra != nil && h.extra.overflow != nil {\n\t\t// Promote current overflow buckets to the old generation.\n\t\tif h.extra.oldoverflow != nil {\n\t\t\tthrow(\"oldoverflow is not nil\")\n\t\t}\n\t\th.extra.oldoverflow = h.extra.overflow\n\t\th.extra.overflow = nil\n\t}\n\tif nextOverflow != nil {\n\t\tif h.extra == nil {\n\t\t\th.extra = new(mapextra)\n\t\t}\n\t\th.extra.nextOverflow = nextOverflow\n\t}\n\n\t// the actual copying of the hash table data is done incrementally\n\t// by growWork() and evacuate().\n}\n```\n\n再来看一下`bucket`的迁移操作：\n\n```go\nfunc growWork(t *maptype, h *hmap, bucket uintptr) {\n\t// 迁移将要使用的bucket对应的oldbucket的数据\n\tevacuate(t, h, bucket&h.oldbucketmask())\n\n\t// 继续对h.nevacuate对应的bucket进行迁移\n\tif h.growing() {\n\t\tevacuate(t, h, h.nevacuate)\n\t}\n}\n```\n\n从上面可以看到，一次`growwork`最多可以迁移两个`bucket`，这样可以尽早完成扩容之后的迁移\n\n接着看一下`evacuate`的逻辑：\n\n```go\nfunc evacuate(t *maptype, h *hmap, oldbucket uintptr) {\n    // 计算要进行迁移的bucket\n\tb := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)))\n\tnewbit := h.noldbuckets() // 获取oldbuckets数组的长度\n    // 如果还没有执行过迁移\n\tif !evacuated(b) {\n\t\t// 一个oldbucket中的key可能迁移到两个新的bucket中，这里使用x来表示低位目标bucket，y表示高位目标bucket\n\t\tvar xy [2]evacDst\n\t\tx := &xy[0]\n        // 低位目标bucket的索引和当前要迁移的oldbucket的索引一致\n\t\tx.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize)))\n\t\tx.k = add(unsafe.Pointer(x.b), dataOffset)\n\t\tx.v = add(x.k, bucketCnt*uintptr(t.keysize))\n\t\t// 如果是sameSizeGrow，buckets长度没有变化，则不会有高位目标bucket\n\t\tif !h.sameSizeGrow() {\n\t\t\t// Only calculate y pointers if we're growing bigger.\n\t\t\t// Otherwise GC can see bad pointers.\n\t\t\ty := &xy[1]\n            // 计算高位目标bucket\n\t\t\ty.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize)))\n\t\t\ty.k = add(unsafe.Pointer(y.b), dataOffset)\n\t\t\ty.v = add(y.k, bucketCnt*uintptr(t.keysize))\n\t\t}\n\t\t// 遍历bucket对应的bmap链表\n\t\tfor ; b != nil; b = b.overflow(t) {\n\t\t\tk := add(unsafe.Pointer(b), dataOffset)\n\t\t\tv := add(k, bucketCnt*uintptr(t.keysize))\n\t\t\tfor i := 0; i < bucketCnt; i, k, v = i+1, add(k, uintptr(t.keysize)), add(v, uintptr(t.valuesize)) {\n\t\t\t\ttop := b.tophash[i]\n\t\t\t\tif top == empty { // 空槽，没有键值对\n\t\t\t\t\tb.tophash[i] = evacuatedEmpty\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif top < minTopHash {\n\t\t\t\t\tthrow(\"bad map state\")\n\t\t\t\t}\n\t\t\t\tk2 := k\n\t\t\t\tif t.indirectkey {\n\t\t\t\t\tk2 = *((*unsafe.Pointer)(k2))\n\t\t\t\t}\n\t\t\t\tvar useY uint8\n                // 不是sameSizeGrow，说明可能会迁移到高位目标bucket\n\t\t\t\tif !h.sameSizeGrow() {\n\t\t\t\t\thash := t.key.alg.hash(k2, uintptr(h.hash0))\n                    // 存在迭代器，并且key!=key(NaNs)，一般不会走这个分支\n\t\t\t\t\tif h.flags&iterator != 0 && !t.reflexivekey && !t.key.alg.equal(k2, k2) {\n\t\t\t\t\t\tuseY = top & 1\n\t\t\t\t\t\ttop = tophash(hash)\n\t\t\t\t\t} else {\n                        // 比如hash是7，oldbuckets长度是4，现在是8，原来bucket是3，现在应该迁移到7这个bucket，这种情况hash&newbit=newbit    \n\t\t\t\t\t\tif hash&newbit != 0 {\n\t\t\t\t\t\t\tuseY = 1\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n                // 这里是对全局常量进行检查：evacuatedY=evacuatedX+1\n                // evacuatedX标记迁移到低位目标bucket\n                // evacuatedY标记迁移到高位目标bucket\n\t\t\t\tif evacuatedX+1 != evacuatedY {\n\t\t\t\t\tthrow(\"bad evacuatedN\")\n\t\t\t\t}\n\t\t\t\t// 对当前槽进行标记，表示已经完成迁移\n\t\t\t\tb.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY\n                // 根据是否迁移到高位bucket选择目标bucket\n\t\t\t\tdst := &xy[useY]                 // evacuation destination\n\t\t\t\t// 如果当前bmap满了，创建新的bmap\n\t\t\t\tif dst.i == bucketCnt {\n\t\t\t\t\tdst.b = h.newoverflow(t, dst.b)\n\t\t\t\t\tdst.i = 0\n\t\t\t\t\tdst.k = add(unsafe.Pointer(dst.b), dataOffset)\n\t\t\t\t\tdst.v = add(dst.k, bucketCnt*uintptr(t.keysize))\n\t\t\t\t}\n                // 执行键值对迁移\n\t\t\t\tdst.b.tophash[dst.i&(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check\n\t\t\t\tif t.indirectkey {\n\t\t\t\t\t*(*unsafe.Pointer)(dst.k) = k2 // copy pointer\n\t\t\t\t} else {\n\t\t\t\t\ttypedmemmove(t.key, dst.k, k) // copy value\n\t\t\t\t}\n\t\t\t\tif t.indirectvalue {\n\t\t\t\t\t*(*unsafe.Pointer)(dst.v) = *(*unsafe.Pointer)(v)\n\t\t\t\t} else {\n\t\t\t\t\ttypedmemmove(t.elem, dst.v, v)\n\t\t\t\t}\n              \t// 更新迁移目标状态\n\t\t\t\tdst.i++\n\t\t\t\t// These updates might push these pointers past the end of the\n\t\t\t\t// key or value arrays.  That's ok, as we have the overflow pointer\n\t\t\t\t// at the end of the bucket to protect against pointing past the\n\t\t\t\t// end of the bucket.\n\t\t\t\tdst.k = add(dst.k, uintptr(t.keysize))\n\t\t\t\tdst.v = add(dst.v, uintptr(t.valuesize))\n\t\t\t}\n\t\t}\n\t\t// Unlink the overflow buckets & clear key/value to help GC.\n        // 如果不存在对oldbuckets的迭代器并且键值对中包含指针，在oldbuckets清除当前迁移的bucket，帮助尽快gc掉这些没有用的内存\n\t\tif h.flags&oldIterator == 0 && t.bucket.kind&kindNoPointers == 0 {\n\t\t\tb := add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))\n\t\t\t// Preserve b.tophash because the evacuation\n\t\t\t// state is maintained there.\n\t\t\tptr := add(b, dataOffset)\n\t\t\tn := uintptr(t.bucketsize) - dataOffset\n\t\t\tmemclrHasPointers(ptr, n)\n\t\t}\n\t}\n\t// 如果当前迁移的bucket等于h.nevacuate则更新h.nevacuate的值\n    // 如果所有bucket都已经迁移完成，则消除扩容状态\n\tif oldbucket == h.nevacuate {\n\t\tadvanceEvacuationMark(h, t, newbit)\n\t}\n}\n```\n\n\n\n\n\n\n\n","tags":["go"]},{"title":"go中的猴子补丁","url":"/2019/03/06/go中的猴子补丁/","content":"\n### 函数值\n\n首先查看下面代码：\n\n```go \nfunc a()int {return 1}\n\nfunc main() {\n\tfmt.Printf(\"%p\\n\", a) // 0x48f950\n\tfn := a\n\tfmt.Printf(\"0x%x\\n\",*(*uintptr)(unsafe.Pointer(&fn))) // 0x4c8680\n\tfmt.Printf(\"0x%x\\n\", **(**uintptr)(unsafe.Pointer(&fn))) // 0x48f950\n}\n```\n\n根据上面的输出我们可以发现，函数值`fn`并没有直接持有函数`a`的地址，这是因为**`Go`的函数值可以包含一些额外的上下文信息**，这是实现闭包和绑定实例方法的关键，我们可以在[源码](https://github.com/golang/go/blob/e9d9d0befc634f6e9f906b5ef7476fbd7ebd25e3/src/runtime/runtime2.go#L75-L78)中找到点函数值类型的线索：\n\n```go\ntype funcval struct {\n\tfn uintptr\n\t// variable-size, fn-specific data here\n}\n```\n\n我们代码中的函数变量，实际上应该`*funcval`类型\n\n##### 闭包实现原理\n\n接下来，我们探究一下`golang`中闭包的实现原理，我们首先写一个简单的闭包demo，然后从编译后的汇编代码来探究其实现\n\n```go\nfunc main() {\n\tf := fn() // 这里的f是一个函数值\n\tf()\n}\n\nfunc fn() func() {\n\tvar a = 10\n\treturn func() {\n\t\tfmt.Println(a) // 捕获局部变量a\n\t}\n}\n```\n\n接下来将上面代码编译成汇编：\n\n```sh\n$ go tool compile -S -N main.go > asm.s\n```\n\n下面是生成的汇编，只保留主要的内容：\n\n```assembly\n\"\".main STEXT size=72 args=0x0 locals=0x18\n\t0x0000 00000 (demo.go:7)\tTEXT\t\"\".main(SB), $24-0\n\t0x0024 00036 (demo.go:8)\tCALL\t\"\".fn(SB) # 调用fn函数获取\n\t0x0029 00041 (demo.go:8)\tMOVQ\t(SP), DX # 保存返回的函数值指针到DX，这里的DX是关键\n\t0x002d 00045 (demo.go:8)\tMOVQ\tDX, \"\".f+8(SP) # 把DX的值赋给局部变量f \n\t0x0032 00050 (demo.go:9)\tMOVQ\t(DX), AX # 从上面funcval结构可知，(DX)为实际函数地址，也就是下面的\"\".fn.func1\n\t0x0035 00053 (demo.go:9)\tCALL\tAX # 调用实际的函数\n\t0x0040 00064 (demo.go:10)\tRET\n\n\"\".fn STEXT size=136 args=0x8 locals=0x28\n\t0x0000 00000 (demo.go:12)\tTEXT\t\"\".fn(SB), $40-8\n\t0x0036 00054 (demo.go:14)\tLEAQ\ttype.noalg.struct { F uintptr; \"\".a int }(SB), AX # 这里表示实际funcval的类型\n\t0x003d 00061 (demo.go:14)\tMOVQ\tAX, (SP)\n\t0x0041 00065 (demo.go:14)\tCALL\truntime.newobject(SB) # new一个funcval\n\t0x0046 00070 (demo.go:14)\tMOVQ\t8(SP), AX # 返回值\n\t0x0050 00080 (demo.go:14)\tLEAQ\t\"\".fn.func1(SB), CX # 取实际函数地址\n\t0x0057 00087 (demo.go:14)\tMOVQ\tCX, (AX) # 保存实际地址\n\t0x0061 00097 (demo.go:14)\tMOVQ\t\"\".a+16(SP), CX # 保存变量a到funcval\n\t0x0066 00102 (demo.go:14)\tMOVQ\tCX, 8(AX) \n\t0x006f 00111 (demo.go:14)\tMOVQ\tAX, \"\".~r0+48(SP) # 设置返回值\n\t0x007d 00125 (demo.go:14)\tRET\n\n\"\".fn.func1 STEXT size=258 args=0x0 locals=0x88\n\t0x0000 00000 (demo.go:14)\tTEXT\t\"\".fn.func1(SB), NEEDCTXT, $136-0\n\t0x0036 00054 (demo.go:14)\tMOVQ\t8(DX), AX\t# [DX+8]实际上存储的就是闭包引用外部的变量a\n\t0x003a 00058 (demo.go:14)\tMOVQ\tAX, \"\".a+48(SP) # 将AX赋值给变量a\n\t0x003f 00063 (demo.go:15)\tMOVQ\tAX, \"\"..autotmp_2+56(SP)\n\t0x0056 00086 (demo.go:15)\tLEAQ\ttype.int(SB), AX # fmt.Println函数实际接收的是[]interface{}，这里需要先将a转换成interface{}类型\n\t0x005d 00093 (demo.go:15)\tMOVQ\tAX, (SP)\n\t0x0061 00097 (demo.go:15)\tMOVQ\t\"\"..autotmp_2+56(SP), AX\n\t0x0066 00102 (demo.go:15)\tMOVQ\tAX, 8(SP)\n\t0x006b 00107 (demo.go:15)\tCALL\truntime.convT2E64(SB)\n```\n\n从上面我们可以看到，`go`的闭包是通过`funcval`携带额外的上下文信息来实现的。\n\n当创建闭包函数时，将被闭包捕获的变量的地址保存到`funcval`，当调用闭包函数时，会将`funcval`的地址保存到`DX`寄存器，执行闭包函数时，可以通过`DX`寄存器来访问这些变量。\n\n\n\n### 实现猴子补丁\n\n现在，我们要在`go`中实现猴子补丁，所想要实现的效果是：\n\n```go\nfunc a() {\n\tfmt.Println(\"run a\")\n}\nfunc b() {\n\tfmt.Println(\"run b\")\n}\n\nfunc main() {\n\ta() // run a\n\treplace(a, b)\n\ta() // run b\n}\n```\n\n我们要在`replace`方法中，将对函数`a`的调用替换成对函数`b`的调用。\n\n具体实现：\n\n```go\nfunc replace(a, b func()) {\n\treplaceFunction(**(**uintptr)(unsafe.Pointer(&a)), *(*uintptr)(unsafe.Pointer(&b)))\n}\n\n// from is a pointer to the actual function\n// to is a pointer to a go funcvalue\nfunc replaceFunction(from, to uintptr) {\n    // demo只支持64bit\n\tif unsafe.Sizeof(uintptr(1)) != 8 {\n\t\tpanic(\"only support amd64\")\n\t}\n    // jmpToFunctionValue生成跳转到to代表的函数的机器码\n\tjumpData := jmpToFunctionValue(to)\n    // 使用生成的机器码替换from函数\n\tcopyToLocation(from, jumpData)\n\treturn\n}\n\n// movabs rdx,to # to是一个*funcval，需要将其存储到DX寄存器，rdx是64bit的DX寄存器\n// jmp QWORD PTR [rdx] # 跳转到to对应的实际函数的开始处执行\nfunc jmpToFunctionValue(to uintptr) []byte {\n\treturn []byte{\n\t\t0x48, 0xBA,\n\t\tbyte(to),\n\t\tbyte(to >> 8),\n\t\tbyte(to >> 16),\n\t\tbyte(to >> 24),\n\t\tbyte(to >> 32),\n\t\tbyte(to >> 40),\n\t\tbyte(to >> 48),\n\t\tbyte(to >> 56), // movabs rdx,to\n\t\t0xFF, 0x22,     // jmp QWORD PTR [rdx]\n\t}\n}\n\n// 内存替换，因为code所在的代码段默认是只读的，因此需要使用系统调用mprotect将其更改为可写的\nfunc copyToLocation(location uintptr, data []byte) {\n\tf := rawMemoryAccess(location, len(data))\n\tmprotectCrossPage(location, len(data), syscall.PROT_READ|syscall.PROT_WRITE|syscall.PROT_EXEC)\n\tcopy(f, data[:])\n\tmprotectCrossPage(location, len(data), syscall.PROT_READ|syscall.PROT_EXEC)\n}\n\n// 将指定内存地址转换成一个slice\nfunc rawMemoryAccess(p uintptr, length int) []byte {\n\treturn *(*[]byte)(unsafe.Pointer(&reflect.SliceHeader{\n\t\tData: p,\n\t\tLen:  length,\n\t\tCap:  length,\n\t}))\n}\n\n// 使用系统调用mprotect修改指定内存的访问权限\nfunc mprotectCrossPage(addr uintptr, length int, prot int) {\n\tpageSize := syscall.Getpagesize()\n\tfor p := pageStart(addr); p < addr+uintptr(length); p += uintptr(pageSize) {\n\t\tpage := rawMemoryAccess(p, pageSize)\n\t\terr := syscall.Mprotect(page, prot)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t}\n}\n\n// 内存页对齐\nfunc pageStart(ptr uintptr) uintptr {\n\treturn ptr & ^(uintptr(syscall.Getpagesize() - 1))\n}\n```\n\n当执行`replace(a,b)`时，会动态将函数`a`的指令替换成`movabs rdx,to; jmp QWORD PTR [rdx]`\n\n之后调用函数`a`时，会执行`call`指令，这时候会把传递给函数`a`的参数保存到栈上，并且将返回地址保存到指定的寄存器`RA`中；\n\n因为函数`a`被替换成上诉两条指令，因此会跳转到函数`b`执行，这时候函数`b`可以直接使用栈上的参数（这就要求两个函数要有相同的函数签名）；因为`morestack`操作是在函数开始执行的时候进行检查的，因此不会有栈溢出的问题。\n\n当函数`b`执行完成时，会执行`ret`指令，这时候会把返回值保存到栈上，同时将`RA`中的返回地址弹出到`PC`寄存器中；\n\n对于函数调用者来说，整个过程是透明的。\n\n\n\n### refer\n\n[monkey patching in Go](https://bou.ke/blog/monkey-patching-in-go/)\n\n[bouk/monkey](https://github.com/bouk/monkey)","tags":["go"]},{"title":"net/rpc分析","url":"/2019/02/28/net-rpc分析/","content":"\n### rpc\n\n`golang`本身提供了`net/rpc`标准库，用于提供`rpc`服务。\n\n`rpc`通过将网络传输和数据序列化/反序列化屏蔽在接口背后，提供一种简洁的调用接口，已达到调用远程服务方法在执行本地方法一样。\n\n### server \n\n##### service\n\n`service`代表每个注册的服务\n\n```go\ntype methodType struct {\n\tsync.Mutex \t\t\t\t  // protects counters\n\tmethod     reflect.Method // 方法信息\n\tArgType    reflect.Type   // 第一个参数类型\n\tReplyType  reflect.Type   // 第二个参数类型，该参数用来返回结果\n\tnumCalls   uint           // 统计调用次数\n}\n\ntype service struct {\n\tname   string                 // 服务名\n\trcvr   reflect.Value          // 服务对象的值\n\ttyp    reflect.Type           // 服务对象的类型\n\tmethod map[string]*methodType // 该服务对外提供的方法\n}\n```\n\n##### server\n\n`server`代表一个`rpc server`\n\n```go\ntype Server struct {\n\tserviceMap sync.Map     // 注册的服务：map[string]*service\n\treqLock    sync.Mutex   // protects freeReq\n\tfreeReq    *Request     // 缓存Request列表，避免每次请求都要重新创建一个\n\trespLock   sync.Mutex   // protects freeResp\n\tfreeResp   *Response\n}\n```\n\n##### Request & Response\n\n```go \n// Request is a header written before every RPC call. It is used internally\n// but documented here as an aid to debugging, such as when analyzing\n// network traffic.\ntype Request struct {\n\tServiceMethod string   // format: \"Service.Method\"\n\tSeq           uint64   // 请求的Seq，客户端会对请求进行编号，用于区分不同的请求\n\tnext          *Request // for free list in Server\n}\n\n// Response is a header written before every RPC return. It is used internally\n// but documented here as an aid to debugging, such as when analyzing\n// network traffic.\ntype Response struct {\n\tServiceMethod string    // echoes that of the Request\n\tSeq           uint64    // echoes that of the request\n\tError         string    // error, if any.\n\tnext          *Response // for free list in Server\n}\n```\n\n##### Register\n\n```go\nfunc (server *Server) Register(rcvr interface{}) error {\n\t// 使用反射名作为服务名称\n    return server.register(rcvr, \"\", false)\n}\n\nfunc (server *Server) RegisterName(name string, rcvr interface{}) error {\n    // 自定义服务名称\n   return server.register(rcvr, name, true)\n}\n\nfunc (server *Server) register(rcvr interface{}, name string, useName bool) error {\n   s := new(service) \n   s.typ = reflect.TypeOf(rcvr)   // 设置类型\n   s.rcvr = reflect.ValueOf(rcvr) // 设置值\n   // 默认取类型名\n   sname := reflect.Indirect(s.rcvr).Type().Name()\n   if useName { // 如果需要使用自定义名称\n      sname = name\n   }\n   if sname == \"\" {\n      s := \"rpc.Register: no service name for type \" + s.typ.String()\n      log.Print(s)\n      return errors.New(s)\n   }\n    // 如果该service不是导出类型，保错\n   if !isExported(sname) && !useName {\n      s := \"rpc.Register: type \" + sname + \" is not exported\"\n      log.Print(s)\n      return errors.New(s)\n   }\n   s.name = sname\n\n   // 存找该services用于提供对外服务的方法\n   s.method = suitableMethods(s.typ, true)\n\t// 方法数必须大于0\n   if len(s.method) == 0 {\n      str := \"\"\n\n      // To help the user, see if a pointer receiver would work.\n      method := suitableMethods(reflect.PtrTo(s.typ), false)\n      if len(method) != 0 {\n         str = \"rpc.Register: type \" + sname + \" has no exported methods of suitable type (hint: pass a pointer to value of that type)\"\n      } else {\n         str = \"rpc.Register: type \" + sname + \" has no exported methods of suitable type\"\n      }\n      log.Print(str)\n      return errors.New(str)\n   }\n\t// 不允许同一个服务名称重复注册\n   if _, dup := server.serviceMap.LoadOrStore(sname, s); dup {\n      return errors.New(\"rpc: service already defined: \" + sname)\n   }\n   return nil\n}\n```\n\n`suitableMethods`用来查找`service`中需要暴露的方法，实现就是遍历该`service`的所有方法，并返回其中符合条件的方法\n\n```go \nfunc suitableMethods(typ reflect.Type, reportErr bool) map[string]*methodType {\n\tmethods := make(map[string]*methodType)\n    // 遍历方法\n\tfor m := 0; m < typ.NumMethod(); m++ {\n\t\tmethod := typ.Method(m)\n\t\tmtype := method.Type\n\t\tmname := method.Name\n\t\t// Method must be exported.\n        // 如果method是导出的（方法名首字母大写），PkgPath为空\n\t\tif method.PkgPath != \"\" { \n\t\t\tcontinue\n\t\t}\n\t\t// Method needs three ins: receiver, *args, *reply.\n        // 参数个数必须为3，其中第一个参数为service对象\n\t\tif mtype.NumIn() != 3 {\n\t\t\tif reportErr {\n\t\t\t\tlog.Printf(\"rpc.Register: method %q has %d input parameters; needs exactly three\\n\", mname, mtype.NumIn())\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\t// First arg need not be a pointer.\n\t\t// 第二个参数必须是内置类型或者自定义的导出类型，不需要是指针类型\n        argType := mtype.In(1)\n\t\tif !isExportedOrBuiltinType(argType) {\n\t\t\tif reportErr {\n\t\t\t\tlog.Printf(\"rpc.Register: argument type of method %q is not exported: %q\\n\", mname, argType)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\t// Second arg must be a pointer.\n\t\treplyType := mtype.In(2)\n        // 第三个参数必须是指针类型，该参数用来向客户端返回请求结果\n\t\tif replyType.Kind() != reflect.Ptr {\n\t\t\tif reportErr {\n\t\t\t\tlog.Printf(\"rpc.Register: reply type of method %q is not a pointer: %q\\n\", mname, replyType)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\t// Reply type must be exported.\n        // 该参数也必须是内置类型或者导出类型\n\t\tif !isExportedOrBuiltinType(replyType) {\n\t\t\tif reportErr {\n\t\t\t\tlog.Printf(\"rpc.Register: reply type of method %q is not exported: %q\\n\", mname, replyType)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\t// Method needs one out.\n        // 方法必须有且只有一个error类型的返回值\n\t\tif mtype.NumOut() != 1 {\n\t\t\tif reportErr {\n\t\t\t\tlog.Printf(\"rpc.Register: method %q has %d output parameters; needs exactly one\\n\", mname, mtype.NumOut())\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\t// The return type of the method must be error.\n\t\tif returnType := mtype.Out(0); returnType != typeOfError {\n\t\t\tif reportErr {\n\t\t\t\tlog.Printf(\"rpc.Register: return type of method %q is %q, must be error\\n\", mname, returnType)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n        // 符合条件，添加\n\t\tmethods[mname] = &methodType{method: method, ArgType: argType, ReplyType: replyType}\n\t}\n\treturn methods\n}\n```\n\n##### 启动服务\n\n```go \nfunc (server *Server) Accept(lis net.Listener) {\n   for {\n      conn, err := lis.Accept()\n      if err != nil {\n         log.Print(\"rpc.Serve: accept:\", err.Error())\n         return\n      }\n      // 每个客户启用一个goroutine进行处理\n      go server.ServeConn(conn)\n   }\n}\n```\n\n##### 处理请求\n\n```go\nfunc (server *Server) ServeConn(conn io.ReadWriteCloser) {\n\tbuf := bufio.NewWriter(conn)\n    // 默认使用gob编解码\n\tsrv := &gobServerCodec{\n\t\trwc:    conn,\n\t\tdec:    gob.NewDecoder(conn),\n\t\tenc:    gob.NewEncoder(buf),\n\t\tencBuf: buf,\n\t}\n\tserver.ServeCodec(srv)\n}\n\nfunc (server *Server) ServeCodec(codec ServerCodec) {\n\tsending := new(sync.Mutex) // 写response内容时需要加锁\n\twg := new(sync.WaitGroup)\n\tfor {\n        // 从连接中读取请求，主要是通过gobEncoder实现\n\t\tservice, mtype, req, argv, replyv, keepReading, err := server.readRequest(codec)\n\t\tif err != nil {\n\t\t\tif debugLog && err != io.EOF {\n\t\t\t\tlog.Println(\"rpc:\", err)\n\t\t\t}\n\t\t\tif !keepReading {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\t// send a response if we actually managed to read a header.\n\t\t\tif req != nil {\n\t\t\t\tserver.sendResponse(sending, req, invalidRequest, codec, err.Error())\n\t\t\t\tserver.freeRequest(req)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n        // 每个rpc都使用一个goroutine进行处理\n\t\tgo service.call(server, sending, wg, mtype, req, argv, replyv, codec)\n\t}\n\t// 优雅关闭\n\twg.Wait()\n\tcodec.Close()\n}\n```\n\n```go\nfunc (s *service) call(server *Server, sending *sync.Mutex, wg *sync.WaitGroup, mtype *methodType, req *Request, argv, replyv reflect.Value, codec ServerCodec) {\n\tif wg != nil {\n\t\tdefer wg.Done()\n\t}\n\tmtype.Lock()\n\tmtype.numCalls++ // 统计调用次数\n\tmtype.Unlock()\n\tfunction := mtype.method.Func\n\t// 调用具体的请求方法\n\treturnValues := function.Call([]reflect.Value{s.rcvr, argv, replyv})\n\t// The return value for the method is an error.\n\terrInter := returnValues[0].Interface()\n\terrmsg := \"\"\n    // 如果请求方法返回error\n\tif errInter != nil {\n\t\terrmsg = errInter.(error).Error()\n\t}\n    // 写入响应结果，这里主要通过gob.Decoder实现\n\tserver.sendResponse(sending, req, replyv.Interface(), codec, errmsg)\n\t// 释放req\n    server.freeRequest(req)\n}\n```\n\n### client\n\n##### client\n\n```go\ntype Client struct {\n\tcodec ClientCodec // codec\n\n\treqMutex sync.Mutex // protects following\n\trequest  Request\n\n\tmutex    sync.Mutex // protects following\n\tseq      uint64 // 下一次请求的seq\n\tpending  map[uint64]*Call // 正在执行的请求\n\tclosing  bool // user has called Close\n\tshutdown bool // server has told us to stop\n}\n```\n\n##### Call\n\n```go\ntype Call struct {\n   ServiceMethod string      // 调用的远程方法\n   Args          interface{} // 方法第一个参数\n   Reply         interface{} // 第二个参数，用于接收返回值\n   Error         error       // 保存请求的错误信息\n   Done          chan *Call  // 用于通知请求结束\n}\n```\n\n\n\n##### NewClient\n\n```go\nfunc NewClient(conn io.ReadWriteCloser) *Client {\n\tencBuf := bufio.NewWriter(conn)\n\tclient := &gobClientCodec{conn, gob.NewDecoder(conn), gob.NewEncoder(encBuf), encBuf}\n\treturn NewClientWithCodec(client)\n}\n\nfunc NewClientWithCodec(codec ClientCodec) *Client {\n\tclient := &Client{\n\t\tcodec:   codec,\n\t\tpending: make(map[uint64]*Call),\n\t}\n\tgo client.input() // input用来处理server的响应\n\treturn client\n}\n\n```\n\n\n\n##### Call\n\n使用方法`Call`和方法`Go`调用远程方法，其中`Call`会同步等待请求结束，`Go`是异步执行\n\n```go \nfunc (client *Client) Call(serviceMethod string, args interface{}, reply interface{}) error {\n    // Call方法内部也是调用Go，然后等待调用完成后返回\n\tcall := <-client.Go(serviceMethod, args, reply, make(chan *Call, 1)).Done\n\treturn call.Error\n}\n\n// Go方法返回一个channel用来通知调用结束\nfunc (client *Client) Go(serviceMethod string, args interface{}, reply interface{}, done chan *Call) *Call {\n\tcall := new(Call)\n\tcall.ServiceMethod = serviceMethod\n\tcall.Args = args\n\tcall.Reply = reply\n    \n\tif done == nil {\n\t\tdone = make(chan *Call, 10) // buffered.\n\t} else {\n\t\t// If caller passes done != nil, it must arrange that\n\t\t// done has enough buffer for the number of simultaneous\n\t\t// RPCs that will be using that channel. If the channel\n\t\t// is totally unbuffered, it's best not to run at all.\n        if cap(done) == 0 {\n\t\t\tlog.Panic(\"rpc: done channel is unbuffered\")\n\t\t}\n\t}\n\tcall.Done = done\n\tclient.send(call)\n\treturn call\n}\n\n// send执行实际的请求发送\nfunc (client *Client) send(call *Call) {\n\tclient.reqMutex.Lock()\n\tdefer client.reqMutex.Unlock()\n\n\t// Register this call.\n\tclient.mutex.Lock()\n\tif client.shutdown || client.closing {\n\t\tclient.mutex.Unlock()\n\t\tcall.Error = ErrShutdown\n\t\tcall.done()\n\t\treturn\n\t}\n\tseq := client.seq // 获取此次请求seq\n\tclient.seq++ // 计算下一次请求seq\n\tclient.pending[seq] = call // 加入pending列表中\n\tclient.mutex.Unlock() \n\n\t// Encode and send the request.\n\tclient.request.Seq = seq\n\tclient.request.ServiceMethod = call.ServiceMethod\n    // 发送请求\n\terr := client.codec.WriteRequest(&client.request, call.Args)\n\tif err != nil {\n\t\tclient.mutex.Lock()\n\t\tcall = client.pending[seq]\n\t\tdelete(client.pending, seq)\n\t\tclient.mutex.Unlock()\n\t\tif call != nil {\n\t\t\tcall.Error = err\n\t\t\tcall.done()\n\t\t}\n\t}\n}\n```\n\n分析上面的`send`方法，当请求发送出去之后就返回了，那么如何处理请求的响应呢？我们可以看到每次新的请求都会加入到`client.pending`中，那么对应的应该有一个幕后的协程来处理，当收到`server`的响应时，根据`seq`获取对应的`call`，然后通过`call.Done`通知请求完成，\n\n对应的方法为`input`：\n\n```go\nfunc (client *Client) input() {\n\tvar err error\n\tvar response Response\n\tfor err == nil {\n\t\tresponse = Response{}\n        // 读取server的返回结果\n\t\terr = client.codec.ReadResponseHeader(&response)\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n        // 获取这次响应对应的请求的seq\n\t\tseq := response.Seq\n\t\tclient.mutex.Lock()\n        // 获取对应的请求\n\t\tcall := client.pending[seq]\n\t\tdelete(client.pending, seq)\n\t\tclient.mutex.Unlock()\n\t\t// 处理响应结果\n\t\tswitch {\n\t\tcase call == nil:\n\t\t\t// We've got no pending call. That usually means that\n\t\t\t// WriteRequest partially failed, and call was already\n\t\t\t// removed; response is a server telling us about an\n\t\t\t// error reading request body. We should still attempt\n\t\t\t// to read error body, but there's no one to give it to.\n\t\t\terr = client.codec.ReadResponseBody(nil)\n\t\t\tif err != nil {\n\t\t\t\terr = errors.New(\"reading error body: \" + err.Error())\n\t\t\t}\n\t\tcase response.Error != \"\":\n\t\t\t// We've got an error response. Give this to the request;\n\t\t\t// any subsequent requests will get the ReadResponseBody\n\t\t\t// error if there is one.\n\t\t\tcall.Error = ServerError(response.Error)\n\t\t\terr = client.codec.ReadResponseBody(nil)\n\t\t\tif err != nil {\n\t\t\t\terr = errors.New(\"reading error body: \" + err.Error())\n\t\t\t}\n\t\t\tcall.done()\n\t\tdefault:\n\t\t\terr = client.codec.ReadResponseBody(call.Reply)\n\t\t\tif err != nil {\n\t\t\t\tcall.Error = errors.New(\"reading body \" + err.Error())\n\t\t\t}\n\t\t\tcall.done()\n\t\t}\n\t}\n    // 发生错误退出之后，停止所有等待的请求\n\t// Terminate pending calls.\n\tclient.reqMutex.Lock()\n\tclient.mutex.Lock()\n\tclient.shutdown = true\n\tclosing := client.closing\n\tif err == io.EOF {\n\t\tif closing {\n\t\t\terr = ErrShutdown\n\t\t} else {\n\t\t\terr = io.ErrUnexpectedEOF\n\t\t}\n\t}\n    // 停止所有等待的请求\n\tfor _, call := range client.pending {\n\t\tcall.Error = err\n\t\tcall.done()\n\t}\n\tclient.mutex.Unlock()\n\tclient.reqMutex.Unlock()\n\tif debugLog && err != io.EOF && !closing {\n\t\tlog.Println(\"rpc: client protocol error:\", err)\n\t}\n}\n\n// 通知调用结束\nfunc (call *Call) done() {\n\tselect {\n\tcase call.Done <- call:\n\t\t// ok\n\tdefault:\n\t\t// We don't want to block here. It is the caller's responsibility to make\n\t\t// sure the channel has enough buffer space. See comment in Go().\n\t\tif debugLog {\n\t\t\tlog.Println(\"rpc: discarding Call reply due to insufficient Done chan capacity\")\n\t\t}\n\t}\n}\n```\n\n","tags":["go"]},{"title":"slice扩容","url":"/2019/02/26/slice扩容/","content":"\n### slice header \n\ngo中的`slice`声明如下：\n\n```go\ntype slice struct {\n\tarray unsafe.Pointer // 指向底层数组\n\tlen   int // 长度，当前存储的元素个数\n\tcap   int // 容量，底层数组的长度\n}\n```\n\n### grow\n\n`slice`中的`len`表示当前切片中存在的元素个数，而`cap`表示切边底层数组总共可以存放的元素个数，\n\n当我们使用`append`函数为切片追加元素时，如果底层数组剩余容量`cap-len`不足以容纳新的元素，则会发生扩容，具体的扩容逻辑如下：\n\n```go \n// @params et: slice元素类型\n// @params old: 老的slice\n// @params cap: 期待的最小cap值，这里的cap等于(old.len + append的元素个数)\n// @return: 新的slice，并且拷贝老的数据到新的slice\nfunc growslice(et *_type, old slice, cap int) slice {\n    // 如果元素不需要存储空间，比如类型struct{}\n\tif et.size == 0 {\n\t\tif cap < old.cap {\n\t\t\tpanic(errorString(\"growslice: cap out of range\"))\n\t\t}\n        // 直接创建一个新的slice，不需要内存分配\n        // 这里zerobase是一个值为0的uintptr\n\t\treturn slice{unsafe.Pointer(&zerobase), old.len, cap}\n\t}\n\t\n\tnewcap := old.cap\n\tdoublecap := newcap + newcap\n\t// 如果x2不能满足，则使用期待值\n    if cap > doublecap {\n\t\tnewcap = cap\n\t} else {\n        // 否则，如果元素个数小于1024，直接x2\n\t\tif old.len < 1024 {\n\t\t\tnewcap = doublecap\n\t\t} else {\n            // 持续1.25倍直到满足\n\t\t\tfor 0 < newcap && newcap < cap {\n\t\t\t\tnewcap += newcap / 4\n\t\t\t}\n\t\t\t// 如果溢出了，直接使用期待值\n\t\t\tif newcap <= 0 {\n\t\t\t\tnewcap = cap\n\t\t\t}\n\t\t}\n\t}\n\n\tvar overflow bool\n    // 原来元素占用内存大小，现在元素占用内存大小，新的底层数组容量大小\n\tvar lenmem, newlenmem, capmem uintptr\n\t// 计算上面声明的变量值，这里根据et.size进行优化\n\tswitch {\n\tcase et.size == 1: // 不需要乘除法\n\t\tlenmem = uintptr(old.len)\n\t\tnewlenmem = uintptr(cap)\n\t\tcapmem = roundupsize(uintptr(newcap)) \n\t\toverflow = uintptr(newcap) > maxAlloc\n\t\tnewcap = int(capmem)\n\tcase et.size == sys.PtrSize: // 会别优化成移位运算\n\t\tlenmem = uintptr(old.len) * sys.PtrSize\n\t\tnewlenmem = uintptr(cap) * sys.PtrSize\n\t\tcapmem = roundupsize(uintptr(newcap) * sys.PtrSize)\n\t\toverflow = uintptr(newcap) > maxAlloc/sys.PtrSize\n\t\tnewcap = int(capmem / sys.PtrSize)\n\tcase isPowerOfTwo(et.size): // 位运算\n\t\tvar shift uintptr\n\t\tif sys.PtrSize == 8 {\n\t\t\t// Mask shift for better code generation.\n\t\t\tshift = uintptr(sys.Ctz64(uint64(et.size))) & 63\n\t\t} else {\n\t\t\tshift = uintptr(sys.Ctz32(uint32(et.size))) & 31\n\t\t}\n\t\tlenmem = uintptr(old.len) << shift\n\t\tnewlenmem = uintptr(cap) << shift\n\t\tcapmem = roundupsize(uintptr(newcap) << shift)\n\t\toverflow = uintptr(newcap) > (maxAlloc >> shift)\n\t\tnewcap = int(capmem >> shift)\n\tdefault:\n\t\tlenmem = uintptr(old.len) * et.size\n\t\tnewlenmem = uintptr(cap) * et.size\n\t\tcapmem = roundupsize(uintptr(newcap) * et.size)\n\t\toverflow = uintptr(newcap) > maxSliceCap(et.size)\n\t\tnewcap = int(capmem / et.size)\n\t}\n\n\t// The check of overflow (uintptr(newcap) > maxSliceCap(et.size))\n\t// in addition to capmem > _MaxMem is needed to prevent an overflow\n\t// which can be used to trigger a segfault on 32bit architectures\n\t// with this example program:\n\t//\n\t// type T [1<<27 + 1]int64\n\t//\n\t// var d T\n\t// var s []T\n\t//\n\t// func main() {\n\t//   s = append(s, d, d, d, d)\n\t//   print(len(s), \"\\n\")\n\t// }\n\tif cap < old.cap || overflow || capmem > maxAlloc {\n\t\tpanic(errorString(\"growslice: cap out of range\"))\n\t}\n\n\tvar p unsafe.Pointer\n    // 切片元素内不包含指针\n\tif et.kind&kindNoPointers != 0 {\n        // 分配新的底层数组，这里false指示不需要内存清零\n\t\tp = mallocgc(capmem, nil, false)\n        // 不包含指针，内存拷贝\n\t\tmemmove(p, old.array, lenmem)\n\t\t// The append() that calls growslice is going to overwrite from old.len to cap (which will be the new length).\n\t\t// Only clear the part that will not be overwritten.\n        // 新数组中未被使用的内存清零\n\t\tmemclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem)\n\t} else {\n\t\t// Note: can't use rawmem (which avoids zeroing of memory), because then GC can scan uninitialized memory.\n        // 因为元素中包含指针，垃圾收集器需要跟踪指针，因此分配内存时需要在位图中标记指针的位置\n\t\tp = mallocgc(capmem, et, true)\n\t\t// 没有开启写屏障，直接拷贝内存\n        if !writeBarrier.enabled {\n\t\t\tmemmove(p, old.array, lenmem)\n\t\t} else { // gc中，开启了写屏障\n\t\t\tfor i := uintptr(0); i < lenmem; i += et.size {\n\t\t\t\ttypedmemmove(et, add(p, i), add(old.array, i))\n\t\t\t}\n\t\t}\n\t}\n\t// 返回新的slice\n\treturn slice{p, old.len, newcap}\n}\n\n```\n\n\n\n### turn string to []byte\n\n当执行强制类型转换，将`string`类型转换成`[]byte`时，会执行`stringtoslicebyte`：\n\n```go\n// The constant is known to the compiler.\n// There is no fundamental theory behind this number.\nconst tmpStringBufSize = 32\n\ntype tmpBuf [tmpStringBufSize]byte\n// 这里的tmpBuf是一个长度为32的数组\nfunc stringtoslicebyte(buf *tmpBuf, s string) []byte {\n   var b []byte\n   // 如果buf不为空并且字符串长度小于32，直接使用buf\n   if buf != nil && len(s) <= len(buf) { \n      *buf = tmpBuf{} // 清零\n      b = buf[:len(s)]\n   } else {\n      b = rawbyteslice(len(s))\n   }\n   copy(b, s)\n   return b\n}\n```\n\n根据上面的逻辑，当对长度小于32的小字符串进行强制类型转换时，会返回一个`cap`为32的`slice`","tags":["go"]},{"title":"channel源码分析","url":"/2019/01/31/channel源码分析/","content":"\n`channel`是`go`中的一种数据结构，可以用来实现并发控制、协程间通信、...\n\n### 结构定义\n\n`channel`结构在`runtime`中的定义如下：\n\n```go\ntype hchan struct {\n\tqcount   uint           // total data in the queue\n\tdataqsiz uint           // size of the circular queue，缓冲区是一个环形队列\n\tbuf      unsafe.Pointer // points to an array of dataqsiz elements\n\telemsize uint16\n\tclosed   uint32 // 标记该channel是否已经关闭\n\telemtype *_type // element type，该channel内数据元素的类型\n\tsendx    uint   // send index\n\trecvx    uint   // receive index\n\trecvq    waitq  // list of recv waiters，\n\tsendq    waitq  // list of send waiters\n\n\t// lock protects all fields in hchan, as well as several\n\t// fields in sudogs blocked on this channel.\n\t//\n\t// Do not change another G's status while holding this lock\n\t// (in particular, do not ready a G), as this can deadlock\n\t// with stack shrinking.\n\tlock mutex\n}\n\ntype waitq struct {\n\tfirst *sudog // sudog封装了阻塞的g\n\tlast  *sudog\n}\n```\n\n### 创建channel\n\n当我们要创建channel时，需要使用`make`接口，对应的创建逻辑如下：\n\n```go \ntype chantype struct {\n\ttyp  _type\n\telem *_type\n\tdir  uintptr\n}\n// 可以看到这里返回的是*hchan，也说明我们代码中的channel实际上就是一个指针类型 \nfunc makechan(t *chantype, size int) *hchan {\n\telem := t.elem // channel的元素类型\n\n\t// compiler checks this but be safe.\n\tif elem.size >= 1<<16 { \n\t\tthrow(\"makechan: invalid channel element type\")\n\t}\n   \t// 内存对齐校验\n\tif hchanSize%maxAlign != 0 || elem.align > maxAlign {\n\t\tthrow(\"makechan: bad alignment\")\n\t}\n\t// buf size校验\n\tif size < 0 || uintptr(size) > maxSliceCap(elem.size) || uintptr(size)*elem.size > maxAlloc-hchanSize {\n\t\tpanic(plainError(\"makechan: size out of range\"))\n\t}\n\n\t// Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers.\n\t// buf points into the same allocation, elemtype is persistent.\n\t// SudoG's are referenced from their owning thread so they can't be collected.\n\t// TODO(dvyukov,rlh): Rethink when collector can move allocated objects.\n\tvar c *hchan\n\tswitch {\n\tcase size == 0 || elem.size == 0: // 缓冲区为0\n\t\t// Queue or element size is zero.\n\t\tc = (*hchan)(mallocgc(hchanSize, nil, true))\n\t\t// Race detector uses this location for synchronization.\n\t\tc.buf = unsafe.Pointer(c)\n\tcase elem.kind&kindNoPointers != 0: // 不包含指针\n\t\t// Elements do not contain pointers.\n\t\t// Allocate hchan and buf in one call.\n\t\tc = (*hchan)(mallocgc(hchanSize+uintptr(size)*elem.size, nil, true))\n\t\tc.buf = add(unsafe.Pointer(c), hchanSize)\n\tdefault:\n\t\t// Elements contain pointers.\n        // 包含指针，hchan和buf要分开分配内存\n\t\tc = new(hchan)\n\t\tc.buf = mallocgc(uintptr(size)*elem.size, elem, true)\n\t}\n\t// 初始化状态\n\tc.elemsize = uint16(elem.size)\n\tc.elemtype = elem\n\tc.dataqsiz = uint(size)\n\n\tif debugChan {\n\t\tprint(\"makechan: chan=\", c, \"; elemsize=\", elem.size, \"; elemalg=\", elem.alg, \"; dataqsiz=\", size, \"\\n\")\n\t}\n\treturn c\n}\n```\n\n### 写入channel\n\n```go\nfunc chansend1(c *hchan, elem unsafe.Pointer) {\n\tchansend(c, elem, true, getcallerpc())\n}\nfunc chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool {\n\t// 往空channel写入，会导致阻塞\n    if c == nil {\n\t\tif !block {\n\t\t\treturn false\n\t\t}\n\t\tgopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2)\n\t\tthrow(\"unreachable\")\n\t}\n\n\tif debugChan {\n\t\tprint(\"chansend: chan=\", c, \"\\n\")\n\t}\n\n\tif raceenabled {\n\t\tracereadpc(unsafe.Pointer(c), callerpc, funcPC(chansend))\n\t}\n\n\t// Fast path: check for failed non-blocking operation without acquiring the lock.\n\t//\n\t// After observing that the channel is not closed, we observe that the channel is\n\t// not ready for sending. Each of these observations is a single word-sized read\n\t// (first c.closed and second c.recvq.first or c.qcount depending on kind of channel).\n\t// Because a closed channel cannot transition from 'ready for sending' to\n\t// 'not ready for sending', even if the channel is closed between the two observations,\n\t// they imply a moment between the two when the channel was both not yet closed\n\t// and not ready for sending. We behave as if we observed the channel at that moment,\n\t// and report that the send cannot proceed.\n\t//\n\t// It is okay if the reads are reordered here: if we observe that the channel is not\n\t// ready for sending and then observe that it is not closed, that implies that the\n\t// channel wasn't closed during the first observation.\n\tif !block && c.closed == 0 && ((c.dataqsiz == 0 && c.recvq.first == nil) ||\n\t\t(c.dataqsiz > 0 && c.qcount == c.dataqsiz)) {\n\t\treturn false\n\t}\n\n\tvar t0 int64\n\tif blockprofilerate > 0 {\n\t\tt0 = cputicks()\n\t}\n\n\tlock(&c.lock)\n\t// channel已经关闭，panic\n\tif c.closed != 0 {\n\t\tunlock(&c.lock)\n\t\tpanic(plainError(\"send on closed channel\"))\n\t}\n\t// 如果有阻塞在写的g，直接发送给这个g\n\tif sg := c.recvq.dequeue(); sg != nil {\n\t\t// Found a waiting receiver. We pass the value we want to send\n\t\t// directly to the receiver, bypassing the channel buffer (if any).\n\t\tsend(c, sg, ep, func() { unlock(&c.lock) }, 3)\n\t\treturn true\n\t}\n\t// buf channel并且有足够buf，写入buf\n\tif c.qcount < c.dataqsiz {\n\t\t// Space is available in the channel buffer. Enqueue the element to send.\n\t\tqp := chanbuf(c, c.sendx)\n\t\tif raceenabled {\n\t\t\traceacquire(qp)\n\t\t\tracerelease(qp)\n\t\t}\n\t\ttypedmemmove(c.elemtype, qp, ep)\n\t\tc.sendx++\n\t\tif c.sendx == c.dataqsiz {\n\t\t\tc.sendx = 0\n\t\t}\n\t\tc.qcount++\n\t\tunlock(&c.lock)\n\t\treturn true\n\t}\n\n\tif !block {\n\t\tunlock(&c.lock)\n\t\treturn false\n\t}\n\n\t// Block on the channel. Some receiver will complete our operation for us.\n    // 写阻塞\n\tgp := getg()\n\tmysg := acquireSudog()\n\tmysg.releasetime = 0\n\tif t0 != 0 {\n\t\tmysg.releasetime = -1\n\t}\n\t// No stack splits between assigning elem and enqueuing mysg\n\t// on gp.waiting where copystack can find it.\n\tmysg.elem = ep\n\tmysg.waitlink = nil\n\tmysg.g = gp\n\tmysg.isSelect = false\n\tmysg.c = c\n\tgp.waiting = mysg\n\tgp.param = nil\n\tc.sendq.enqueue(mysg)\n    // 挂起\n\tgoparkunlock(&c.lock, waitReasonChanSend, traceEvGoBlockSend, 3)\n\t// 这里是阻塞被唤醒之后的逻辑\n\t// someone woke us up.\n\tif mysg != gp.waiting {\n\t\tthrow(\"G waiting list is corrupted\")\n\t}\n\tgp.waiting = nil\n    // channel被关闭时，会设置gp.param=nil\n\tif gp.param == nil {\n\t\tif c.closed == 0 {\n\t\t\tthrow(\"chansend: spurious wakeup\")\n\t\t}\n        // 该channel已经关闭，panic\n\t\tpanic(plainError(\"send on closed channel\"))\n\t}\n\tgp.param = nil\n\tif mysg.releasetime > 0 {\n\t\tblockevent(mysg.releasetime-t0, 2)\n\t}\n\tmysg.c = nil\n\treleaseSudog(mysg)\n\treturn true\n}\n```\n\n\n\n### 从channel读取\n\n```go \n// 单返回值版本\nfunc chanrecv1(c *hchan, elem unsafe.Pointer) {\n\tchanrecv(c, elem, true)\n}\n\n// 两返回值版本\nfunc chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) {\n\t_, received = chanrecv(c, elem, true)\n\treturn\n}\n\nfunc chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) {\n\t// raceenabled: don't need to check ep, as it is always on the stack\n\t// or is new memory allocated by reflect.\n\n\tif debugChan {\n\t\tprint(\"chanrecv: chan=\", c, \"\\n\")\n\t}\n\t// 从空channel读会导致阻塞\n\tif c == nil {\n\t\tif !block {\n\t\t\treturn\n\t\t}\n\t\tgopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2)\n\t\tthrow(\"unreachable\")\n\t}\n\n\t// Fast path: check for failed non-blocking operation without acquiring the lock.\n\t//\n\t// After observing that the channel is not ready for receiving, we observe that the\n\t// channel is not closed. Each of these observations is a single word-sized read\n\t// (first c.sendq.first or c.qcount, and second c.closed).\n\t// Because a channel cannot be reopened, the later observation of the channel\n\t// being not closed implies that it was also not closed at the moment of the\n\t// first observation. We behave as if we observed the channel at that moment\n\t// and report that the receive cannot proceed.\n\t//\n\t// The order of operations is important here: reversing the operations can lead to\n\t// incorrect behavior when racing with a close.\n\tif !block && (c.dataqsiz == 0 && c.sendq.first == nil ||\n\t\tc.dataqsiz > 0 && atomic.Loaduint(&c.qcount) == 0) &&\n\t\tatomic.Load(&c.closed) == 0 {\n\t\treturn\n\t}\n\n\tvar t0 int64\n\tif blockprofilerate > 0 {\n\t\tt0 = cputicks()\n\t}\n\n\tlock(&c.lock)\n\t// 如果channel已经关闭，并且缓冲区内元素数量为0，则返回空元素\n\tif c.closed != 0 && c.qcount == 0 {\n\t\tif raceenabled {\n\t\t\traceacquire(unsafe.Pointer(c))\n\t\t}\n\t\tunlock(&c.lock)\n\t\tif ep != nil {\n\t\t\ttypedmemclr(c.elemtype, ep)\n\t\t}\n\t\treturn true, false // 第二个返回值false表示没有读取到真正的内容\n\t}\n\t// 如果存在等待写的g，直接从这个g读取\n\tif sg := c.sendq.dequeue(); sg != nil {\n\t\t// Found a waiting sender. If buffer is size 0, receive value\n\t\t// directly from sender. Otherwise, receive from head of queue\n\t\t// and add sender's value to the tail of the queue (both map to\n\t\t// the same buffer slot because the queue is full).\n\t\trecv(c, sg, ep, func() { unlock(&c.lock) }, 3)\n\t\treturn true, true\n\t}\n\t// 如果缓冲区存在元素，则读取缓冲区元素\n    // channel即使已经被关闭，如果缓冲区还有元素，仍可以读取\n\tif c.qcount > 0 {\n\t\t// Receive directly from queue\n\t\tqp := chanbuf(c, c.recvx)\n\t\tif raceenabled {\n\t\t\traceacquire(qp)\n\t\t\tracerelease(qp)\n\t\t}\n\t\tif ep != nil {\n\t\t\ttypedmemmove(c.elemtype, ep, qp)\n\t\t}\n\t\ttypedmemclr(c.elemtype, qp)\n\t\tc.recvx++\n\t\tif c.recvx == c.dataqsiz {\n\t\t\tc.recvx = 0\n\t\t}\n\t\tc.qcount--\n\t\tunlock(&c.lock)\n\t\treturn true, true\n\t}\n\n\tif !block {\n\t\tunlock(&c.lock)\n\t\treturn false, false\n\t}\n\n\t// no sender available: block on this channel.\n    // 阻塞在写操作\n\tgp := getg()\n\tmysg := acquireSudog()\n\tmysg.releasetime = 0\n\tif t0 != 0 {\n\t\tmysg.releasetime = -1\n\t}\n\t// No stack splits between assigning elem and enqueuing mysg\n\t// on gp.waiting where copystack can find it.\n\tmysg.elem = ep\n\tmysg.waitlink = nil\n\tgp.waiting = mysg\n\tmysg.g = gp\n\tmysg.isSelect = false\n\tmysg.c = c\n\tgp.param = nil\n\tc.recvq.enqueue(mysg)\n    // 挂起\n\tgoparkunlock(&c.lock, waitReasonChanReceive, traceEvGoBlockRecv, 3)\n\n    // 这之后是唤醒之后的逻辑\n\t// someone woke us up\n\tif mysg != gp.waiting {\n\t\tthrow(\"G waiting list is corrupted\")\n\t}\n\tgp.waiting = nil\n\tif mysg.releasetime > 0 {\n\t\tblockevent(mysg.releasetime-t0, 2)\n\t}\n\tclosed := gp.param == nil\n\tgp.param = nil\n\tmysg.c = nil\n\treleaseSudog(mysg)\n\t// 如果已经关闭就返回false\n    return true, !closed\n}\n```\n\n\n\n### 关闭channel\n\n```go \n\nfunc closechan(c *hchan) {\n    // 如果关闭nil channel，则panic\n\tif c == nil {\n\t\tpanic(plainError(\"close of nil channel\"))\n\t}\n\n\tlock(&c.lock)\n   \t// 如果channel已经关闭，则panic\n\tif c.closed != 0 {\n\t\tunlock(&c.lock)\n\t\tpanic(plainError(\"close of closed channel\"))\n\t}\n\t// 竞争检测\n\tif raceenabled {\n\t\tcallerpc := getcallerpc()\n\t\tracewritepc(unsafe.Pointer(c), callerpc, funcPC(closechan))\n\t\tracerelease(unsafe.Pointer(c))\n\t}\n\t// 设置关闭标志位\n\tc.closed = 1\n\t// glist用于收集释放的g\n\tvar glist *g\n\n\t// release all readers\n    // 关闭时，要释放所有阻塞在读操作的协程\n\tfor {\n\t\tsg := c.recvq.dequeue()\n\t\tif sg == nil {\n\t\t\tbreak\n\t\t}\n        // 从已关闭的channel中读取的都是空内容，因此这里将元素内存置零\n\t\tif sg.elem != nil {\n\t\t\ttypedmemclr(c.elemtype, sg.elem)\n\t\t\tsg.elem = nil\n\t\t}\n\t\tif sg.releasetime != 0 {\n\t\t\tsg.releasetime = cputicks()\n\t\t}\n        // 从sudog中获取阻塞的g\n\t\tgp := sg.g\n\t\tgp.param = nil\n\t\tif raceenabled {\n\t\t\traceacquireg(gp, unsafe.Pointer(c))\n\t\t}\n        // 链表设置\n\t\tgp.schedlink.set(glist)\n\t\tglist = gp\n\t}\n\n\t// release all writers (they will panic)\n    // 释放等待写的channel\n\tfor {\n\t\tsg := c.sendq.dequeue()\n\t\tif sg == nil {\n\t\t\tbreak\n\t\t}\n\t\tsg.elem = nil\n\t\tif sg.releasetime != 0 {\n\t\t\tsg.releasetime = cputicks()\n\t\t}\n\t\tgp := sg.g\n\t\tgp.param = nil\n\t\tif raceenabled {\n\t\t\traceacquireg(gp, unsafe.Pointer(c))\n\t\t}\n\t\tgp.schedlink.set(glist)\n\t\tglist = gp\n\t}\n\tunlock(&c.lock)\n\n\t// Ready all Gs now that we've dropped the channel lock.\n    // 将上面释放的所有g设置为就绪状态，等待调度\n\tfor glist != nil {\n\t\tgp := glist\n\t\tglist = glist.schedlink.ptr()\n\t\tgp.schedlink = 0\n\t\tgoready(gp, 3)\n\t}\n}\n\n```\n\n","tags":["go","channel"]},{"title":"golang执行command","url":"/2018/12/27/golang执行command/","content":"\n### 在golang中使用cmd\n\n在日常开发中，我们有时候需要在程序中调用系统的其他指令来完成任务，比如通过调用`mysqldump`来执行数据库备份。\n\n`golang`提供了`Cmd`，可以很方便的帮助我们来完成这些内容。\n\n> Package exec runs external commands. It wraps os.StartProcess to make it\n> easier to remap stdin and stdout, connect I/O with pipes, and do other\n> adjustments.\n>\n> Unlike the \"system\" library call from C and other languages, the\n> os/exec package intentionally does not invoke the system shell and\n> does not expand any glob patterns or handle other expansions,\n> pipelines, or redirections typically done by shells. The package\n> behaves more like C's \"exec\" family of functions. To expand glob\n> patterns, either call the shell directly, taking care to escape any\n> dangerous input, or use the path/filepath package's Glob function.\n> To expand environment variables, use package os's ExpandEnv.\n\n### demo\n\n```go\nfunc Backup(p string){\n    cmd := exec.Cmd{}\n\tcmd.Path = \"/usr/bin/mysqldump\"\n    cmd.Args = []string{\"-uuname\", \"-ppasswd\", `db_name`}\n\tfd, err := os.OpenFile(p, os.O_CREATE|os.O_TRUNC|os.O_RDWR, 0666)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer fd.Close()\n\tcmd.Stderr = os.Stderr // 重定向错误输出，可以在控制台中看到子进程的错误信息，方便排查\n\tcmd.Stdout = fd // 重定向cmd的输出，保存到目标文件中\n\terr = cmd.Run() // Run实际上就是Start和Wait的组合，会等待子进程结束才返回，如果需要异步直接使用Start\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n\nfunc Restore(p string) {\n\tcmd := exec.Cmd{}\n\tcmd.Path = \"/usr/bin/mysql\"\n    cmd.Args = []string{\"-uuname\", \"-ppasswd\", \"-Ddb_name\"}\n\tfd, err := os.Open(p)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer fd.Close()\n\tcmd.Stdin = fd // 重定向标准输出为打开文件\n\tcmd.Stdout = os.Stdout\n\tcmd.Stderr = os.Stderr\n\tif err := cmd.Run(); err != nil {\n\t\tpanic(err)\n\t}\n}\n```\n\n如同上面`demo`所示，我们可以通过重定向子进程的`stdin`，`stdout`，`stderr`等\n\n此外，`Cmd`也提供了`Pipe`接口，看一下实现：\n\n```go\nfunc (c *Cmd) StdinPipe() (io.WriteCloser, error) {\n\tif c.Stdin != nil {\n\t\treturn nil, errors.New(\"exec: Stdin already set\")\n\t}\n\tif c.Process != nil {\n\t\treturn nil, errors.New(\"exec: StdinPipe after process started\")\n\t}\n\tpr, pw, err := os.Pipe() // 创建一条管道\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tc.Stdin = pr // 重定向标准输出为读取端\n\tc.closeAfterStart = append(c.closeAfterStart, pr)\n\twc := &closeOnce{File: pw} // 包装管道的写出端\n\tc.closeAfterWait = append(c.closeAfterWait, wc)\n\treturn wc, nil // 返回\n}\n```\n\n管道可以用于两个进程之间单向传输数据，一端用于写入，一端用于读取。\n\n\n\n### Cmd不是Shell\n\n**当我们在控制台执行命令的时候，实际上我们输入的命令会先通过`shell`进行预处理，然后才会被实际的程序执行**\n\n比如，当我们在控制台执行：\n\n```sh\n$ rm -rf *\n```\n\n`shell`会先将`*`替换成所有匹配的文件列表，然后再把`-rf`和待删除的文件列表传给`rm`命令执行\n\n而如果通过`Cmd`进行调用，并不会执行这些预处理。\n\n比如：\n\n```go\nfunc main(){\n    cmd := exec.Cmd{}\n\tcmd.Path = \"/bin/rm\"\n    cmd.Args = []string{\"-r\", \"-f\", \"*\"}\n\tcmd.Stdout = os.Stdout\n\tcmd.Stderr = os.Stderr\n\tif err := cmd.Run(); err != nil {\n\t\tpanic(err)\n\t}\n}\n```\n\n`*`会直接作为参数传递给`rm`，而`rm`本身并不会执行模糊匹配，而是把`*`当做普通的文件名对待，如果当前目录没有存在文件名为`*`的文件，则会报错：`No such file or directory`\n\n解决的方法一：\n\n```go\nfunc main(){\n    cmd := exec.Cmd{}\n\tcmd.Path = \"/bin/bash\"\n    cmd.Args = []string{\"-c\", \"rm -rf *\"} // 使用 bash -c \"rm -rf *\"\n\tcmd.Stdout = os.Stdout\n\tcmd.Stderr = os.Stderr\n\tif err := cmd.Run(); err != nil {\n\t\tpanic(err)\n\t}\n}\n```\n\n解决方法二：\n\n```go\nfunc main(){\n    fs, _ := filepath.Glob(\"*\") // 获取匹配`*`的文件列表\n    cmd := exec.Cmd{}\n\tcmd.Path = \"/bin/rm\"\n    cmd.Args = []string{\"-r\", \"-f\"}\n    cmd.Args = append(cmd.Args, fs...)\n\tcmd.Stdout = os.Stdout\n\tcmd.Stderr = os.Stderr\n\tif err := cmd.Run(); err != nil {\n\t\tpanic(err)\n\t}\n}\n```\n\n","tags":["go"]},{"title":"grpc上手使用","url":"/2018/12/21/grpc上手使用/","content":"\n# grpc上手使用\n\n### 安装\n\n`golang`版本的`grpc`要求`go`版本要在`1.6`以上\n\n##### install gRPC\n\n使用`go get`命令安装`grpc`包\n\n```sh\n$ go get -u google.golang.org/grpc\n```\n\n> 由于某些不可逆原因，上面命令会报连接超时，可以到`github`上将项目`clone`到`$GOPATH/src/google.golang.org/`下\n>\n> ```sh\n> $ cd $GOPATH/src/google.golang.org\n> $ git clone git@github.com:grpc/grpc-go.git grpc\n> ```\n\n##### install Protocol Buffers  v3\n\n`grpc`默认使用`protobuf`作为序列化工具。\n\n1. 打开[Releases](https://github.com/protocolbuffers/protobuf/releases)页面，下载对应平台的`.zip`包`protoc-<version>-<platform>.zip`\n2. 解压\n3. 添加二进制文件路径导`PATH`环境变量\n\n##### install protoc plugin\n\n安装`golang`版本对应的`protobuf`生成工具\n\n```sh\n$ go get -u github.com/golang/protobuf/protoc-gen-go\n$ export PATH=$PATH:$GOPATH/bin\n```\n\n### 运行demo\n\n进入`example`目录\n\n```sh\n$ cd $GOPATH/src/google.golang.org/grpc/examples/helloworld\n```\n\n删除原来的`helloworld.pb.go`文件，并使用`protoc`生成自己生成一个\n\n```sh\n$ rm helloworld/helloworld.pb.go // 删除原来的helloworld.pb.go文件\n$ protoc -I helloworld/ helloworld/helloworld.proto --go_out=plugins=grpc:helloworld // 根据 .proto 文件生成对应的.go文件\n```\n\n编写`grpc`接口时，在`.proto`文件定义接口通信数据格式和接口信息，然后通过`protoc`自动生成对应的`go`代码，大大方便了开发\n\n- `-I PATH`：specify the directory in which to search for imports.  May be specified multiple times; directories will be searched in order.  If not given, the current working directory is used.\n- `--go_out`：指定输出`go`代码\n- `plugins=grpc`：`.proto`中的`service `是`grpc`扩展的功能，需要使用`grpc`插件进行解析才能生成对应的接口定义代码。\n\n运行 `grpc server `和 `grpc client`\n\n```sh\n$ go run greeter_server/main.go // 启动grpc server\n$ go run greeter_client/main.go // 启动grpc client\n```\n\n\n\n### 实践\n\n使用`grpc`开发一个简单的求和服务。\n\n##### 定义.proto文件\n\n在项目下创建`proto/sum.proto`文件：\n\n```protobuf\nsyntax = \"proto3\"; // 使用 proto3\n\n// java生成选项\noption java_multiple_files = true;\noption java_package = \"io.grpc.examples.helloworld\";\noption java_outer_classname = \"HelloWorldProto\";\n\npackage proto; // 生成的go所属的package\n\nmessage SumResp {\n    int64 sum = 1;\n}\n\nmessage SumReq {\n    int64 a = 1;\n    int64 b = 2;\n}\n\n\nservice CalcSvc {\n    // 每个rpc接口声明都必须有且一个参数和一个返回值\n    rpc Sum(SumReq) returns (SumResp) {}\n}\n```\n\n##### 根据接口描述文件生成源码\n\n进入`proto`目录，执行\n\n```sh\n$ protoc sum.proto --go_out=plugins=grpc:.\n```\n\n可以看到，在本目录下生成`sum.pb.go`文件，且`package`为`proto`\n\n##### 开发服务端接口\n\n首先查看生成的`sum.pb.go`文件，可以看到根据`sum.proto`文件中的`CalcSvc`接口定义生成了对应的接口：\n\n```go\n// CalcSvcServer is the server API for CalcSvc service.\ntype CalcSvcServer interface {\n\t// 每个rpc接口声明都必须有且一个参数和一个返回值\n\tSum(context.Context, *SumReq) (*SumResp, error)\n}\n```\n\n开发服务端接口只要就是根据这些接口定义实现具体的业务逻辑\n\n在项目下创建`service/main.go`：\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/reflection\"\n\t\"grpc-demo/proto\"\n\t\"log\"\n\t\"net\"\n)\n\n// 类型断言\nvar _ proto.CalcSvcServer = new(CalcSvc)\n\ntype CalcSvc struct{}\n\nfunc (CalcSvc) Sum(ctx context.Context, req *proto.SumReq) (resp *proto.SumResp, err error) {\n    // 建议使用GetA，不要直接使用req.A，可能存在req=nil的情况\n\ta := req.GetA() \n\tb := req.GetB()\n\tlog.Println(\"request coming ...\")\n\treturn &proto.SumResp{\n\t\tSum: a + b,\n\t}, err\n}\n\nfunc main() {\n\tlis, err := net.Listen(\"tcp\", \":8888\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n    // 注册服务到gRPC\n\ts := grpc.NewServer()\n\tproto.RegisterCalcSvcServer(s, &CalcSvc{})\n    // 启用Server Reflection，可以使用gRPC CLI去检查services\n    // https://github.com/grpc/grpc-go/blob/master/Documentation/server-reflection-tutorial.md\n\treflection.Register(s)\n    // 启动服务\n\tif err := s.Serve(lis); err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n```\n\n##### 客户端访问\n\n在项目下创建`client/main.go`：\n\n```go \npackage main\n\nimport (\n\t\"context\"\n\t\"google.golang.org/grpc\"\n\t\"grpc-demo/proto\"\n\t\"log\"\n)\n\nfunc main() {\n    // 创建gRPC连接\n    // WithInsecure option 指定不启用认证功能\n\tconn, err := grpc.Dial(\":8888\", grpc.WithInsecure())\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n    // 创建gRPC client\n\tclient := proto.NewCalcSvcClient(conn)\n    // 请求gRPC server\n\tresp, err := client.Sum(context.Background(), &proto.SumReq{\n\t\tA: 5,\n\t\tB: 10,\n\t})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tlog.Printf(\"5 + 10 = %d\", resp.GetSum())\n}\n```\n\n##### 运行\n\n```go \n$ go run service/main.go\n$ go run client/main.go\n```\n\n\n\n### grpc连接复用\n\n首先修改服务端代码，**添加 `1s` 的睡眠时间**，模拟复杂业务处理场景：\n\n```go\nfunc (CalcSvc) Sum(ctx context.Context, req *proto.SumReq) (resp *proto.SumResp, err error) {\n\ta := req.GetA()\n\tb := req.GetB()\n\tlog.Println(\"request coming ...\")\n    // 添加 1s 睡眠，模拟接口执行业务逻辑\n\ttime.Sleep(time.Second)\n\treturn &proto.SumResp{\n\t\tSum: a + b,\n\t}, err\n}\n```\n\n##### http2多路复用\n\n`grpc`底层使用`http2`协议进行通信，因此单条连接支持多路复用\n\n修改客户端代码：\n\n```go\n\nfunc main() {\n\tconn ,err:=grpc.Dial(\":8888\", grpc.WithInsecure())\n\tif err!=nil {\n\t\tlog.Fatal(err)\n\t}\n\tclient :=proto.NewCalcSvcClient(conn)\n\n\twg := sync.WaitGroup{}\n\tbegin := time.Now()\n\tconcurrentNum := 1000\n\twg.Add(concurrentNum)\n    \n\tfor i := 0; i < concurrentNum; i++ {\n\t\tgo func() {\n\t\t\tresp, err := client.Sum(context.Background(), &proto.SumReq{\n\t\t\t\tA: 5,\n\t\t\t\tB: 10,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal(err)\n\t\t\t}\n\t\t\tlog.Printf(\"5 + 10 = %d\", resp.GetSum())\n\t\t\twg.Done()\n\t\t}()\n\t}\n\twg.Wait()\n\tlog.Printf(\"用时：%v\", time.Now().Sub(begin))\n}\n```\n\n在上面代码中，服务端每次都睡眠`1s`，客户端使用单条连接进行通信，**1000个并发请求总共执行时间为`1.1s`左右**\n\n如果是`2000`个请求，平均在`1.2s`左右，`10000`个请求是`2`s左右。\n\n可见`grpc`本身单条连接可用提供的并发效果足以满足大部分业务场景。\n\n**注意：**上面的`1000`个并发请求并不是单条连接可以同时发起`1000`个请求，而是其内部支持类似`pipeline`的机制。\n\n##### 连接池\n\n接下来不使用`http2`的多路复用，采用连接池的方式来创建请求\n\n首先实现一个连接池：\n\n```go\npackage main\n\nimport (\n\t\"google.golang.org/grpc\"\n\t\"sync\"\n\t\"time\"\n)\n\n// 连接池选项\ntype Options struct {\n\tDial        Dialer\n\tMaxConn     int\n\tMaxIdle     int\n\tWaitTimeout time.Duration\n}\n\n// 创建连接\ntype Dialer func() (*grpc.ClientConn, error)\n\ntype Pool struct {\n\tdial    Dialer\n\tmaxConn int // 最大打开连接数\n\tmaxIdle int // 最大空闲连接数\n\n\twaitTimeout time.Duration // 等待连接超时时间\n    // 等待连接时通过connCh来传输可用连接\n\tconnCh      chan *grpc.ClientConn\n\n\tcurConnNum int // 记录当前打开的连接数\n    // 保存空闲连接\n\tfreeConn   []*grpc.ClientConn\n\tsync.Mutex\n}\n\n// 创建连接池\nfunc NewPool(opts Options) *Pool {\n\tif opts.MaxConn <= 0 {\n\t\topts.MaxConn = 10\n\t}\n\tif opts.MaxIdle <= 0 {\n\t\topts.MaxIdle = 5\n\t}\n\tif opts.MaxIdle > opts.MaxConn {\n\t\topts.MaxIdle = opts.MaxIdle\n\t}\n\n\treturn &Pool{\n\t\tdial:        opts.Dial,\n\t\tmaxConn:     opts.MaxConn,\n\t\tmaxIdle:     opts.MaxIdle,\n\t\twaitTimeout: opts.WaitTimeout,\n\t\tconnCh:      make(chan *grpc.ClientConn),\n\t\tfreeConn:    make([]*grpc.ClientConn, 0, opts.MaxIdle),\n\t}\n\n}\n\n// 获取连接\nfunc (p *Pool) Get() (conn *grpc.ClientConn) {\n\tp.Lock()\n\t// 已经到达最大连接数\n\tif p.curConnNum >= p.maxConn {\n        // 如果等待超时时间为0，直接返回\n\t\tif p.waitTimeout == 0 {\n\t\t\tp.Unlock()\n\t\t\treturn\n\t\t}\n\n\t\tvar tm <-chan time.Time\n        // 如果等待超时时间小于0，表示无限等待\n\t\tif p.waitTimeout > 0 {\n\t\t\ttm = time.After(p.waitTimeout)\n\t\t}\n\t\tp.Unlock()\n        // 等待可用连接或者超时\n\t\tselect {\n\t\tcase <-tm:\n\t\tcase conn = <-p.connCh:\n\t\t}\n\t\treturn\n\t}\n\t// 如果存在空闲连接\n\tif ln := len(p.freeConn); ln > 0 {\n\t\tconn = p.freeConn[0]\n\t\tp.freeConn[0] = p.freeConn[ln-1]\n\t\tp.freeConn = p.freeConn[:ln-1]\n\t} else { // 创建新的连接\n\t\tc, err := p.dial()\n\t\tif err != nil {\n\t\t\tconn = nil\n\t\t} else {\n\t\t\tp.curConnNum++\n\t\t\tconn = c\n\t\t}\n\t}\n\tp.Unlock()\n\treturn\n}\n\n// 释放连接\nfunc (p *Pool) Put(conn *grpc.ClientConn) error {\n\tif conn == nil {\n\t\treturn nil\n\t}\n    // 首先判断是否有其他协程在等待连接\n\tselect {\n\tcase p.connCh <- conn:\n\t\treturn nil\n\tdefault:\n\t}\n\tp.Lock()\n\tdefer p.Unlock()\n    // 放回空闲连接\n\tif len(p.freeConn) < p.maxIdle {\n\t\tp.freeConn = append(p.freeConn, conn)\n\t\treturn nil\n\t}\n    // 再次判断是否有等待可用连接\n\tselect {\n\tcase p.connCh <- conn:\n\t\treturn nil\n\tdefault:\n        // 关闭连接\n\t\tp.curConnNum--\n\t\treturn conn.Close()\n\t}\n}\n\n// 统计连接池状态\nfunc (p *Pool) Stat() PoolStat {\n\tp.Lock()\n\tp.Unlock()\n\treturn PoolStat{\n\t\tConnNum:     p.curConnNum,\n\t\tIdleConnNum: len(p.freeConn),\n\t}\n}\n\ntype PoolStat struct {\n\tConnNum     int\n\tIdleConnNum int\n}\n\n```\n\n接下来，使用该连接池进行测试：\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"google.golang.org/grpc\"\n\t\"grpc-demo/proto\"\n\t\"log\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc main() {\n\topts := Options{\n\t\tDial: func() (*grpc.ClientConn, error) {\n\t\t\treturn grpc.Dial(\":8888\", grpc.WithInsecure())\n\t\t},\n\t\tWaitTimeout: time.Second * 10,\n\t\tMaxConn:     100, // 设置最大连接数为100\n\t\tMaxIdle:     50,\n\t}\n\tpool := NewPool(opts)\n\tif pool == nil {\n\t\tpanic(\"nil pool\")\n\t}\n\n\twg := sync.WaitGroup{}\n\tbegin := time.Now()\n\tconcurrentNum := 1000\n\twg.Add(concurrentNum)\n\tfor i := 0; i < concurrentNum; i++ {\n\t\tgo func() {\n\n\t\t\tconn := pool.Get()\n\t\t\tif conn == nil {\n\t\t\t\tpanic(\"nil conn\")\n\t\t\t}\n\t\t\tdefer pool.Put(conn)\n\t\t\tclient := proto.NewCalcSvcClient(conn)\n\n\t\t\tresp, err := client.Sum(context.Background(), &proto.SumReq{\n\t\t\t\tA: 5,\n\t\t\t\tB: 10,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal(err)\n\t\t\t}\n\t\t\tlog.Printf(\"5 + 10 = %d\", resp.GetSum())\n\t\t\twg.Done()\n\t\t}()\n\t}\n\twg.Wait()\n\tlog.Printf(\"用时：%v\", time.Now().Sub(begin))\n\tlog.Println(pool.Stat())\n}\n```\n\n在上面的代码中，每次请求时都从连接池中获取一个连接，请求完成后将其释放。\n\n运行上面代码，**`1000`个并发请求总共需要花费`10.15s`左右**。\n\n\n\n### 负载均衡\n\n这里使用`dns`来进行负载均衡进行演示。\n\n我实验机器上面的本机`IP`是`127.0.0.1`，虚拟机`IP`是`192.168.50.12`\n\n首先，修改系统的`hosts`文件，添加：\n\n```\n192.168.50.12 www.grpc.com\n127.0.0.1 www.grpc.com\n```\n\n然后，同时在本地和虚拟机中启动`grpc server`\n\n最后，修改`grpc client`代码：\n\n```go\nconn, err := grpc.Dial(\"dns:///www.grpc.com:8888\", grpc.WithInsecure(), grpc.WithBalancerName(roundrobin.Name))\nif err != nil {\n\tlog.Fatal(err)\n}\nclient := proto.NewCalcSvcClient(conn)\n```\n\n在创建`grpc`连接的时候，使用`dns:///www.grpc.com:8888`，同时指定负载策略为`roundrobin`。\n\n执行`grpc client`，可用看到**两边的`grpc server`都有打印出请求日志**。\n\n`grpc`提供的负载均衡测试是在**请求级别上进行负载均衡**。\n\n`grpc`会同时为每个`grpc server`创建一条连接；每次要发起一个请求的时候，都会根据负载策略选择一条连接来发起请求。","tags":["go","grpc"]},{"title":"go编译共享库给c调用","url":"/2018/12/19/go编译共享库给c调用/","content":"\n### introduce\n\n使用` golang`开发`httpServer`非常方便，如果我们需要在`c`程序中内嵌`httpServer`，可以考虑使用`go`来开发服务模块，然后编译成共享库供`c`调用\n\n### code by go \n\n##### code\n\n```go\npackage main\n\nimport (\n\t\"net/http\"\n\t\"time\"\n\t\"log\"\n)\n\nimport \"C\" // 需要导入`C`才可以生成`.h`文件\n\n\n// 使用`export`导出函数\n//export ServerRun\nfunc ServerRun(_addr *C.char) int {\n    // 转换c字符串为golang字符串\n    addr :=C.GoString(_addr)\n\tmux := http.NewServeMux()\n\tmux.HandleFunc(\"/\", func(resp http.ResponseWriter, req *http.Request) {\n\t\tresp.Write([]byte{'H', 'i', '!'})\n\t})\n\tif err := http.ListenAndServe(addr, mux); err != nil {\n\t\tlog.Println(err.Error())\n\t\treturn -1\n\t}\n\treturn 0\n}\n\n// 内部函数也可以导出\n//export wait\nfunc wait() {\n\ttime.Sleep(time.Hour * 1)\n}\n\nfunc main() {}\n```\n\n注意点：\n\n- 需要引入`C`包，可以使用`C`包中的`GoString`将`c`的字符串转换为`go`的字符串\n\n- 需要导出的函数，需要使用`//export funcName`标识\n\n- 包内函数也可以导出\n\n- `go`和`c`两者的字符串内存布局不同，如果`go`函数参数声明为`go`的字符串类型，在`c`中相当于一个结构体：\n\n  ```c\n  typedef struct { const char *p; ptrdiff_t n; } _GoString_;\n  typedef _GoString_ GoString;\n  ```\n\n  当要在`c`中调用`go`函数时，需要手动构造字符串，而且还有内存安全的问题。\n\n##### compile\n\n- 动态共享库：运行时动态加载；如果运行时加载失败则报错\n\n  ```sh\n  $ go build -buildmode=c-shared -o libtest.so main.go\n  ```\n\n  编译完成之后将生成`libtest.so`和`libtest.h`文件\n\n- 静态共享库：编译时静态链接到程序中；生成二进制文件较大\n\n  ```sh\n  $ go build -buildmode=c-archive -o test.a main.go\n  ```\n\n  编译完成之后将生成`test.h`和`test.a`文件\n\n\n\n### use in c \n\n##### code \n\n在开始写代码之前，我们要先看一下生成的`test.h`里面的内容：\n\n```c\ntypedef struct { const char *p; ptrdiff_t n; } _GoString_;\ntypedef _GoString_ GoString;\n\ntypedef long long GoInt64;\ntypedef GoInt64 GoInt;\n\nextern GoInt ServerRun(char* p0);\n\nextern void wait();\n```\n\n可以看到，`.h`文件中包含了外部函数`ServerRun`和`wait`的声明\n\n```c\n#include<stdio.h>\n#include \"test.h\"\n\nint main(void){\n\t// 执行 ServerRun\n    if (ServerRun(\":8080\") != 0){\n        printf(\"failed to start server!\");\n        return -1;\n    }\n    return 0;\n}\n```\n\n\n\n##### compile \n\n- 静态共享库\n\n  ```sh\n  $ gcc -pthread -o test main.c test.a \n  ```\n\n  使用静态链接时，需要指定`-pthread`选项 \n\n  > Link with the POSIX threads library.  This option is supported on GNU/Linux targets, most other Unix derivatives, and also on x86 Cygwin and MinGW targets.  On some targets this option also sets flags for the preprocessor, so it should be used consistently for both compilation and linking.\n\n  也可以动态加载`pthread`库\n\n  ```sh\n  $ gcc -lpthread -o test main.c test.a\n  ```\n\n- 动态共享库\n\n  ```sh\n  $ gcc main.c -ltest -L. -I. -o test\n  ```\n\n  - `-l`：声明使用到的动态共享库，比如`libtest.so`，则这里传入`test`\n  - `-L`：在指定路径中查找共享库；也可以将`.so`文件拷贝到默认共享库目录下\n  - `-I`：在指定路径中查找`.h`头部文件\n\n\n\n编译之后生成`test`文件，执行`./test`，然后在访问`http://localhost:8080`可以看到返回了`Hi!`内容。\n\n如果使用动态加载，运行前需要先将`libtest.so`文件拷贝到动态加载库默认的加载路径中，或者将当前路径加到`LD_LIBRARY_PATH `环境变量中。\n","tags":["go"]},{"title":"goland 中获取 goid","url":"/2018/08/18/goland-中获取-goid/","content":"\n### introduce\n\n目前网上有很多获取goroutine id的方法，主要分为两种：\n\n- 通过runtime.Stack方法获取栈的信息，而栈信息以`goroutine {goid}` 开头，再通过字符串处理就可以提取出goid\n- go中通过g来表示goroutine，而在tls中保存了当前执行的g的地址。可以通过汇编获取到g的地址，然后加上goid在g中的偏移量就可以获取到goid的值了\n\n第一种方法实现方便，只要通过简单的字符串处理就可以获取到goid，但是性能开销较大；\n\n第二种方法，需要结合汇编来获取当前执行的g的地址，而且需要获取到goid在g中的偏移量；而不同的版本中g的结构都不一样，因此该方法需要为每个版本都提供一种实现\n\n### code\n\n下面将基于go1.10实现上面两种获取goid的方案。\n\n##### 方法一：\n\n```go\n\tstack := make([]byte, 20) //读取前二十个字节\n\truntime.Stack(stack, false)\n\tgoid,_ :=strconv.Atoi(strings.Split(string(stack),\" \")[1])\n```\n\n在上面的实现中，读取栈的前20个字节，其内容为`goroutine 6 ...`，我们这里只需要关注goid在字符串数组第二的位置，然后通过简单的字符串切割和类型转换就可以获取到goid了\n\n##### 方法二：\n\n因为g的定义在runtime.runtime2.go中，我们需要将其拷贝出来\n\n```go\ntype g struct {\n\tstack       stack\n\tstackguard0 uintptr\n    _defer      uintptr\n\t...\n\tgoid           int64\n\t...\n}\n\ntype stack struct {\n\tlo uintptr\n\thi uintptr\n}\n\ntype gobuf struct {\n\tsp   uintptr\n\tpc   uintptr\n\tg    uintptr\n\tctxt unsafe.Pointer\n\tret  uint64\n\tlr   uintptr\n\tbp   uintptr\n}\n```\n\n拷贝的时候，因为g中还引用了其他类型，也需要一起拷贝出来。这里有个小技巧，因为我们只是需要使用g来计算goid的偏移量，因此如果有的字段是指针类型的，那么可以将其换成`uintptr`类型。比如说`_defer`是`*_defer`类型，那么可以将其换成`uintptr`类型，这样我们就不需要在自己的代码中声明`_defer`结构了。\n\n然后，声明全局变量`offset`\n\n```go\nvar offset =unsafe.Offsetof((*g)(nil).goid)\n```\n\n我们通过`unsafe.Offsetof`方法来计算goid在g中的偏移。\n\n接着，在go文件中声明Goid方法的stub\n\n```go\nfunc Goid()int64\n```\n\n并在goid.s中实现该函数\n\n```assembly\nTEXT ·Goid(SB),NOSPLIT,$0-8\n    MOVQ ·offset(SB),AX\t//获取到全局变量offset\n    MOVQ (TLS),BX\t\t//获取当前g的地址\n    ADDQ BX,AX\t\t\t//计算goid的地址\n    MOVQ (AX),BX\t\t//获取goid的值\n    MOVQ BX,ret+0(FP)\n    RET\n\t//最后的空行必须保留，否则编译报错\n```\n\n在上述实现中，我直接在汇编中计算goid在内存中的地址。还有一种实现是在汇编中获取g的地址，然后将其转换成*g类型并获取goid的值，这样就不需要计算offset的值了，但是在实际测试中，前者的执行速度是后者的两倍。\n\n\n\n以上代码可以在[github](https://github.com/ymcvalu/goid)上查看\n\n\n\n","tags":["go","goid"]},{"title":"go自定义类型的序列化过程","url":"/2018/08/13/go自定义类型的序列化过程/","content":"\n\n\n### 问题引入\n当某个struct存在某个字段为string或者[]byte类型但是实际上保存的内容是json格式的数据时，对其进行json序列化，比如\n```go\ntype Message struct {\n\tFrom string     `json:\"from\"`\n\tTo   string     `json:\"to\"`\n\tData string `json:\"data\"`\n}\n\nfunc main() {\n\tmsg := Message{\n\t\tFrom: \"XiaoMing\",\n\t\tTo:   \"LiGang\",\n\t\tData: `{\"title\":\"test\",\"body\":\"something\"}`,\n\t}\n\tjsonData, err := json.Marshal(msg)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tfmt.Println(string(jsonData))\n}\n```\n在上面的例子中，Data字段是string类型，但是保存的内容是json格式的数据，这个时候，程序输出：\n```json\n{\"from\":\"XiaoMing\",\"to\":\"LiGang\",\"data\":\"{\\\"title\\\":\\\"test\\\",\\\"body\\\":\\\"something\\\"}\"}\n```\n可以看到，序列化之后的data是一个字符串。\n如果Message对应的是数据库中的一张表，而data字段在数据库中是json类型，当我们需要一个接口，查询Message表中的记录返回给客户端。如果直接执行序列化，那么客户端获取到的Data实际上是一个字符串，客户端还需要自行对这个字符串进行json反序列化。\n>这时候我们就会想，有没有什么办法能够在服务端序列化Message时，将data字段序列化成json对象而不是字符串呢？\n\n### 自定义序列化\n因为data字段的值本身就是json类型，为什么不能在序列化时直接使用呢？\n查看json包的官方文档，我们可以发现关于 [自定义序列化](https://godoc.org/encoding/json#ex-package--CustomMarshalJSON)的例子\n当执行json序列化时，如果对应的类型实现了`Marshaler`接口：\n```go\ntype Marshaler interface {\n\tMarshalJSON() ([]byte, error)\n}\n```\n那么就会执行其`MarshalJSON`方法，并将返回的字节数组作为该值的序列化值。\n那么回到上面的例子，我们就很容易实现目标：\n```go\ntype JsonString string\n\nfunc (j JsonString) MarshalJSON() ([]byte, error) {\n\tfmt.Println(\"marshal...\")\n\treturn []byte(j), nil\n}\n\ntype Message struct {\n\tFrom string     `json:\"from\"`\n\tTo   string     `json:\"to\"`\n\tData JsonString `json:\"data\"`\n}\n```\n在上面的代码中基于`string`类型声明了`JsonString`，代表json格式的字符串，并实现了Marshaler接口。因为JsonString代表的就是json字符串，直接将其转换成字节数组返回。\n然后将Message中的Data字段换成JsonString类型。\n再次执行程序，可以看到：\n```json\n{\"from\":\"XiaoMing\",\"to\":\"LiGang\",\"data\":{\"title\":\"test\",\"body\":\"something\"}}\n```\n**Perfect!**","tags":["go"]},{"title":"golang中的defer实现","url":"/2018/04/15/golang中的defer实现/","content":"\n\n\n`defer`是go独有的关键字，可以说是go的一大特色。\n\n被`defer`修饰的函数调用，会在函数返回时被执行，因此常常被用于执行锁或者资源释放等。\n\n在每次获得资源时，都紧接`defer`语句对其进行释放，可以防止在后续的操作中忘记释放资源。\n\n在享受其便捷之后，你有没有想过defer机制是如何实现的呢？\n\n首先编写简单的main函数\n\n```go\nfunc main() {\n\tdefer func() {\n\t\tfmt.Println(\"exit\")\n\t}()\n}\n```\n\n使用`go tool compile -N -S main.go > main.s`命令编译查看输出的汇编代码\n\n```assembly\n\"\".main STEXT size=96 args=0x0 locals=0x18\n\tTEXT\t\"\".main(SB), $24-0\n\t...\n\tMOVL\t$0, (SP)\t;deferproc第一个参数0\n\tLEAQ\t\"\".main.func1·f(SB), AX ;匿名函数被编译成main.func1，保存函数地址到AX\n\tMOVQ\tAX, 8(SP) ;deferproc第二个参数为匿名函数地址\n\tPCDATA\t$0, $0\n\tCALL\truntime.deferproc(SB) ;调用defer函数\n\t...\n\tCALL\truntime.deferreturn(SB) ;返回之前执行deferreturn函数\n\tMOVQ\t16(SP), BP\n\tADDQ\t$24, SP\n\tRET\n\t...\n```\n\n根据输出的汇编代码，可以看到defer语句被替换成了调用`runtime.deferproc`方法，查看具体的实现，而在函数返回时执行`runtime.deferreturn`方法\n\n首先分析`runtime.deferproc`方法\n\n```go\n// Create a new deferred function fn with siz bytes of arguments.\n// The compiler turns a defer statement into a call to this.\n//go:nosplit\n//siz表示fn函数的参数总大小\nfunc deferproc(siz int32, fn *funcval) { // arguments of fn follow fn\n    //deferproc不允许在系统栈执行\n\tif getg().m.curg != getg() {\n\t\t// go code on the system stack can't defer\n\t\tthrow(\"defer on system stack\")\n\t}\n\n\t// the arguments of fn are in a perilous state. The stack map\n\t// for deferproc does not describe them. So we can't let garbage\n\t// collection or stack copying trigger until we've copied them out\n\t// to somewhere safe. The memmove below does that.\n\t// Until the copy completes, we can only call nosplit routines.\n\tsp := getcallersp(unsafe.Pointer(&siz))\n    //fn的参数紧跟在fn之后,因此通过简单的指针运算可以获取fn的参数起始地址\n\targp := uintptr(unsafe.Pointer(&fn)) + unsafe.Sizeof(fn)\n    //获取defer语句的pc\n\tcallerpc := getcallerpc()\n\t//获取一个_defer\n\td := newdefer(siz)\n\tif d._panic != nil {\n\t\tthrow(\"deferproc: d.panic != nil after newdefer\")\n\t}\n\td.fn = fn\n\td.pc = callerpc\n\td.sp = sp\n\tswitch siz {\n\tcase 0:\n\t\t// Do nothing.\n\tcase sys.PtrSize:\n\t\t*(*uintptr)(deferArgs(d)) = *(*uintptr)(unsafe.Pointer(argp))\n\tdefault:\n        //deferArgs:分配_defer时,连同参数存储空间一起分配,参数紧跟_defer之后存储,该函数进行指针运算,返回参数的起始地址：\n        //拷贝参数,因此在执行defer语句语义之前,需要先准备好接收者和参数\n\t\tmemmove(deferArgs(d), unsafe.Pointer(argp), uintptr(siz))\n\t}\n\n\t// deferproc returns 0 normally.\n\t// a deferred func that stops a panic\n\t// makes the deferproc return 1.\n\t// the code the compiler generates always\n\t// checks the return value and jumps to the\n\t// end of the function if deferproc returns != 0.\n\treturn0()\n\t// No code can go here - the C return register has\n\t// been set and must not be clobbered.\n}\n```\n\n具体的逻辑已经很清楚了，这里要说明的是：`runtime.deferproc`接受两个参数，需要延时执行的函数fn的地址以及fn的参数总大小，而fn的参数需要紧跟着分配在`&fn`后面。\n\n在函数中我们看到了`_defer`这个类型，该类型是实现`defer`机制的关键，其声明如下：\n\n```go\n// A _defer holds an entry on the list of deferred calls.\n// If you add a field here, add code to clear it in freedefer.\ntype _defer struct {\n\tsiz     int32\t//参数size\n\tstarted bool\t//是否执行过\n\tsp      uintptr // sp at time of defer\n\tpc      uintptr\n\tfn      *funcval //需要延时执行的函数地址\n\t_panic  *_panic // panic that is running defer\n\tlink    *_defer //每个goroutine中的_defer以链表组织\n}\n```\n\n在`runtime.newdefer`方法中，会获取一个_defer结构，**并将其加入当前goroutine的` _defer`队列头部**。\n\n接着看一下`runtime.deferreturn`方法实现\n\n```go\n// Run a deferred function if there is one.\n// The compiler inserts a call to this at the end of any\n// function which calls defer.\n// If there is a deferred function, this will call runtime·jmpdefer,\n// which will jump to the deferred function such that it appears\n// to have been called by the caller of deferreturn at the point\n// just before deferreturn was called. The effect is that deferreturn\n// is called again and again until there are no more deferred functions.\n// Cannot split the stack because we reuse the caller's frame to\n// call the deferred function.\n\n// The single argument isn't actually used - it just has its address\n// taken so it can be matched against pending defers.\n//go:nosplit\nfunc deferreturn(arg0 uintptr) { //这边的arg0只是为了获取当前的sp\n\tgp := getg()\n\td := gp._defer\t//获取_defer链表头部\n    //如果没有_defer,则返回,详见上面注释\n\tif d == nil {\n\t\treturn\n\t}\n    //确保sp前后一致\n\tsp := getcallersp(unsafe.Pointer(&arg0))\n\tif d.sp != sp {\n\t\treturn\n\t}\n\n\t// Moving arguments around.\n\t//\n\t// Everything called after this point must be recursively\n\t// nosplit because the garbage collector won't know the form\n\t// of the arguments until the jmpdefer can flip the PC over to\n\t// fn.\n    //拷贝参数到sp中\n\tswitch d.siz {\n\tcase 0:\n\t\t// Do nothing.\n\tcase sys.PtrSize:\n\t\t*(*uintptr)(unsafe.Pointer(&arg0)) = *(*uintptr)(deferArgs(d))\n\tdefault:\n\t\tmemmove(unsafe.Pointer(&arg0), deferArgs(d), uintptr(d.siz))\n\t}\n\tfn := d.fn\n\td.fn = nil\n\tgp._defer = d.link //从链表中移除\n\tfreedefer(d) //释放当前_defer\n    //call runtime·jmpdefer,\n    // which will jump to the deferred function such that it appears\n    // to have been called by the caller of deferreturn at the point\n    // just before deferreturn was called. The effect is that deferreturn\n    // is called again and again until there are no more deferred fns.\n    //执行fn,并修改pc为 `CALL\truntime.deferreturn(SB)`,下一条指令再次进入该函数,如果gp.defer为nil或者sp不一致,则返回,否则继续执行defer\n    //每次添加defer时,总是添加到head,处理时则是从head开始处理,因此defer的处理顺序是FILO\n\tjmpdefer(fn, uintptr(unsafe.Pointer(&arg0)))\n}\n```\n\n至此，defer语句的运行机制分析完成了，主要理了大概的执行流程，其中还有一些细节由于篇幅有限并没有细说，可以自行分析。\n\ngo中还有一个比较独特的地方，如果程序发生异常，会保证先执行所有defer声明的延时函数，然后才退出程序；而我们可以在延时函数中获取到当前整个堆栈的信息，比如说：\n\n```\n函数A执行defer语句，调用函数B\n函数B函数B发生panic\n执行函数A的延时函数，这时候是可以获取到函数B的栈帧数据的\n```\n\n按照上面的执行流程，在执行函数A的延时函数时，实际上这时候函数B的栈帧还没有弹出，神奇吧？这是因为执行panic时，就会去遍历当前goroutine的`_defer`链表，并依次执行这些延时函数，而不是返回函数A之后再执行函数A的延时函数。\n\n实际的执行流程是这样的：\n\n```\n函数A执行defer语句，调用函数B\n函数B函数B发生panic\n在panic内部，遍历_defer链表，并依次执行延时函数\n如果有延时函数执行了recover，则在延时函数返回后，直接跳转到_defer.pc，而不会执行后续的延时函数\n```\n\n\n\n最后，`defer`函数虽然方便，但是需要有额外的运行开销，在使用时需要进行取舍，尤其是具有多个参数的时候，会发生多次内存拷贝：\n\n```\nruntime.deferproc执行之前：移动到栈中\nruntime.deferproc执行过程中，拷贝_defer之后\nruntime.deferreturn执行时，移动到栈中\n```\n\n\n\n\n\n\n\n","tags":["go","defer"]},{"title":"go程序启动过程分析","url":"/2018/01/07/go程序启动过程分析/","content":"\n\n\n事实上，编译好的可执⾏⽂件真正执⾏时并⾮我们所写的 main.main 函数，因为编译器\n\n总是会插⼊⼀段引导代码，完成诸如命令⾏参数、运⾏时初始化等⼯作，然后才会进⼊⽤\n\n户逻辑。 \n\n程序的入口因平台而异：\n\n```sh\nrt0_android_arm.s rt0_dragonfly_amd64.s rt0_linux_amd64.s ...\nrt0_darwin_386.s rt0_freebsd_386.s rt0_linux_arm.s ...\nrt0_darwin_amd64.s rt0_freebsd_amd64.s rt0_linux_arm64.s ...\n```\n\nrt0_linux_amd64.s:\n\n```assembly\nTEXT _rt0_amd64_linux(SB),NOSPLIT,$-8\n   LEAQ   8(SP), SI ; argv\n   MOVQ   0(SP), DI ; argc\n   MOVQ   $main(SB), AX\t\t;move address of main to ax\n   JMP    AX\n   \n   TEXT main(SB),NOSPLIT,$-8\n   MOVQ   $runtime·rt0_go(SB), AX\t;跳转到runtime.rt0.go执行\n   JMP    AX\n```\n\nasm_amd64.s:\n\n```assembly\nTEXT runtime·rt0_go(SB),NOSPLIT,$0\n\t// copy arguments forward on an even stack\n\tMOVQ\tDI, AX\t\t// argc\n\tMOVQ\tSI, BX\t\t// argv\n\tSUBQ\t$(4*8+7), SP\t\t// 2args 2auto\n\tANDQ\t$~15, SP\n\tMOVQ\tAX, 16(SP)\n\tMOVQ\tBX, 24(SP)\n   ..\nok:\n\t; set the per-goroutine and per-mach \"registers\"\n\tget_tls(BX)\n\tLEAQ\truntime·g0(SB), CX\t;将g0的地址保存到CX\n\tMOVQ\tCX, g(BX)\t;设置 g(BX)为g0\n\tLEAQ\truntime·m0(SB), AX\t\n\n\t// save m->g0 = g0\n\tMOVQ\tCX, m_g0(AX)\t;设置m.g0\n\t// save m0 to g0->m\n\tMOVQ\tAX, g_m(CX)\t;设置g.m\n    ...\n\t;调用初始化函数\n\tMOVL\t16(SP), AX\t\t// copy argc\n\tMOVL\tAX, 0(SP)\n\tMOVQ\t24(SP), AX\t\t// copy argv\n\tMOVQ\tAX, 8(SP)\n\tCALL\truntime·args(SB)\t\t;\n\tCALL\truntime·osinit(SB)\t\t;\n\tCALL\truntime·schedinit(SB)\t;\n\n\t// create a new goroutine to start program\n\tMOVQ\t$runtime·mainPC(SB), AX\t\t// entry\n\tPUSHQ\tAX\n\tPUSHQ\t$0\t\t\t// arg size\n\t;创建一个新的goroutine并加入到等待队列，该goroutine执行runtime.mainPC所指向的函数\n\tCALL\truntime·newproc(SB)\n\tPOPQ\tAX\n\tPOPQ\tAX\n\n\t;该函数内部会调用调度程序，从而调度到刚刚创建的goroutine执行\n\tCALL\truntime·mstart(SB)\n\n\tMOVL\t$0xf1, 0xf1  // crash\n\tRET\n\n;声明全局的变量mainPC为runtime.main函数的地址，该变量为read only\nDATA\truntime·mainPC+0(SB)/8,$runtime·main(SB)\t\nGLOBL\truntime·mainPC(SB),RODATA,$8\n```\n\n\n\nruntime1.go:\n\n```go\nfunc args(c int32, v **byte) {\n\targc = c\n\targv = v\n\tsysargs(c, v)\n}\nfunc sysargs(argc int32, argv **byte) {\n}\n```\n\nos_windows.go:\n\n```go\nfunc osinit() {\n    ...\n\tncpu = getproccount()\t//获取cpu核数\n    ...\n}\n```\n\n\n\nproc.go:\n```go\n    // The bootstrap sequence is:\n    //\n    //\tcall osinit\n    //\tcall schedinit\n    //\tmake & queue new G\n    //\tcall runtime·mstart\n    //\n    // The new G calls runtime·main.\n    func schedinit() {\n    \t// raceinit must be the first call to race detector.\n    \t// In particular, it must be done before mallocinit below calls racemapshadow.\n    \t_g_ := getg()\t//获取的是g0\n    \tif raceenabled {\n    \t\t_g_.racectx, raceprocctx0 = raceinit()\n    \t}\n    \t//最大系统线程数量限制\n    \tsched.maxmcount = 10000\n    \n    \ttracebackinit()\n    \tmoduledataverify()\n      \t//栈、内存分配器和调度器的相关初始化\n    \tstackinit()\n    \tmallocinit()\n    \tmcommoninit(_g_.m)\n      \n    \talginit()       // maps must not be used before this call\n    \tmodulesinit()   // provides activeModules\n    \ttypelinksinit() // uses maps, activeModules\n    \titabsinit()     // uses activeModules\n    \n    \tmsigsave(_g_.m)\n    \tinitSigmask = _g_.m.sigmask\n    \n      \t//处理命令行参数和环境变量\n    \tgoargs()\n    \tgoenvs()\n      \t\n      \t//处理 GODEBUG、GOTRACEBACK 调试相关的环境变量设置\n    \tparsedebugvars()\n      \n      \t//垃圾回收器初始化\n    \tgcinit()\n    \n    \tsched.lastpoll = uint64(nanotime())\n      \t//通过 CPU核心数和GOMAXPROCS环境变量确定P的数量，P用于调度g到m上\n    \tprocs := ncpu\n    \tif n, ok := atoi32(gogetenv(\"GOMAXPROCS\")); ok && n > 0 {\n    \t\tprocs = n\n    \t}\n    \tif procs > _MaxGomaxprocs {\n    \t\tprocs = _MaxGomaxprocs\n    \t}\n    \tif procresize(procs) != nil {\n    \t\tthrow(\"unknown runnable goroutine during bootstrap\")\n    \t}\n    \n    \tif buildVersion == \"\" {\n    \t\t// Condition should never trigger. This code just serves\n    \t\t// to ensure runtime·buildVersion is kept in the resulting binary.\n    \t\tbuildVersion = \"unknown\"\n    \t}\n    }\n```\n\n```go\n    // Called to start an M.\n    //go:nosplit\n    func mstart() {\n    \t....\n    \tmstart1()\n    }\n```\n```go\n    func mstart1() {\n         ...\n      \t//调度goroutine\n    \tschedule()\n    }\n\n```\n```go\n// go程序编译时，会在main包生成init函数，该函数内调用所有依赖的包的init函数，如果同一个包被程序重复引入多次，他的init函数只会执行一次\n// 当编译时，链接器会将main.init链接到main_init\n//go:linkname main_init main.init\nfunc main_init()\n// 编译时，链接器会将用户的main.main函数链接到main_main\n//go:linkname main_main main.main\nfunc main_main()\n\n// The main goroutine.\nfunc main() {\n\tg := getg()\t//当前获取的g是刚刚在rt0_go内创建的goroutine\n\n\t// Racectx of m0->g0 is used only as the parent of the main goroutine.\n\t// It must not be used for anything else.\n\tg.m.g0.racectx = 0\n\n\t// Max stack size is 1 GB on 64-bit, 250 MB on 32-bit.\n\t// Using decimal instead of binary GB and MB because\n\t// they look nicer in the stack overflow failure message.\n  \t//执行栈最大限制：1GB on 64-bit，250MB on 32-bit\n\tif sys.PtrSize == 8 {\t//64-bit下指针长度是8个字节\n\t\tmaxstacksize = 1000000000\n\t} else {\n\t\tmaxstacksize = 250000000\n\t}\n\n\t// Allow newproc to start new Ms.\n\tmainStarted = true\n\n  \t//启动系统后台监控（定期垃圾回收以及并发任务的调度等）\n\tsystemstack(func() {\n\t\tnewm(sysmon, nil)\n\t})\n\n\t// Lock the main goroutine onto this, the main OS thread,\n\t// during initialization. Most programs won't care, but a few\n\t// do require certain calls to be made by the main thread.\n\t// Those can arrange for main.main to run in the main thread\n\t// by calling runtime.LockOSThread during initialization\n\t// to preserve the lock.\n\tlockOSThread()\n\n\tif g.m != &m0 {\n\t\tthrow(\"runtime.main not on m0\")\n\t}\n\n  \t//执行runtime包内的所有初始化函数 init\n\truntime_init() // must be before defer\n\tif nanotime() == 0 {\n\t\tthrow(\"nanotime returning zero\")\n\t}\n\n\t// Defer unlock so that runtime.Goexit during init does the unlock too.\n\tneedUnlock := true\n\tdefer func() {\n\t\tif needUnlock {\n\t\t\tunlockOSThread()\n\t\t}\n\t}()\n\n\t// Record when the world started. Must be after runtime_init\n\t// because nanotime on some platforms depends on startNano.\n\truntimeInitTime = nanotime()\n\n  \t//启动垃圾回收器的后台操作\n\tgcenable()\n\n\tmain_init_done = make(chan bool)\n\n  \t//执行用户包（包括标准库）的初始化函数 init，程序所有的包的init函数都会在这个函数内被全部执行\n    // 因为main_init是在编译时进行链接的，因此这里使用间接调用\n\tfn := main_init // make an indirect call, as the linker doesn't know the address of the main package when laying down the runtime\n\tfn()\n\tclose(main_init_done\n\tneedUnlock = false\n\tunlockOSThread()\n\n  \t//执行用户逻辑入口 main.main 函数\n\tfn = main_main // make an indirect call, as the linker doesn't know the address of the main package when laying down the runtime\n\tfn()\n   ...\n  \t//执行结束，程序正常退出\n\texit(0)\n}\n```\n\n\n### 总结\n\n• 所有 init 函数都在同⼀个 goroutine 内执⾏\n\n• 所有 init 函数结束后才会执⾏ main.main 函数 \n\n### 参考\n\n- 雨痕的 Go 1.5源码剖析","tags":["go"]},{"title":"libtask分析","url":"/2017/12/29/libtask分析/","content":"\n\n\n`libtask` 是一个开源的 `C` 语言协程库。\n\n`C` 语言协程可以通过更改寄存器，切换协程上下文实现协程调度。\n\n更改寄存器可以通过 `C` 语言内联汇编实现，通过汇编代码直接更改寄存器的内容。\n\n也可以使用 `ucontext` 配合 `getContext` 、 `setContext` 、`makeContext` 、`swapContext` 函数来实现。\n\n`ucontext` 结构封装了寄存器信息和栈信息，是协程执行的上下文，而其他四个函数分别用于获取当前执行的上下文，设置当前上下文，创建上下文和交换上下文，这些函数已经封装了对寄存器内容的交换工作。\n\n##### Task\n\n一个Task可以看成是一个需要异步执行的任务，coroutine的抽象描述。\n\n```c\ntypedef struct Context Context;\t\nstruct Context\n{\n\tucontext_t\tuc;\t//ucontext封装了协程执行的上下文信息\n};\nstruct Task\n{\n\tchar\tname[256];\t// offset known to acid\n\tchar\tstate[256];\n\tTask\t*next;\n\tTask\t*prev;\n\tTask\t*allnext;\n\tTask\t*allprev;\n\tContext\tcontext;\t//协程上下文\n\tuvlong\talarmtime;\n\tuint\tid;\n\tuchar\t*stk;\t//协程栈指针\n\tuint\tstksize;\t//栈大小\n\tint\texiting;\n\tint\talltaskslot;\t//在全局task数组内的index\n\tint\tsystem;\n\tint\tready;\n\tvoid\t(*startfn)(void*);\t//Task需要执行的函数\n\tvoid\t*startarg;\t//startfn 的参数\n\tvoid\t*udata;\n};\n```\n\n##### Task创建\n\n```c\nint taskcreate(void (*fn)(void*), void *arg, uint stack){\n\tint id;\n\tTask *t;\n\n\tt = taskalloc(fn, arg, stack);\t//分配task和stack的空间\n\ttaskcount++;\t\n\tid = t->id;\n  //判断数组是否还有足够空间\n\tif(nalltask%64 == 0){\n      //扩展数组\n\t\talltask = realloc(alltask, (nalltask+64)*sizeof(alltask[0]));\n\t\tif(alltask == nil){\n\t\t\tfprint(2, \"out of memory\\n\");\n\t\t\tabort();\n\t\t}\n\t}\n  \t//保存Task在alltask数组内的index\n\tt->alltaskslot = nalltask;\n\talltask[nalltask++] = t;\t//保存task到alltask数组\n\ttaskready(t);\t//设置为ready，可以被调度执行\n\treturn id;\n}\n\n//taskalloc分配task和stack的空间\nstatic Task* taskalloc(void (*fn)(void*), void *arg, uint stack){\n\tTask *t;\n\tsigset_t zero;\n\tuint x, y;\n\tulong z;\n\n\t/* allocate the task and stack together */\n\tt = malloc(sizeof *t+stack);\t//分配内存，stack紧跟在task之后\n\tif(t == nil){\n\t\tfprint(2, \"taskalloc malloc: %r\\n\");\n\t\tabort();\n\t}\n  \t//清除task的内存\n\tmemset(t, 0, sizeof *t);\n\tt->stk = (uchar*)(t+1);\t//设置stack指针，stack紧跟task之后，t+1指针偏移一个Task大小\n\tt->stksize = stack;\t//设置stack大小\n\tt->id = ++taskidgen;\t//设置id\n\tt->startfn = fn;\t//设置任务需要执行的函数\n\tt->startarg = arg;\t//startfn的参数\n\n\t/* do a reasonable initialization */\n\tmemset(&t->context.uc, 0, sizeof t->context.uc);\n\tsigemptyset(&zero);\n\tsigprocmask(SIG_BLOCK, &zero, &t->context.uc.uc_sigmask);\n\n\t/* must initialize with current context */\n\tif(getcontext(&t->context.uc) < 0){\t//获取当前ucontext，并保存到t->context.uc\n\t\tfprint(2, \"getcontext: %r\\n\");\n\t\tabort();\n\t}\n\n\t/* call makecontext to do the real work. */\n\t/* leave a few words open on both ends */\n  \t//设置栈顶指针和栈大小，两端都保留一点空间\n\tt->context.uc.uc_stack.ss_sp = t->stk+8;\t\n\tt->context.uc.uc_stack.ss_size = t->stksize-64;\n#if defined(__sun__) && !defined(__MAKECONTEXT_V2_SOURCE)\t\t/* sigh */\n#warning \"doing sun thing\"\n\t/* can avoid this with __MAKECONTEXT_V2_SOURCE but only on SunOS 5.9 */\n\tt->context.uc.uc_stack.ss_sp = \n\t\t(char*)t->context.uc.uc_stack.ss_sp\n\t\t+t->context.uc.uc_stack.ss_size;\n#endif\n\t/*\n\t * All this magic is because you have to pass makecontext a\n\t * function that takes some number of word-sized variables,\n\t * and on 64-bit machines pointers are bigger than words.\n\t */\n//print(\"make %p\\n\", t);\n  //计算startfn的参数:y,x\n  /**\n  taskstart的参数是uint，即32位，而指针如果是64位，则需要将指针的高32位和低32位分离，分别传递\n  将指针分离为高32位(x)和低32位(y)，在taskstart内再通过两个参数合成task指针\n  该方法可以同时适用于32位和64位的编译器\n  **/\n\tz = (ulong)t;\n\ty = z;\n\tz >>= 16;\t/* hide undefined 32-bit shift from 32-bit compilers */\n\tx = z>>16;\n  //这里传入的是taskstart函数，在该函数内执调用t->startfn，并传入t->startarg\n\tmakecontext(&t->context.uc, (void(*)())taskstart, 2, y, x);\n\n\treturn t;\n}\n\n/**\n初始化uc_context，set the context of coroutine\n**/\n#ifdef NEEDAMD64MAKECONTEXT\nvoid\nmakecontext(ucontext_t *ucp, void (*func)(void), int argc, ...)\n{\n\tlong *sp;\n\tva_list va;\t//用于遍历可变长参数的指针\n\n\tmemset(&ucp->uc_mcontext, 0, sizeof ucp->uc_mcontext);\n\tif(argc != 2)\n\t\t*(int*)0 = 0;\t//报错\n\tva_start(va, argc);\t//遍历可变参数\n\t//前6个参数可以使用寄存器（%rdi，%rsi，%rdx，%rcx，%r8，%r9）保存，后面参数入栈\n\t//用于传递函数参数，rdi：第一个参数，rsi：第二个参数；调用func时传入rdi和rsi\n\tucp->uc_mcontext.mc_rdi = va_arg(va, int);\n\tucp->uc_mcontext.mc_rsi = va_arg(va, int);\n\tva_end(va);\n\t/**设置栈指针**/\n\tsp = (long*)ucp->uc_stack.ss_sp+ucp->uc_stack.ss_size/sizeof(long);\t//移动sp指针\n\tsp -= argc;\t\n\tsp = (void*)((uintptr_t)sp - (uintptr_t)sp%16);\t/* 16-align for OS X */ //地址对齐\n\t*--sp = 0;\t/* return address */\n\tucp->uc_mcontext.mc_rip = (long)func;\t//ip，rip存放下一条指令地址\n\tucp->uc_mcontext.mc_rsp = (long)sp;\t//栈顶指针\n}\n#endif\n\nstatic void\ntaskstart(uint y, uint x)\n{\n\tTask *t;\n\tulong z;\n\t// t = (x<<32)|y\n\tz = x<<16;\t/* hide undefined 32-bit shift from 32-bit compilers */\n\tz <<= 16;\n\tz |= y;\n\tt = (Task*)z;\t//获取task地址\n\n//print(\"taskstart %p\\n\", t);\n\tt->startfn(t->startarg);\t//调用startfn\n//print(\"taskexits %p\\n\", t);\n\ttaskexit(0);\t//startfn结束，设置退出标志位\n//print(\"not reacehd\\n\");\n}\n```\n\n### Task调度\n\n```c\ntypedef struct Tasklist Tasklist;\nstruct Tasklist\t/* used internally */\n{\n\tTask\t*head;\n\tTask\t*tail;\n};\n```\n\n```c\nContext\ttaskschedcontext;\t\nTasklist\ttaskrunqueue;\nTask\t*taskrunning;\n\nvoid\nneedstack(int n)\n{\n\tTask *t;\n\n\tt = taskrunning;\n\n\tif((char*)&t <= (char*)t->stk\n\t|| (char*)&t - (char*)t->stk < 256+n){\n\t\tfprint(2, \"task stack overflow: &t=%p tstk=%p n=%d\\n\", &t, t->stk, 256+n);\n\t\tabort();\n\t}\n}\n\nvoid\ntaskswitch(void)\n{\n\tneedstack(0);\n\tcontextswitch(&taskrunning->context, &taskschedcontext);\n}\n\nint\nswapcontext(ucontext_t *oucp, const ucontext_t *ucp)\n{\n\tif(getcontext(oucp) == 0)\t//get the context into *oucp\n\t\tsetcontext(ucp);\t//set the context as *ucp\n\treturn 0;\n}\n\nvoid\ntaskready(Task *t)\n{\n\tt->ready = 1;\n\taddtask(&taskrunqueue, t);\t//加入调度队列\n}\n\nint\ntaskyield(void)\n{\n\tint n;\n\t\n\tn = tasknswitch;\n\ttaskready(taskrunning);\t//将当前task加入等待队列\n\ttaskstate(\"yield\");\n\ttaskswitch();\t//切换\n\treturn tasknswitch - n - 1;\n}\n\nint\nanyready(void)\n{\n\treturn taskrunqueue.head != nil;\t//判断等待队列队首是否为空\n}\n\nvoid\ntaskexit(int val)\n{\n\ttaskexitval = val;\n\ttaskrunning->exiting = 1;\n\ttaskswitch();\t//切换上下文，执行调度程序\n}\n\n\nstatic void\ntaskscheduler(void)\n{\n\tint i;\n\tTask *t;\n\n\ttaskdebug(\"scheduler enter\");\n\tfor(;;){\n\t\tif(taskcount == 0)\n\t\t\texit(taskexitval);\n\t\tt = taskrunqueue.head;\n\t\tif(t == nil){\n\t\t\tfprint(2, \"no runnable tasks! %d tasks stalled\\n\", taskcount);\n\t\t\texit(1);\n\t\t}\n\t\tdeltask(&taskrunqueue, t);\n\t\tt->ready = 0;\n\t\ttaskrunning = t;\t//设置taskrunning\n\t\ttasknswitch++;\n\t\ttaskdebug(\"run %d (%s)\", t->id, t->name);\n      //当前context保存到taskschedcontext，即taskschedcontext为调度上下文\n\t\tcontextswitch(&taskschedcontext, &t->context);\t//交换 task context\n//print(\"back in scheduler\\n\");\n\t\ttaskrunning = nil;\n\t\tif(t->exiting){\t//如果退出\n\t\t\tif(!t->system)\n\t\t\t\ttaskcount--;\n\t\t\ti = t->alltaskslot;\n\t\t\talltask[i] = alltask[--nalltask];\t//替换为全局数组的最后一个task\n\t\t\talltask[i]->alltaskslot = i;\n\t\t\tfree(t);\t//释放task\n\t\t}\n\t}\n}\n\n/*\n * startup\n */\n\nstatic int taskargc;\nstatic char **taskargv;\nint mainstacksize;\n\nstatic void\ntaskmainstart(void *v)\n{\n\ttaskname(\"taskmain\");\n\ttaskmain(taskargc, taskargv);\n}\n\nint\nmain(int argc, char **argv)\n{\n\tstruct sigaction sa, osa;\n\n\tmemset(&sa, 0, sizeof sa);\n\tsa.sa_handler = taskinfo;\n\tsa.sa_flags = SA_RESTART;\n\tsigaction(SIGQUIT, &sa, &osa);\n\n#ifdef SIGINFO\n\tsigaction(SIGINFO, &sa, &osa);\n#endif\n\n\targv0 = argv[0];\n\ttaskargc = argc;\n\ttaskargv = argv;\n\n\tif(mainstacksize == 0)\n\t\tmainstacksize = 256*1024;\n\ttaskcreate(taskmainstart, nil, mainstacksize);\n\ttaskscheduler();\n\tfprint(2, \"taskscheduler returned in main!\\n\");\n\tabort();\n\treturn 0;\n}\n```\n","tags":["libtask"]},{"title":"kotlin函数初级入门","url":"/2017/12/11/kotlin函数初级入门/","content":"\n\n\n### 普通函数声明\n使用 `func` 关键字声明一个函数，像这样\n\n```kotlin\nfun add(a:Int,b:Int):Int{\n    return a+b\n}\n```\n**在`kotlin`中，所有函数的参数都是`val`的，即不可变参数**\n如果函数体只有一行代码，可以简洁点：\n```kotlin\nfun add(a: Int, b: Int): Int = a + b\n```\n更简单点，返回值自动推断：\n```kotlin\nfun add(a: Int, b: Int) = a + b\n```\n###带默认值的函数\n可以在声明函数参数的时候，直接指定默认值，如果调用时没有传入，将使用默认值，带有默认值的参数可以在任何位置\n```kotlin\nfun add(a: Int=1, b: Int) = a + b\n```\n调用的时候，可以使用`参数名=值`的形式给出参数\n```kotlin\nadd(b=1)\n```\n换个位置声明默认值：\n```kotlin\nfun add(a: Int , b: Int=1) = a + b\nfun adds (a:Int,b:Int=1,c:Int)= a+b+c\nfun main(vararg args:String){\n    add(1)    //自动匹配第一个参数\n    adds (1,c=2)    //默认值之后的参数需要显示指出参数名\n}\n```\n函数匹配优先级：\n```kotlin\nfun add(a:Int) = a*a\nfun add(a: Int , b: Int=1) = a + b\nfun main(vararg args:String){\n   println(add(3))  //输出 9 \n}\n```\n当有多个函数匹配时，带默认值参数个数少的优先级越高，不带默认值的优先级最高\n\n### 可变参数\n在`kotlin`中，使用 `vararg` 关键字来标识可变参数\n和`java`一样，多个参数会被封装成数组赋值给a\n\n```kotlin\nfun add(vararg a: Int, b: Int):Int{\n    var sum :Int = 0\n    a.forEach { \n        sum+=it\n    }\n    return sum+b\n}\n```\n和`java`不同的是，在java中我们可以直接将一个数组赋值给可变参数，这有时候会引起混淆，因此在kotlin中，我们需要显示使用运算符`*`将数组解构成元素\n比如我们可以这样调用上面的方法：\n```kotlin\nfun main(vararg args: String) {\n    var arr = IntArray(10) { it }\n    add(*arr, b = 1)\n}\n```\n注意，第二个参数我们需要明确指出他的参数名，否则他会被当作可变参数中的一个值\n\n### 使用lambda\n`lambda`是一种特殊的函数。和传统函数不同的是，他可以被存储，传递，并且可以捕获外部变量形成闭包。\n#####`lambda`的类型\n因为`lambda`本质上还是对象，因此他是有类型的。\n `lambda`的类型格式为：\n\n```kotlin\n(参数列表)->返回值类型\n```\n`lambda`的`body`结构为：\n```kotlin\n{形参列表->\n  语句\n  ...\n  最后一个语句的值为返回值（如果需要返回值）\n}\n```\n比如：\n```kotlin\nval max:(Int,Int)->Int = {a,b -> if (a>b) a else b}\n```\n`max`用于比较两个整数，并返回他们中的最大者。因为这边接收了两个参数，因此我们需要在`lambda`的`body`中显示的为这两个参数指定一个名字，就像我们需要为函数指定形参名。\n上面的例子也可以这样写：\n```kotlin\nval max =  { a:Int,b:Int-> if (a>b) a else b}  as (Int,Int)->Unit\n```\n不过这是比较2b的写法了，使用`as`对`lambda`进行类型转换，然后`max`的类型自动推出，这里我只是想说明`lambda`本质上还是个对象，因此一样可以进行类型转换。\n\n### 高阶函数\n`lambda`可以作为函数的参数或者返回值，举个例子：\n\n```kotlin\nfun <T> forEach(list:List<T>,block:(t:T)->Unit){\n    for (t in list){\n        block(t)\n    }\n}\n\nfun main(vararg args:String){\n    var list = listOf(1,2,3,4,5)\n    forEach(list){\n        println(it)\n    }\n}\n```\n在上面的例子中，我们声明了一个`forEach`的函数，他的功能是遍历一个列表，并对列表中的每个元素调用指定的`lambda`，然后我们在`main`函数中调用它。\n值得注意的是，这里当我们的`lambda`是函数的最后一个参数时，我们可以将其写在`()`外面，当函数参数只有一个`lambda`时，可以直接省略`()`；\n还有第二个要注意的是，我们使用了匿名参数，当`lambda`只有一个参数时，我们可以不用显示的指定一个参数名，而是使用默认的`it`来引用。\n\n### 扩展函数\n在`kotlin`中，我们可以很方便的扩展某个类，为其增加方法：\n\n```kotlin\nfun Int.compareWith(a: Int): Int {\n    return when {\n        this > a -> 1\n        this < a -> -1\n        else -> 0\n    }\n}\n\nfun main(vararg args: String) {\n    println(10.compareWith(4))\n}\n```\n如上所示，声明一个扩展函数的语法很简单，只需要在方法名前面加上`类名.`，在方法中我们可以使用`this`来引用他，但是只能访问`public`的成员。这个`类名`我们使用`receiver`来描述它。\n扩展函数只是`kotlin`中众多语法糖中的一个，他并没有真正的扩展这个类，只是将方法的一个参数提到了方法名前面作为`receiver`：\n```kotlin\nfun Int.compareWith(a:Int):Int\n===>\nfun compareWith(this:Int,a:Int):Int  \n```\n所以调用扩展函数和普通的函数调用没有区别，函数的`receiver`本质上还是这个函数的参数，而不是这个方法的所有者，因此在调用时使用的是静态分派，并不支持多态。\n而且当扩展函数与类的方法冲突时，默认使用的是类的方法。\n\n##### 结合泛型的扩展函数\n\n```kotlin\nfun <T:Any> T?.toStr(){\n    println(this?.toString()?:\"this is a null ref\")\n}\nfun main(vararg args:String){\n    null.toStr()\n}\n```\n正如上面的例子中所看到的，我们可以使用泛型参数作为函数的`receiver`，而且我们使用了`T?`，说明支持`null`\n\n##### 函数参数使用扩展函数\n对刚刚的`forEach`函数稍加改造：\n\n```kotlin\nfun <T> forEach(list:List<T>,block:T.()->Unit){\n    for (t in list){\n       t.block()\n    }\n}\n\nfun main(vararg args:String){\n    var list = listOf(1,2,3,4,5)\n    forEach(list){\n        println(this)\n    }\n}\n```\n注意在声明函数参数时，我们使用了`T.()->Unit`，也就是声明了一个具有`receiver`的`lambda`\n\n ","tags":["kotlin"]},{"title":"使用kotlin自定义生成器","url":"/2017/12/02/使用kotlin自定义生成器/","content":"\n使用kotlin的coroutine机制，可以很容易实现一个generator\n\n```kotlin\nimport java.util.concurrent.atomic.AtomicReference\nimport kotlin.coroutines.experimental.*\n\n\nclass Generater<T : Any> private constructor() {\n    private var mContinuation: AtomicReference<Continuation<Unit>?> = AtomicReference(null)\n    private val values: ThreadLocal<T?> = ThreadLocal()\n    /**\n     * -1:结束\n     *  0:未开始\n     *  1:开始\n     */\n    @Volatile\n    private var status: Int = 0\n\n    companion object {\n        fun <T : Any> build(block: suspend Generater<T>.() -> Unit): Generater<T> {\n            val g = Generater<T>()\n            var c = object : Continuation<Unit> {\n                override val context: CoroutineContext\n                    get() = EmptyCoroutineContext\n\n                override fun resume(value: Unit) {\n                    g.status = -1\n                }\n\n                override fun resumeWithException(exception: Throwable) {\n                    g.status = -1\n                    throw exception\n                }\n            }\n            g.mContinuation.compareAndSet(null, block.createCoroutine(g, c))\n            g.status = 1\n            return g\n        }\n    }\n\n    suspend fun yield(t: T?) {\n        suspendCoroutine<Unit> {\n            values.set(t)\n            mContinuation.compareAndSet(null, it)\n            //Thread.sleep(100)\n        }\n    }\n\n    fun next(): T? {\n        while (true) {\n            if (status == -1) {\n                values.set(null)\n                break\n            }\n          \t//可以提到循环外面\n            if (status == 0) {\n                throw IllegalStateException(\"生成器未启动\")\n            }\n            val c = mContinuation.getAndSet(null)\n            c ?: continue\n\n            synchronized(this) {\n                c.resume(Unit)\n            }\n            break\n        }\n        return values.get()\n    }\n\n}\n```\n\n使用\n\n```kotlin\n\nfun main(vararg args: String) {\n\t//声明生成器\n    var g = Generater.build {\n        yield(0L)\n        var i = 0L\n        var j = 1L\n        while (true) {\n            yield(j)\n            var next = i + j\n            i = j\n            j = next\n        }\n    }\n\t//多线程访问\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n\n    Thread {\n        for (i in 0..2)\n            println(Thread.currentThread().name + \":\" + g.next())\n    }.start()\n}\n```\n\n","tags":["kotlin","coroutine","generator"]},{"title":"使用kotlin协程机制撸一个简易的异步执行库","url":"/2017/11/10/使用kotlin协程机制撸一个简易的异步执行库/","content":"\n\n\n> 由于android限制了只能在UI线程更新视图，而在UI线程中做耗时任务又会导致ANR，因此在平时的开发中，需要将耗时的数据请求工作放到子线程中执行，而视图更新工作放到UI线程中，使用传统的handler或者asyncTask，需要将逻辑分到多个函数内\n\n**使用`kotlin`的协程机制，可以用同步的方式实现异步**\nkotlin的协程机制是基于状态机模型和`C-P-S`风格实现的。\n一个协程通过`resume`启动，当协程内部调用`supended`函数时，协程会被暂停，通过调用 `resume`可以再次启动协程。每次暂停都会修改协程的状态，再次启动协程时，会从新的状态处开始执行。\n\n现在通过kotlin的基础api实现一个简单的异步调用接口，最后的效果如下：\n\n ```\n btn.setOnClickListener {\n            runOnUI {  \n                //执行在主线程，可以做一些初始化操作                         \n                Log.e(\"log\", Thread.currentThread().name)\n                var used = async {               //从工作线程直接返回数据到主线程\n                   //切换到工作线程执行，而且lambda可以直接访问外部变量，构成闭包\n                    Log.e(\"log\", Thread.currentThread().name)\n                    var start = System.currentTimeMillis()\n                    Thread.sleep(3000)\n                    System.currentTimeMillis() - start\n                }\n                //继续执行在主线程\n                Log.e(\"log\", Thread.currentThread().name)\n                Toast.makeText(this@MainActivity, \"后台线程用时${used}ms\", Toast.LENGTH_SHORT).show()\n            }\n        }\n ```\n>在后续的内容中，我将在实现的过程中逐步分析kotlin协程机制的基本原理\n\n首先声明一个创建协程的函数：\n```\n//该函数接收一个 suspend类型的lambda\ninline fun runOnUI(noinline block: suspend () -> Unit) {\n    var continuation = object : Continuation<Unit> {\n      //ThreadSwitcher是ContinuationInterceptor的子类，用于在协程resume时切换到主线程执行\n        override val context: CoroutineContext\n            get() = ThreadSwitcher()  \n\n        override inline fun resume(value: Unit) = Unit\n\n        override inline fun resumeWithException(exception: Throwable) = Unit\n    }\n        //使用suspend类型的lambda创建一个协程并启动\n        block.createCoroutine(continuation).resume(Unit)\n}\n```\n`createCoroutine`是官方提供的一个基础api，该函数如下：\n```\npublic fun <T> (suspend () -> T).createCoroutine(\n        completion: Continuation<T>\n): Continuation<Unit> = SafeContinuation(createCoroutineUnchecked(completion), COROUTINE_SUSPENDED)\n```\n可以看到调用了`createCoroutineUnchecked`创建一个`Coroutine`，继续查看该方法：\n```\n@SinceKotlin(\"1.1\")\n@kotlin.jvm.JvmVersion\npublic fun <T> (suspend () -> T).createCoroutineUnchecked(\n        completion: Continuation<T>\n): Continuation<Unit> =\n//这里的this是执行createCoroutine函数的block\n        if (this !is kotlin.coroutines.experimental.jvm.internal.CoroutineImpl)\n            buildContinuationByInvokeCall(completion) {\n                @Suppress(\"UNCHECKED_CAST\")\n                (this as Function1<Continuation<T>, Any?>).invoke(completion)\n            }\n        else\n//编译时，block会被编译成一个CoroutineImpl的子类，所以走这个分支\n            (this.create(completion) as kotlin.coroutines.experimental.jvm.internal.CoroutineImpl).facade\n```\n查看编译之后生成的`block`：\n```\n//查看在Activity#onCreate调用runOnUI处传入的lambda的编译类\nfinal class ymc/demo/com/asyncframe/MainActivity$onCreate$1$1 \n          extends kotlin/coroutines/experimental/jvm/internal/CoroutineImpl   \n          implements kotlin/jvm/functions/Function1  {      //lambda编译类都实现FunctionN函数\n  ...\n}\n```\n可以看到传入`runOnUI`的`lambda`确实被编译成了一个`CoroutineImpl`，这是因为编译器推断出了这个`lambda`是`suspend`类型的。\n\n继续上面的分析，创建协程所涉及到的两个方法中都出现了 `Continuation`这个类，那么这个类是干嘛的呢？\n首先，先看看`completion`，这个是我们调用`createCoroutine`手动传入的，当协程结束时，他的`resume`会被调用，当协程异常结束时，他的`resumeWithException`会被调用。\n再看看`createCoroutineUnchecked`，这个函数也返回了一个`Continuation`，那么这个又是什么呢？\n```\n (this.create(completion) as kotlin.coroutines.experimental.jvm.internal.CoroutineImpl).facade\n```\n可以看到，返回的是`CoroutineImpl`的`facade`，那这个又是什么呢？\n我们进入`CoroutineImpl`，可以看到\n```\nabstract class CoroutineImpl(\n        arity: Int,\n        @JvmField\n        protected var completion: Continuation<Any?>?\n) : Lambda(arity), Continuation<Any?> {     //Coroutine本身是一个Continuation\n\n  override val context: CoroutineContext\n          get() = _context!!\n\n  private var _facade: Continuation<Any?>? = null\n \n  val facade: Continuation<Any?> get() {\n          if (_facade == null) _facade = interceptContinuationIfNeeded(_context!!, this)\n          return _facade!!\n      }\n  ...\n}\n```\n原来这是一个代理属性，接着查看`interceptContinuationIfNeeded`，\n```\ninternal fun <T> interceptContinuationIfNeeded(\n        context: CoroutineContext,\n        continuation: Continuation<T>\n) = context[ContinuationInterceptor]?.interceptContinuation(continuation) ?: continuation\n```\n这个函数从`Coroutine`的上下文中查找`ContinuationInterceptor`，如果有就调用他的`interceptContinuation`对传入的`continuation`进行包装，否则直接返回传入的`continuation`\n\n**`Continuation`**是一个可**继续执行**体的抽象，每个`Coroutine`都是一个可继续执行体，`Continuation`是一个协程对外的接口，启动/恢复协程的`resume`就是在该接口中定义的。\n协程可以是链式连接的，一个协程可以有子协程，子协程持有父协程的引用，当子协程执行时，父协程暂停，子协程结束时，内部通过调用父协程的`resume`返回父协程。\n\n还记得我们前面用到的`ThreadSwitcher`吗，他就是一个`ContinuationInterceptor`\n我们来看看来看`ThreadSwitcher`的实现：\n```\n/**\nInterceptor用于用于拦截并包装Continuation，让我们有机会在协程resume前做一些额外的操作，比如线程切换\n**/\nclass ThreadSwitcher : ContinuationInterceptor, AbstractCoroutineContextElement(ContinuationInterceptor.Key) {\n\n    override fun <T> interceptContinuation(continuation: Continuation<T>): Continuation<T>\n            = object : Continuation<T> by continuation {\n\n        override fun resume(value: T) {\n          //如果在主线程，直接执行\n            if (Looper.getMainLooper() === Looper.myLooper()) {\n                continuation.resume(value)\n            } else {\n            //否则，使用handler机制post到主线程执行\n                postman.post {\n                    resume(value)\n                }\n            }\n        }\n\n        override fun resumeWithException(exception: Throwable) {\n            if (Looper.getMainLooper() === Looper.myLooper()) {\n                continuation.resumeWithException(exception)\n            } else {\n                postman.post {\n                    resumeWithException(exception)\n                }\n            }\n        }\n    }\n}\n```\n从上面的分析中，我们可以想象，我们创建的协程会被`ThreadSwitcher`包装，\n```\nblock.createCoroutine(continuation).resume(Unit)\n```\n`createCoroutine`返回的实际是`ThreadSwitcher`返回的`Continuation`，所以当我们执行`resume`启动协程时，会先切换到主线程执行。\n\n紧接着，我们来实现`async`：\n```\nsuspend inline fun <T> async(crossinline block: () -> T): T\n        = suspendCoroutine {\n//dispatcher是一个对线程池的封装，将任务分发到子线程中\n    dispatcher.dispatch {\n        it.resume(block())\n    }\n}\n```\n使用`suspend`修饰的方法只可以在协程内部调用，而`suspendCoroutine`方法是`kotlin`提供的一个基础api,用于实现暂停协程。\n我们接着来分析`suspendCoroutine`，查看他的实现：\n```\npublic inline suspend fun <T> suspendCoroutine(crossinline block: (Continuation<T>) -> Unit): T =\n        suspendCoroutineOrReturn { c: Continuation<T> ->\n            val safe = SafeContinuation(c)\n            block(safe)\n            safe.getResult()\n        }\n```\n可以看到这个方法接收的`block`是带`Continuation`参数的\n真正实现功能的是`suspendCoroutineOrReturn`，当我们继续跟进时，发现：\n```\npublic inline suspend fun <T> suspendCoroutineOrReturn(crossinline block: (Continuation<T>) -> Any?): T =\n        throw NotImplementedError(\"Implementation is intrinsic\")\n```\nwhat!直接抛出异常了???\n这是因为这是一个特殊的函数，需要编译器特殊处理，他需要将当前协程内的`_facade`属性，包装成`SafeContinuation`，再作为我们传入的`block`的参数，而且这个`_facade`是经过`ContinuationInterceptor`处理过的，也就是说当我们调用`resume`恢复线程时，会先切换到主线程。\n为了验证上面的分析，我们查看`async`编译之后的字节码：\n```\n//可以看到编译之后，我们的async多了一个Continuation类型的参数\n private final static async(Lkotlin/jvm/functions/Function0;Lkotlin/coroutines/experimental/Continuation;)Ljava/lang/Object;\n   L0\n    LINENUMBER 70 L0\n    NOP\n   L1\n    LINENUMBER 77 L1\n    ICONST_0\n    INVOKESTATIC kotlin/jvm/internal/InlineMarker.mark (I)V\n    ALOAD 1  //将第二个参数，也就是Continuation入栈\n//调用CoroutineIntrinsics.normalizeContinuation \n    INVOKESTATIC kotlin/coroutines/experimental/jvm/internal/CoroutineIntrinsics.normalizeContinuation (Lkotlin/coroutines/experimental/Continuation;)Lkotlin/coroutines/experimental/Continuation;  \n//将返回值存到slot3\n    ASTORE 3\n   L2\n    LINENUMBER 78 L2\n//new 一个SafeContinuation\n    NEW kotlin/coroutines/experimental/SafeContinuation\n    DUP  \n  //将刚刚normalizeContinuation返回的continuation传入SafeContinuation的构造函数\n    ALOAD 3\n    INVOKESPECIAL kotlin/coroutines/experimental/SafeContinuation.<init> (Lkotlin/coroutines/experimental/Continuation;)V\n    ASTORE 4\n   L3\n  ...\n```\n我们可以看到，编译之后的字节码已经没有了`suspendCoroutine`和`suspendCoroutineOrReturn`的身影，因为这两个函数都是`inline`函数。\n我们接着来看`CoroutineIntrinsics.normalizeContinuation`的实现：\n```\nfun <T> normalizeContinuation(continuation: Continuation<T>): Continuation<T> =\n        (continuation as? CoroutineImpl)?.facade ?: continuation\n```\n 还记得我们刚刚分析过`facade`这个属性吗？他是对`_facade`的代理，这个函数返回的是经过拦截器处理过的`Continuation`\n根据刚刚的字节码，我们可以发现`suspend`类型的函数，都会**隐式**额外接受一个当前协程的引用，但是又不能在函数中直接访问。\n\n最后，还有两个上文出现过的线程切换处理类，`postman`和`dispatcher`，使用的是单例模式：\n```\nobject postman : Handler(Looper.getMainLooper()) {\n    override fun handleMessage(msg: Message?) {\n        msg?.callback?.run()\n    }\n}\n\nobject dispatcher {\n    val mCachedThreads = Executors.newCachedThreadPool()\n    inline fun dispatch(noinline block: () -> Unit) {\n        mCachedThreads.execute(block)\n    }\n}\n```\n到此，我们实现了一个简易的异步调用库！","tags":["kotlin","coroutine"]},{"title":"自定义classLoader","url":"/2017/10/19/自定义classLoader/","content":"\n\n\n在`java`中，加载一个类到`jvm`虚拟机并为其实例化一个对象是由`ClassLoader`实现的\n有时候，我们需要实现特殊的类加载方式，就需要自己实现一个`ClassLoader `\n`ClassLoader`中有几个比较重要的方法：\n\n- `loadClass`：\n  该方法实现了双亲委托机制，一般不会重写该方法，他的执行步骤是先委托父加载器加载，如果加载不到，在执行自己的`findClass `加载\n- `findClass`：\n  一般实现自己的`ClassLoader`都是重写该方法，如果方法找不着，则抛出一个`ClassNotFound`异常\n- `defineClass`：\n  该方法是`jvm`提供的一个接口，验证一个`class`字节码数组，并为其创建一个`Class`对象\n>下面简单实现一个`ClassLoader`，用于加载指定目录下的`jar`包内的类\n```java\npublic class JarsClassLoader extends ClassLoader {\n    private String basePath;  //jar包存放的目录\n\n    public JarsClassLoader(String path, ClassLoader parentClasss) {\n        super(parentClasss); //指定父加载器\n        basePath = path;\n    }\n\n    @Override\n    protected Class<?> findClass(String name) throws ClassNotFoundException {\n        byte[] classByte = getClassByte(name); //根据类的全路径名去获取一个字节码数组\n        try {\n            return defineClass(name, classByte, 0, classByte.length);//生成一个class\n        } catch (Exception e) {\n            throw new ClassNotFoundException(\"找不到类：\"+name);\n        }\n    }\n    /**\n     * 该方法遍历basePath下的jar包，查找是否存在指定的类文件\n    **/\n    private byte[] getClassByte(String className) {\n        try {\n            File baseDir = new File(basePath); \n            File[] childrens = baseDir.listFiles();\n            for (File child : childrens) {\n                if (!child.getName().endsWith(\".jar\"))\n                    continue;\n                //jar包的全路径名\n                String jarName = basePath + File.separator + child.getName();\n                //创建一个Zip文件对象\n                ZipFile zip = new ZipFile(jarName);\n                //遍历Zip内的所有实体项\n                Enumeration<ZipEntry> zipEntries = (Enumeration<ZipEntry>) zip.entries();\n                ZipEntry zn;\n                while (zipEntries.hasMoreElements()) {\n                    zn = zipEntries.nextElement();\n                    if (!zn.getName().endsWith(\".class\"))\n                        continue;\n                    //处理实体名，将`/`替换成`.`，并去除`.class`后缀\n                    String znName =\n                            zn.getName().replace(\"/\", \".\").replace(\".class\", \"\");\n                    //如果找到指定的类文件\n                    if (znName.equals(className)) {\n                        BufferedInputStream bis = new BufferedInputStream(zip.getInputStream(zn));\n                        ByteArrayOutputStream bos = new ByteArrayOutputStream((int) zn.getSize());\n                        byte[] bytes = new byte[1024];\n                        int cnt;\n                        while ((cnt = (bis.read(bytes, 0, bytes.length))) > 0) {\n                             bos.write(bytes, 0, cnt);\n                        }\n                        return bos.toByteArray();\n                    }\n                }\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } \n        return null;\n    }\n}\n```","tags":["java","classloader"]},{"title":"java与plsql类型映射","url":"/2017/10/18/java与plsql类型映射/","content":"\n\n\n# java类型与数据库类型\n\n### 场景\n\n需要将`JAVA`中的复杂数据类型作为plsql存储过程参数传递\n\n- 将参数转换为`json`格式的字符串：`json`的转换和解析都需要时间，影响效率，而且需要为schema导入一套`json`处理的`object`，不利于迁移\n- 使用`Struct`和`Array`等，将`java`的类型映射成数据库的`object`和`Array`\n\n### java\n\n首先，定义`java bean`：\n\n```java\npublic class TechnicalInfo {\n    //定时/实时\n    public String timingType;\n    //全量/增量\n    public String amountType;\n    //同步/异步\n    public String syncType;\n    //传输逻辑\n    public String transferLogic;\n    //服务地址\n    public String serviceAddress;\n    //技术场景\n    public String techScene;\n   \n}\n\n/**\n * Fields\n**/\nimport java.sql.Connection;\nimport java.util.List;\nimport java.util.LinkedList;\nimport java.lang.reflect.Field;\nimport oracle.sql.STRUCT;\nimport oracle.sql.StructDescriptor;\n\npublic class Fields {\n    //字段名称\n    public String name;\n    //类型\n    public String type;\n    //长度\n    public String length;\n    //位置\n    public String position;\n    //层级\n    public String level;\n    //描述\n    public String desc;\n    //备注\n    public String remarks;\n\n    public STRUCT toStruct(Connection conn) throws Exception{\n     \t//使用oracle的数据库接口，类型描述符，对应一个object类型\n        StructDescriptor sd = new StructDescriptor(\"SERVICE_FIELDS\",conn);\n         \n        List<Object> objs = new LinkedList<>();\n        Field[] fs = Fields.class.getDeclaredFields();\n        for (Field f : fs){\n            if (f.getType() == String.class){\n                objs.add(f.get(this));\n            }\n        }\n        //创建一个对应plsql中object对象的struct\n        //objs内的数据与object中声明顺序一致，一一对应\n        return new STRUCT(sd,conn,objs.toArray());\n    }\n\n}\n\n/**\n * ServiceInfo\n**/\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.sql.Connection;\nimport java.lang.reflect.Field;\nimport java.sql.Clob;\nimport java.sql.Struct;\nimport oracle.sql.ARRAY;\nimport oracle.sql.ArrayDescriptor;\n\n public class ServiceInfo {\n    //服务编号\n    public String serviceNo;\n    //接口名称\n    public String serviceName;\n    //服务版本\n    public String serviceVersion;\n    //服务提供方\n    public String serviceProvider;\n    //联系人\n    public String contact;\n    //一级分类\n    public String AClass;\n    //二级分类\n    public String BClass;\n    //三级分类\n    public String CClass;\n    //服务描述\n    public String serviceDesc;\n    //业务场景\n    public String businessScene;\n    //备注\n    public String remarks;\n\n    //触发系统报文\n    public String triggeredMsg;\n    //接收系统报文\n    public String receiveMsg;\n\n    //技术信息\n    public TechnicalInfor technicalInfor;\n\n    //字段\n    public List<Fields> fieldses;\n  \n    private ServiceInfo() {\n    }\n\n\n    public static ServiceInfo build() {\n        ServiceInfo si = new ServiceInfo();\n        si.technicalInfor = new TechnicalInfor();\n        si.fieldses = new LinkedList<>();\n        return si;\n    }\n\n    public Struct toStruct(Connection conn) throws Exception {\n      List<Object> objs = new LinkedList<>();\n     \n        Class clazz = this.getClass();\n        Field[] fs = clazz.getDeclaredFields();\n        for (Field f : fs) {\n            if (\"receiveMsg\".equals(f.getName()) || \"triggeredMsg\".equals(f.getName())) {\n                Clob c = conn.createClob();\n                \n                c.setString(1, (String)f.get(this));\n                objs.add(c);\n            } else if (f.getType() == String.class) {\n              objs.add(f.get(this));\n            }else if (f.getType() == TechnicalInfo.class){\n                Field[] ffs = TechnicalInfor.class.getDeclaredFields();\n                for (Field ff: ffs){\n                    if (ff.getType()==String.class){\n                          objs.add(ff.get(this.technicalInfor));\n                    }\n                  \n                }\n            }else  if (\"fieldses\".equals(f.getName()) ){\n                Struct[] paramses = new Struct[fieldses.size()];\n                for (int i=0;i<fieldses.size();i++){\n                    paramses[i]=fieldses.get(i).toStruct(conn);\n                }\n               ArrayDescriptor ad = new ArrayDescriptor(\"ARRAY_OF_FIELDS\",conn);\n                \n                objs.add(new ARRAY(ad,conn,paramses));\n            }\n        }\n        //使用java标准接口创建struct，对应一个plsql的object\n       return     conn.createStruct(\"SERVICE_INFO\",objs.toArray());\n    }\n\n\n}\n```\n\n调用：\n\n```java\n   stmt = am.getDBTransaction().createCallableStatement(\"begin import_service_from_excel.import(:1,:2);    end;\", 1);\n   stmt.registerOutParameter(2, Types.VARCHAR);\n   Struct  serviceStruct =si.toStruct(stmt.getConnection());\n   stmt.setObject(1, serviceStruct);\n   stmt.execute();\n   String msg = stmt.getString(2);\n```\n\n\n\n### plsql\n\n##### object和array\n\n> `object`中的字段需要和`java bean`中的声明字段顺序保持一致\n\n```plsql\ncreate or replace type service_fields as object\n(\n--字段名称\n  field_name varchar2(200),\n--类型\n  field_type varchar2(100),\n--长度\n  field_length varchar2(20),\n--位置\n  field_position varchar2(100),\n--层级\n  field_level varchar2(10),\n--描述\n  field_desc varchar2(100),\n--备注\n  field_remarks varchar2(200)\n)\n\ncreate or replace type array_of_fields as array(1000000) of service_fields not null\n\ncreate or replace type service_info as object\n(\n--服务号\n  service_no varchar2(100),\n--服务名\n  service_name varchar2(100),\n\n--服务版本\n  serviceversion varchar2(50),\n--服务提供方\n  serviceprovider varchar2(50),\n--联系人\n  contact varchar2(50),\n--一级分类\n  aclass varchar2(50),\n--二级分类\n  bclass varchar2(50),\n--三级分类\n  cclass varchar2(50),\n--服务描述\n  servicedesc varchar2(150),\n--业务场景\n  businessscene varchar2(1000),\n--备注\n  remarks varchar2(200),\n--触发系统报文\n  triggeredmsg clob,\n--接收系统报文\n  receivemsg clob,\n--定时/实时\n  timingtype varchar2(20),\n--全量/增量\n  amounttype varchar2(20),\n--同步/异步\n  synctype varchar2(20),\n--传输逻辑\n  transferlogic varchar2(50),\n--服务地址\n  serviceaddress varchar2(1000),\n--技术场景\n  techscene varchar2(1000),\n--参数字段\n  fieldses array_of_fields\n\n)\n```\n\n##### procedure\n\n```plsql\nprocedure import(si  in service_info,\n                   msg out varchar2) is\n    l_cnt number;\n  begin\n   ...\n    \n  end import;\n```\n\n\n","tags":["java","plsql"]},{"title":"kotlin中的object更像是语法糖","url":"/2017/06/10/kotlin中的object更像是语法糖/","content":"\n\n\n### 单例声明\n\n\n\nkotlin中，声明一个单例的语法很简单：\n```\nobject obj\n```\n我们使用`object`关键字替代`class`关键字就可以声明一个单例对象\n`object`一样可以继承其他类，或者实现其他接口：\n```kotlin\ninterface IObj\nabstract class AbstractObj\nobject obj : AbstractObj(),IObj  \n```\n在这里，我们让`obj`这个单例继承了`AbstractObj`，并且实现了`IObj`接口\n声明一个单例对象，和声明一个`class`很类似\n但是，`object`声明的单例对象**不能声明构造函数**，因为单例对象只有一个实例，无需我们手动将它创建出来，因此自然不需要构造函数。\n> 如果需要对单例对象做初始化操作，可以在`init`初始化块内进行\n\n那么`object`是什么时候被创建的呢？\n>官方文档的解释是，`object`是`lazy-init`，即在第一次使用时被创造出来的\n\n`object`单例基本的使用就像上面这样了，基本的用法参照官方的文档说明就好了\n\n### 实现\n\n在java中，我们要使用一个单例模式时，一般使用双重检查锁：\n\n```java\npublic class Obj {\n      private Obj(){}\n      private static volatile Obj INSTANCE;\t\t//volatile防止指令重排\n      public static Obj getObj(){\n          if(INSTANCE==null){\n              synchronized(Obj.class){\n                  if (INSTANCE==null){\n                      INSTANCE=new Obj();\n                  }\n              }\n          }\n          return INSTANCE;\n      }\n}\n```\n而相同的功能，在kotlin只要`object Obj`就搞定了，这样的黑魔法是怎么实现的呢？\n为了探究一二，我们先来看看编译之后的字节码:\n\n```kotlin\n//源代码:\nobject Obj{\n    init{\n        println(\"object init...\")\n    }\n}\n```\n```java\n//对应的字节码：\npublic final class Obj {   //可以看到生成了一个class，而类名就是object name\n  // access flags 0x2\n  private <init>()V     //注意看，<init>的可见性是`private`\n   L0\n    LINENUMBER 8 L0\n    ALOAD 0  //将局部变量表slot 0处的引用入栈，即this引用\n    INVOKESPECIAL java/lang/Object.<init> ()V   //调用父类的<init>\n    ALOAD 0  //和上面一样，将局部变量表slot 0处的引用入栈，即this引用\n    CHECKCAST Obj    //类型检查\n    PUTSTATIC Obj.INSTANCE : LObj;     //保存this引用到`INSTANCE`这个静态域\n   L1\n    LINENUMBER 10 L1\n    LDC \"object init...\"    //从常量池将字符串引用送至栈顶\n    ASTORE 1    //将栈顶的引用保存到局部遍历表第一个slot处\n   L2\n    GETSTATIC java/lang/System.out : Ljava/io/PrintStream;    //获取out实例\n    ALOAD 1    //从局部变量表第一个slot处加载引用到栈顶\n    INVOKEVIRTUAL java/io/PrintStream.println (Ljava/lang/Object;)V   //输出\n   L3\n   L4\n   L5\n    RETURN  //返回\n   L6\n    LOCALVARIABLE this LObj; L0 L6 0\n    MAXSTACK = 2    //操作数栈深度为2\n    MAXLOCALS = 2    //局部变量表为2个slot\n  // access flags 0x19\n  public final static LObj; INSTANCE    //**静态域**，类型为Obj\n  // access flags 0x8\n  static <clinit>()V    //静态初始化块，类初始化时执行\n   L0\n    LINENUMBER 8 L0\n    NEW Obj     //创建一个Obj实例，引用保存在栈顶\n    INVOKESPECIAL Obj.<init> ()V   //调用其<init>，初始化对象，此时会把栈顶引用作为this引用传入\n    RETURN\n    MAXSTACK = 1\n    MAXLOCALS = 0\n}\n```\n从上面的字节码中，我们可以看到，声明一个`object`，实际上就是创建了一个`class`，在类静态初始化时，会创建一个该类的实例，保存到其静态域`INSTANCE`中\n进而可以猜想，源码中对单例的引用会被编译器替换为对`INSTANCE`这个静态域的引用\n为了验证我们的分析，现在来看看使用单例时，对应的字节码\n```kotlin\n源码：\nfun main(args:Array<String>){\n    Obj is Any\n}\n```\n```\n对应的字节码：\npublic final static main([Ljava/lang/String;)V\n    @Lorg/jetbrains/annotations/NotNull;() // invisible, parameter 0\n   L0\n    ALOAD 0\n    LDC \"args\"\n    INVOKESTATIC kotlin/jvm/internal/Intrinsics.checkParameterIsNotNull (Ljava/lang/Object;Ljava/lang/String;)V\n   L1\n    LINENUMBER 5 L1\n    GETSTATIC Obj.INSTANCE : LObj;    //获取Obj的静态域`INSTANCE`\n    INSTANCEOF java/lang/Object        //判断是否是`Object`类型\n    POP\n   L2\n    LINENUMBER 6 L2\n    RETURN\n   L3\n    LOCALVARIABLE args [Ljava/lang/String; L0 L3 0\n    MAXSTACK = 2\n    MAXLOCALS = 1\n```\n\n可以看到，我们在源码中直接使用`object name`访问单例对象，而编译器帮我们做了翻译，实际使用的是内部的静态域`INSTANCE`\n而且，从对上面`Obj`这个生成的类的分析，我们可以发现，`object`在java中的对应的实现是类型这样的：\n\n```java\npublic class  Obj {\n    private Obj(){}\n    private static Obj INSTANCE=null;\n    static {\n        INSTANCE=new Obj();\n    }\n}\n```\n这是最简单的单例实现方法，在类加载器加载class后执行静态初始化时就创建单例对象。\n\n而`object`单例初始化的时机，准确来说，应该是这个类被加载时，静态初始化的时候。\n做个小实验：\n\n```kotlin\nobject Obj{\n    init{\n        println(\"object init...\")\n    }\n}\n```\n```kotlin\nfun main(args:Array<String>){\n         Class.forName(\"Obj\")\n    }\n```\n>控制台输出：object init...\n\n可见，当我们加载这个类的时候，单例就被创建了。\n而单例名就是类名。\n\n那么，`object`真的就是单例吗？\n一般情况下是的，因为字节码中`<init>`方法被声明为`private`，虽然不太准确但是我们可以认为对应了类的一个`private`的无参构造函数，这就使得我们无法创建出一个新的对象出来。\n但是，我们完全可以使用反射机制，从一个`private`的构造函数中创建一个对象出来：\n```kotlin\nfun main(args:Array<String>){\n    println(Obj)\n    var clazz=Class.forName(\"Obj\")\n    var constrouctor=clazz.getDeclaredConstructor()\n    constrouctor.setAccessible(true)\n    var instance=constrouctor.newInstance()\n    constrouctor.setAccessible(false)\n    println(instance)\n}\n输出：\nobject init...\nObj@511d50c0\nobject init...\nObj@60e53b93\n```\n可见，两次输出的对象引用是不一样的。\n\n那么，这就说明kotlin的单例是不安全的吗？这到未必\n我们在原先的基础上，加上几个属性声明：\n```\nobject Obj{\n    var name=\"name\"\n    var age=\"10\"\n    init{\n        println(\"object init...\")\n    }\n}\n```\n观察对应的字节码：\n```\npublic final class Obj {\n  private static Ljava/lang/String; name\n   ...\n  private static Ljava/lang/String; age\n  ....\n  public final static LObj; INSTANCE\n  ...  \n}\n```\n可以看到，这些属性的`field`都被声明为`static`了，尽管可以通过反射手段创建多个`object`的实例，但是它们的状态都是共享的\n总结：\n\n- `object`实际上还是生成一个`class`，但是这个`class`在`kotlin`中是透明的，无法直接访问，比如`Obj.INSTANCE`在kotlin中是不允许的，只能通过`Obj`来引用这个单例\n- `object name`本质上是类名，只是编译器在编译时自动将`object name`换成了 `object`的`INSTANCE`\n- `object`更像是语法糖","tags":["kotlin"]},{"title":"kotlin之代理属性","url":"/2017/05/16/kotlin之代理属性/","content":"\n### 属性代理\n\n##### 委托类\n\n委托类可以自己定义，必须提供`getValue`，如果用于代理var属性，还必须提供`setValue` \n\n```kotlin\nclass Delegate {\n  \t/**\n     * @param thisRef 被代理类实例\n     * @param property 被代理属性\n     */\n    operator fun getValue(thisRef: Any?, property: KProperty<*>): String {\n        return \"$thisRef, thank you for delegating '${property.name}' to me!\"\n    } \n    operator fun setValue(thisRef: Any?, property: KProperty<*>, value: String) {\n        println(\"$value has been assigned to '${property.name} in $thisRef.'\")\n    }\n}\n```\n\n##### 使用\n\n具体的使用方法：\n\n```\nvar 变量名:type by 委托对象\nval 变量名:type by 委托对象\n```\n\n使用代理属性禁止自定义setter和getter，代理的本质就是将setter和getter委托给其他对象\n\nkotlin提供了几个标准的代理工厂方法：\n\n- 懒加载： **the value gets computed only upon first access** \n\n```kotlin\n//通过使用工厂方法lazy()获得Lazy<T>实例\nfun main(args:Array<String>){\n\t//lazy没有提供setter，所以使用lazy代理的属性必须为val\n    val str:String by lazy{  //Lazy<T>懒加载，只会在第一次时执行\n        println(\"lazy\")\n        \"hello\"\n    }\n    println(str)\n    println(str)\n}\n```\n\n- observable properties: **listeners get notified about changes to this property** \n\n```kotlin\nfun main(args:Array<String>){\n    var p=Person()\n    println(p.name)\n    p.name=\"Jim\"\n    println(p.name)\n}\n\nclass Person{\n    var name by Delegates.observable(\"no-name\"){  //set时被调用\n        prop,old,new->\n        println(\"$prop($old->$new)\")\n    }\n}\n```\n\n- **storing properties in a map, not in separate field each **\n\n```kotlin\nfun main(args:Array<String>){\n    var p=Person(mutableMapOf(\"name\" to \"Tim\",\"age\" to 10))\n    println(p.name)\n    println(p.age)\n\n}\n\nclass Person(map:MutableMap<String,Any?>){\n    var name:String by map\n    var age:Int by map\n}\n```\n\n##### 工作原理\n\n```kotlin\nclass C {\n    var prop: Type by MyDelegate()\n} \n// this code is generated by the compiler\n// when the 'provideDelegate' function is available:\nclass C {\n    // calling \"provideDelegate\" to create the additional \"delegate\" property\n    private val prop$delegate = MyDelegate().provideDelegate(this, this::prop)\n    val prop: Type\n        get() = prop$delegate.getValue(this, this::prop)\n}\n```\n\nkotlin 1.1之后，代理属性可以用于local-properties\n\n\n\n### 方法代理\n\n```kotlin\nfun main(args:Array<String>){\n    var b=B(AImpl())\n    b.echo()\n}\n\ninterface A{\n    fun echo()\n}\n\nclass AImpl:A{\n    override fun echo(){\n        println(\"a implemention of A\")\n    }\n}\nclass B(impl:AImpl):A by impl  //impl提供B的接口方法\n```\n方法代理的实现原理就是编译时，自动为B生成echo方法的实现，并在该方法中调用impl的echo方法，因此B实例会持有impl的引用","tags":["kotlin"]},{"title":"使用kotlin写自己的dsl","url":"/2017/04/25/使用kotlin写自己的dsl/","content":"\n\n\n相比于java，kotlin对**FP**更加友好，支持扩展函数和操作符重载，这就为定义dsl提供了支持。\n什么是dsl呢？就是一种面向特定问题的语言。gradle就是是一种用groovy定义的dsl。而kotlin一样对定义dsl提供了友好的支持。\n本篇文章就来定义一个简单用于配置hibernate框架的dsl，写起来就像：\n\n```kotlin\nvar conf= buildConfiguration{\n                connection {\n                    username = \"***\"\n                    password = \"******\"\n                    url = \"jdbc:mysql://localhost:3306/******\"\n                    driver = Driver::class.java\n                }\n                c3p0 {\n                    max_size = 30\n                    min_size = 10\n                    timeout=5000\n                    max_statements=100\n                    idle_test_period=300\n                    acquire_increment=2\n                    validate=true\n                }\n                entity {\n                    mapping = Client::class.java\n                    mapping = Financial_account::class.java\n                    mapping = FundHolding::class.java\n                    mapping=Fund::class.java\n                }\n                dialect=\"org.hibernate.dialect.MySQL5InnoDBDialect\"\n            }\n```\n\n上面是一个对hibernate的简单配置，最后获取一个configuration实例。通过使用dsl，可以避免在运行时解析xml文件，同时又比使用java代码配置简洁，兼具xml的结构化和java的高效。\n那么，这样一个dsl是如何实现的呢？\n\n> 先介绍一下预备知识：\n> 扩展函数：\n```kotlin\nfun Type.foo():Unit{\n  ...\n}\n```\n这样就为`Type`对象创建了一个扩展函数，假如`t`是`Type`的一个实例，就可以：\n```t.foo()```\n`Type`称作`reciver`，而在`foo`函数体内，可以使用`this`访问其`public`成员，甚至可以省略`this`，仿佛`foo`函数是定义在`class Type`内\n而声明一个函数的参数是扩展函数，一般的语法：\n`fun funName(block:Type.(params...)->ReturnType):ReturnType{...}`\n关于扩展函数更多的用法，可以参考官方的文档\n\n首先先声明一个方法：\n```kotlin\nfun buildConfiguration(block:ConfigurationBuilder.()->Unit):Configuration{\n    var cfg=ConfigurationBuilder()\n    cfg.block()\n    return cfg.cfg\n} \n```\n这个方法接收一个有receiver的lambda表达式，因为这样在block的内部就可以直接访问receiver的公共成员了，这一点很重要\n紧接着对这个Configuration这个类进行定义\n```kotlin\nclass ConfigurationBuilder{\n     val TAG=\"hibernate\"\n     val cfg=Configuration()\n     var dialect:String? get() = null\n        set(value){\n            cfg.setProperty(\"$TAG.dialect\",value!!)\n        }\n     inline fun connection(block:ConnectionBuilder.()->Unit)=ConnectionBuilder(cfg).block()\n     inline fun c3p0(block:C3p0Builder.()->Unit)=C3p0Builder(cfg).block()\n     inline fun entity(block:Entity.()->Unit)=Entity(cfg).block()\n}\n```\n\n在里面我定义了三个成员函数，分别对应前面示例中的\n```kotlin\nvar conf= buildConfiguration{\n                connection {\n                    ...\n                }\n                c3p0 {\n                    ...\n                }\n                entity {\n                    ...\n                }\n               ...\n            }\n```\n\n在这个lambda里面，我就直接调用了buildConfiguration的成员函数，那么对象引用呢？还记得我前面说过的吗？buildConfiguration这个方法的参数是一个有receiver的lambda，而在buildConfiguration中声明了一个ConfigurationBuilder对象并通过这个对象调用了这个lambda。那么这个lambda就会在这个对象的上下文中，我们可以直接访问它的公共成员，甚至可以使用this引用这个对象。\n后续的步骤都差不多,我这里为了省事直接就声明了一个Configuration对象，并传到了其他对象里面\n后面的源码\n```kotlin\nclass ConnectionBuilder(val cfg:Configuration){//直接接受了一个configuration对象\n     val TAG=\"hibernate.connection\"\n     var username:String? get() = null  //重写了setter和getter，防止属性有field\n        set(name){\n            cfg.setProperty(\"$TAG.username\",name!!)  //直接硬编码设置属性\n        }\n     var password:String?  get() = null\n        set(password) {\n            cfg.setProperty(\"$TAG.password\", password!!)\n        }\n      var url:String? get() = null\n        set(url){\n            cfg.setProperty(\"$TAG.url\",url!!)\n        }\n      var driver:Class<*>? get() = null\n        set(driver){\n            cfg.setProperty(\"$TAG.driver_class\",driver!!.name)\n        }\n      var pool_size:Int? get() = null\n        set(size){\n            cfg.setProperty(\"$TAG.pool_size\",size!!.toString())\n        }\n}\n//后面的都差不多。。。\n class C3p0Builder(val cfg:Configuration){\n     val TAG=\"hibernate.c3p0\"\n     var max_size:Int? get() = null\n        set(max_size){\n            cfg.setProperty(\"$TAG.max_size\",max_size!!.toString())\n        }\n     var min_size:Int? get() = null\n        set(min_size){\n            cfg.setProperty(\"$TAG.min_size\",min_size!!.toString())\n        }\n     var timeout:Int? get() = null\n        set(timeout){\n            cfg.setProperty(\"$TAG.timeout\",timeout!!.toString())\n        }\n     var max_statements:Int? get() = null\n        set(max_stmt){\n            cfg.setProperty(\"$TAG.max_statements\",max_stmt!!.toString())\n        }\n     var idle_test_period:Int? get() = null\n        set(idle_test_period){\n            cfg.setProperty(\"$TAG.idle_test_period\",idle_test_period!!.toString())\n        }\n     var acquire_increment:Int? get() = null\n        set(acquire){\n            cfg.setProperty(\"$TAG.acquire_increment\",acquire!!.toString())\n        }\n     var validate:Boolean? get() = null\n        set(validate){\n            cfg.setProperty(\"$TAG.validate\",validate!!.toString())\n        }\n}\n class Entity(val cfg:Configuration){\n     var mapping:Class<*>?\n        get()=null\n        set(clazz){\n            cfg.addAnnotatedClass(clazz!!)\n        }\n}\n```\n\n至此，一个简单的dsl就完成了\n总体来说，定义一个dsl的过程基本是一个递归下去的过程，每个步骤都很类似","tags":["kotlin","dsl"]}]